{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0da81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorboard\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506e1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/Owner/ICT5012 - Disseration/transit_learning-master_Newest')\n",
    "from torch_geometric.loader import DataLoader\n",
    "from simulation.citygraph_dataset import CityGraphData, \\\n",
    "    get_dataset_from_config, STOP_KEY\n",
    "from simulation.transit_time_estimator import RouteGenBatchState, get_cost_module_from_cfg\n",
    "import learning.utils as lrnu\n",
    "from torch_utils_2 import get_batch_tensor_from_routes, dump_routes\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5488e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Mater Dei North Routes\n",
    "Mater_Dei_NorthRoutes = [\n",
    "    torch.tensor([3,81,75,76,77,78,79,80,85,86,87,88,119,194,195,196,197,198,29,199,200,201,202,203,204,205,206,207,208]),\n",
    "    torch.tensor([208,209,210,211,201,200,212,213,196,197,214,193,215,28,116,117,118,88,87,86,77,79,80,84,76,75,0,1,2]),\n",
    "    torch.tensor([202,203,204,205,206,207,208,209,210,211,201,200,212,213,196,197,214,193,215,28,116,117,118,88,87,86,77,79,80,84,76,75,0,1,2]),\n",
    "    torch.tensor([3,269,22,23,24,25,26,27,28,29,30,140,31,141,32,33,142,143,144,145,150,144,152,153,154,155,186,187,188,156,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184]),\n",
    "    torch.tensor([184,216,217,218,185,219,220,221,222,223,186,187,188,155,154,153,144,51,150,144,143,142,52,32,141,53,151,30,29,28,54,26,25,24,23,22,5,0,1,2]),\n",
    "    torch.tensor([174,175,176,177,178,179,180,182,183,184,216,217,218,185,219,220,221,222,223,186,187,188,155,154,153,144,51,150,144,143,142,270,32,141,53,151,30,29,28,54,26,25,24,23,22,5,0,1,2]),\n",
    "    torch.tensor([3,269,139,138,137,136,123,124,125,126,127,128,129,130,131,132,133,134,27,28,29,30,140,31,141,32,33,142,143,144,145,146,34,147,148,157,189,190,191,192,148,158,159,160,161,162,163,164,165]),\n",
    "    torch.tensor([165,166,167,168,161,160,158,147,148,157,189,190,191,192,148,34,149,51,150,144,143,142,52,32,141,53,151,30,29,28,54,134,133,132,135,130,129,128,126,125,123,136,137,138,139,5,0,1,2]),\n",
    "    torch.tensor([158,159,160,161,162,163,164,165,166,167,168,161,160,158,147,148,157,189,190,191,192,148,34,149,51,150,144,143,142,52,32,141,53,151,30,29,28,54,134,133,132,135,130,129,128,126,125,123,136,137,138,139,5,0,1,2]),\n",
    "    torch.tensor([3,269,139,138,137,136,123,224,225,226,227,228,229,230,231,232,233,234,235,236,237,239,240,241,240,239,238,248,249,250,251,252,253,254,255]),\n",
    "    torch.tensor([255,256,257,258,259,260,261,262,263,264,265,249,266,267,239,240,241,240,239,238,237,236,235,242,232,243,244,245,229,228,268,246,225,247,224,123,136,137,138,139,5,0,1,2]),\n",
    "    torch.tensor([3,81,82,56,62,58,21,20,19,57,61,14,13,12,11,10,9,8,7,6,63,64,65,66,67,68,69,70,71]),\n",
    "    torch.tensor([71,72,71,73,74,4,55,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,58,59,60,83,0,1,2]),\n",
    "    torch.tensor([63,64,65,66,67,68,69,70,71,72,71,73,74,4,55,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,58,59,60,83,0,1,2]),\n",
    "    torch.tensor([3,269,83,56,110,111,112,113,114,115,27,116,117,118,120,121,89,90,91,92,93,94,95,96,97,35,98,99,100,101,102,36,37,38,39,40,41,42,43]),\n",
    "    torch.tensor([103,44,45,46,47,48,49,50,102,101,100,99,98,35,97,104,95,105,106,107,108,109,271,121,120,118,117,116,122,54,115,114,113,112,111,110,83,0,1,2])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65283045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Config, self).__init__(*args, **kwargs)\n",
    "        for key, value in self.items():\n",
    "            if isinstance(value, dict):\n",
    "                self[key] = Config(value)\n",
    "            elif isinstance(value, list):\n",
    "                # Convert dict elements in lists to Config objects\n",
    "                self[key] = [Config(item) if isinstance(item, dict) else item for item in value]\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "\n",
    "cfg = Config({\n",
    "    'ppo': {\n",
    "        'n_iterations': 200,\n",
    "        'val_period': 10,\n",
    "        'n_epochs': 1,\n",
    "        'minibatch_size': 2,\n",
    "        'horizon': 26,\n",
    "        'epsilon': 0.2,\n",
    "        'use_gae': False,\n",
    "        'gae_lambda': 0.95\n",
    "    },\n",
    "    'discount_rate': 0.95,\n",
    "    'diff_reward': False,\n",
    "    'baseline_lr': 0.0005,\n",
    "    'entropy_weight': 0,\n",
    "    'batch_size': 2,\n",
    "    'reward_scale': 1.0,\n",
    "    'lr': 0.0016134816080499328,\n",
    "    'decay': 0.0008404361781997002,\n",
    "    'optimizer': 'Adam',\n",
    "    'eval': {\n",
    "        'n_routes': 15,\n",
    "        'min_route_len': 11,\n",
    "        'max_route_len': 42\n",
    "    },\n",
    "    'dataset': {\n",
    "        'type': 'mumford',\n",
    "        'kwargs': {\n",
    "            'path': 'datasets/mumford_dataset/Instances',\n",
    "            'city': 'Gozo'\n",
    "        }\n",
    "    },\n",
    "    'experiment': {\n",
    "        'logdir': 'training_logs',\n",
    "        'anomaly': False,\n",
    "        'cpu': False,\n",
    "        'seed': 0,\n",
    "        'symmetric_routes': False\n",
    "    },\n",
    "    'defaults': [\n",
    "        '_self_',\n",
    "        {\n",
    "            'cost_function': {\n",
    "                'type': 'mine',\n",
    "                'kwargs': {\n",
    "                    'mean_stop_time_s': 0,\n",
    "                    'avg_transfer_wait_time_s': 300,\n",
    "                    'demand_time_weight': 0.5,\n",
    "                    'route_time_weight': 0.5,\n",
    "                    'constraint_violation_weight': 5.0,\n",
    "                    'variable_weights': False,\n",
    "                    'pp_fraction': 0.33,\n",
    "                    'op_fraction': 0.33\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fb1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Config, self).__init__(*args, **kwargs)\n",
    "        for key, value in self.items():\n",
    "            if isinstance(value, dict):\n",
    "                self[key] = Config(value)\n",
    "    __getattr__ = dict.get\n",
    "\n",
    "# Minimal experiment configuration\n",
    "exp_dc = Config({\n",
    "    'cost_function': {\n",
    "        'type': 'mine',  # Specify the cost function type as 'mine'\n",
    "        'kwargs': {}     # Any additional parameters can be added here\n",
    "    },\n",
    "    'symmetric_routes': False,    # or False, based on your requirement\n",
    "    'low_memory_mode': False\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66ff223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    __getattr__ = dict.get\n",
    "\n",
    "# ANDRE - CHANGE HERE\n",
    "Dataset_Info = Config({\n",
    "    'csv': True,\n",
    "    'n_routes': 16,\n",
    "    'min_route_len': 29,\n",
    "    'max_route_len': 56,\n",
    "    'type': 'mumford',\n",
    "    'path': 'C:/Users/Owner/ICT5012 - Disseration/transit_learning-master/CEC2013Supp/Instances/Evening_Model',\n",
    "    'city': 'Mater_dei_north_routes'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db85585",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cfg = cfg.experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26734fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_cfg.get('cpu', False) or not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf1cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in cfg:\n",
    "    # setup the model\n",
    "    model = build_model_from_cfg(cfg['model'], exp_cfg)\n",
    "    if 'weights' in cfg.model:\n",
    "        model.load_state_dict(torch.load(cfg.model.weights,map_location=device))\n",
    "    elif weights_required and cfg.model.route_generator.type != 'RandomPathCombiningRouteGenerator': raise ValueError(\"model weights are required but not provided\")\n",
    "else:\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4206e80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_memory_mode: False\n"
     ]
    }
   ],
   "source": [
    "# setup the cost function\n",
    "low_mem_mode = exp_cfg.get('low_memory_mode', False)\n",
    "cost_obj = get_cost_module_from_cfg(exp_dc.cost_function, low_mem_mode,\n",
    "                                    exp_cfg.symmetric_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9978d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_obj.to(device)\n",
    "if model is not None:\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2de489",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = get_dataset_from_config(Dataset_Info)\n",
    "test_dl = DataLoader(test_ds, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86e0e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = cfg.get('n_samples', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af665de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs = cfg.get('sample_batch_size', cfg.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d57f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(test_dl):\n",
    "    if device is not None and device.type != 'cpu':\n",
    "        data = data.cuda()\n",
    "    start_time = time.time()\n",
    "    state = RouteGenBatchState(data, cost_obj, cfg.eval.n_routes, \n",
    "                                   cfg.eval.min_route_len, \n",
    "                                   cfg.eval.max_route_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "795f42b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max route length: 56\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your list of route tensors (on CUDA). Each tensor is 1D.\n",
    "routes_list = Mater_Dei_NorthRoutes\n",
    "\n",
    "# Determine maximum route length among all routes.\n",
    "max_length = max(route.numel() for route in routes_list)\n",
    "print(\"Max route length:\", max_length)\n",
    "\n",
    "# Pad each route with -1 so that all routes have the same length.\n",
    "padded_routes = []\n",
    "for route in routes_list:\n",
    "    pad_length = max_length - route.numel()\n",
    "    if pad_length > 0:\n",
    "        padded_route = torch.cat([route, -1 * torch.ones(pad_length, dtype=route.dtype, device=route.device)])\n",
    "    else:\n",
    "        padded_route = route\n",
    "    padded_routes.append(padded_route)\n",
    "\n",
    "# Stack the padded routes to form a tensor of shape [n_routes, max_length].\n",
    "routes_tensor = torch.stack(padded_routes)\n",
    "\n",
    "# Add a batch dimension so the final tensor has shape [1, n_routes, max_length].\n",
    "final_routes_tensor_correct = routes_tensor.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2487c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.add_new_routes(final_routes_tensor_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02f06cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_STOP_TIME_S = 0\n",
    "AVG_TRANSFER_WAIT_TIME_S = 300\n",
    "UNSAT_PENALTY_EXTRA_S = 3000\n",
    "EPSILON = 1e-6\n",
    "\n",
    "\n",
    "# Start by Obtaining Passenger Cost\n",
    "\n",
    "# Load Demand Matrix from State\n",
    "demand_matrix = state.demand\n",
    "# Load Drive Times Matrix from State\n",
    "drive_times_matrix = state.drive_times\n",
    "\n",
    "# Calculate amount of demand at each number of transfers\n",
    "trips_at_transfers = torch.zeros(state.batch_size, 4, device=device)\n",
    "# Load Number of transfers\n",
    "n_transfers = state.n_transfers.clone()\n",
    "# Label instances where no path exists as nopath\n",
    "nopath = ~state.has_path\n",
    "# Obtain number of unsatisfied demand\n",
    "n_transfers[nopath] = 3\n",
    "for ii in range(3):\n",
    "    d_i = (demand_matrix * (n_transfers == ii)).sum(dim=(1,2))\n",
    "    trips_at_transfers[:, ii] = d_i\n",
    "    \n",
    "d_un = (demand_matrix * (n_transfers > 2)).sum(dim=(1, 2))\n",
    "trips_at_transfers[:, 3] = d_un\n",
    "\n",
    "\n",
    "# Load transit_times (equivalent to shortest distances based on floyd_warshall)\n",
    "trip_times = state.transit_times\n",
    "# Adjust 'inf' trip_time values to 0 if nopath exists\n",
    "trip_times[nopath] = 0\n",
    "# Caclulate demand_time matrix\n",
    "demand_time = demand_matrix * trip_times\n",
    "# Calculate total_demand_time\n",
    "total_dmd_time = demand_time.sum(dim=(1, 2))\n",
    "# Calculate number of total_transfers\n",
    "demand_transfers = demand_matrix * state.n_transfers\n",
    "total_transfers = demand_transfers.sum(dim=(1, 2))\n",
    "# Calculate unserved demand\n",
    "unserved_demand = (demand_matrix * nopath).sum(dim=(1, 2))\n",
    "# Calculate total demand\n",
    "total_demand = demand_matrix.sum(dim=(1,2))\n",
    "# Calculate served demand\n",
    "served_demand = (state.has_path * demand_matrix).sum(dim = (1,2))\n",
    "# Calculate Mean Demand Time\n",
    "mean_demand_time = total_dmd_time/ (served_demand + EPSILON)\n",
    "# Calculate time_normalizer\n",
    "time_normalizer = state.drive_times.flatten(1,2).max(1).values\n",
    "# Calculate Demand Cost\n",
    "demand_cost = (mean_demand_time*served_demand) + (unserved_demand*time_normalizer*2)\n",
    "# Calculate Demand Cost (Before Normalizer)\n",
    "demand_cost /= total_demand\n",
    "# Calculate Demand Cost (After Normalizer)\n",
    "demand_cost = demand_cost/time_normalizer\n",
    "\n",
    "# Start by Obtaining Operator Cost\n",
    "n_routes = state.n_routes_to_plan\n",
    "# Calculate Route Cost (Before Normalizer)\n",
    "route_cost = state.total_route_time\n",
    "# Calculate Route Cost (After Normalizer)\n",
    "route_cost = route_cost/(time_normalizer * n_routes + 1e-6)\n",
    "\n",
    "# Passenger and Operator Cost\n",
    "demand_weight = 0.5\n",
    "route_weight = 0.5\n",
    "Passenger_y_Operator_Cost = (demand_weight*demand_cost) + (route_weight*route_cost)\n",
    "\n",
    "\n",
    "# Calculate Constraint Violation\n",
    "\n",
    "# Number of Uncovered Demand Nodes\n",
    "frac_uncovered = state.get_n_disconnected_demand_edges() / state.n_demand_edges\n",
    "# Calculate Constraint Violation\n",
    "const_viol_cost = frac_uncovered + 0.1 * (frac_uncovered > 0)\n",
    "\n",
    "# Calculate final cost\n",
    "cost = Passenger_y_Operator_Cost + (const_viol_cost * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92588331",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = cost\n",
    "C_p = mean_demand_time/60\n",
    "C_o = state.total_route_time/60\n",
    "d_0 = (trips_at_transfers[:, 0]/total_demand)*100\n",
    "d_1 = (trips_at_transfers[:, 1]/total_demand)*100\n",
    "d_2 = (trips_at_transfers[:, 2]/total_demand)*100\n",
    "d_unsat = (d_un/total_demand)*100\n",
    "disconnected_node_pairs = state.get_n_disconnected_demand_edges()\n",
    "stops_out_of_bounds = min(state.max_route_len - max_length,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a5d8207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Cost        C_p          C_o  0 Tr. (%)  1 Tr. (%)  2 Tr. (%)  \\\n",
      "0  2.259468  20.515188  1043.883301  36.739292   19.30879  13.598798   \n",
      "\n",
      "   Unsat. Demand (%)  Disc. NP          Max RL  \n",
      "0          30.353117       309  [tensor(True)]  \n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with your desired column headers.\n",
    "data = {\n",
    "    \"Cost\": cost[0].item(),\n",
    "    \"C_p\": C_p[0].item(),\n",
    "    \"C_o\": C_o[0].item(),\n",
    "    \"0 Tr. (%)\": d_0[0].item(),\n",
    "    \"1 Tr. (%)\": d_1[0].item(),\n",
    "    \"2 Tr. (%)\": d_2[0].item(),\n",
    "    \"Unsat. Demand (%)\": d_unsat[0].item(),\n",
    "    \"Disc. NP\": disconnected_node_pairs[0].item(),\n",
    "    \"Max RL\": stops_out_of_bounds != 0\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame.\n",
    "df = pd.DataFrame([data])  # each key becomes a column header\n",
    "\n",
    "# Display the DataFrame.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26d1f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+-------------+-------------+-------------+---------------------+------------+----------+\n",
      "|    Cost |     C_p |     C_o |   0 Tr. (%) |   1 Tr. (%) |   2 Tr. (%) |   Unsat. Demand (%) |   Disc. NP |   Max RL |\n",
      "|---------+---------+---------+-------------+-------------+-------------+---------------------+------------+----------|\n",
      "| 2.25947 | 20.5152 | 1043.88 |     36.7393 |     19.3088 |     13.5988 |             30.3531 |        309 |        1 |\n",
      "+---------+---------+---------+-------------+-------------+-------------+---------------------+------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate \n",
    "print(tabulate(df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed7d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
