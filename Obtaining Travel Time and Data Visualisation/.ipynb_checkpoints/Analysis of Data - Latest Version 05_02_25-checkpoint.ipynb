{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c614eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Packages\n",
    "\n",
    "# Importing 'pandas' to handle datasets\n",
    "import pandas as pd\n",
    "# Importing 'numpy' to handle arrays\n",
    "import numpy as np\n",
    "\n",
    "# Importing math to be able to utilise mathematical functions (radian is defined by converting 90 degrees)\n",
    "import math\n",
    "degree = 90\n",
    "radian = math.radians(degree)\n",
    "\n",
    "# Importing 're' package - Python Regular Expressions\n",
    "import re\n",
    "\n",
    "# Importing 'xml.etree.cElementTree' to be able to handle xml files\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import requests \n",
    "import json \n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e369ebc",
   "metadata": {},
   "source": [
    "### Step 1 - Preparing Data Sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00cdb64",
   "metadata": {},
   "source": [
    "Appending the following columns to the 'All_Routes_Complete.csv' file obtained from the Malta public transport (MPT) website\n",
    "\n",
    "    1. 'Stop Island' - Defines the island (Malta/Gozo) the corresponding Route Number operates in. \n",
    "    2. 'Time_Count' - Number of buses operating on a particular Route Number and Route Direction from the start till the end of the bus service.\n",
    "    3. 'Stops - City Name - Stop Island' - Key column used to compare data in 'All_Routes_Complete.csv' to data in Bus_Stop_Info ('Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx')\n",
    "    4. 'Longitude_Final' - Longitude value of corresponding Bus Stop entry ('Stops') obtained from Bus_Stop_Info\n",
    "    5. 'Latitude_Final' - Latitude value of corresponding Bus Stop entry ('Stops') obtained from Bus_Stop_Info\n",
    "    6. 'Bus_Stop_ID' - Unique identifier for all Bus Stops ('Stops')\n",
    "    7. 'Next_Bus_Stop_ID' - Since All_Routes ('All_Routes_Complete.csv') was extracted in sequential order from MPT website, the next row in All_Routes corresponds to the upcoming Bus Stop (Given 'Route Number', 'Route Direction' and 'Date' columns remain the same). Hence, 'Next_Bus_Stop_ID' is the unique identifier of the upcoming Bus Stop ('Stops')\n",
    "    8. 'Bus_Stop_Next_Bus_Stop'- Unique identifier used to define connection between 'Bus_Stop_ID and 'Next_Bus_Stop_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521fc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1 - Load Datasets\n",
    "# Loading 'All_Routes_Complete.csv' (All_Routes) and 'Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx' (Bus_Stop_Info) Datasets\n",
    "# Recall 'All_Routes_Complete.csv' is the file which was obtained from MPT website consisting of all Bus Schedules in sequential order\n",
    "# Recall 'Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx' consits of the Longitude and Latitude data of all Bus Stops defined in 'All_Routes_Complete.csv' \n",
    "\n",
    "# From Home\n",
    "All_Routes = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Scraping Route Names from MPT Website//Results//All_Routes_Complete.csv\", low_memory = False)\n",
    "Bus_Stop_Info = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Obtaining Longitude and Latitude for all Bus Stops//Results (Checks Done + Manual Adjustment)//Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx\")\n",
    "\n",
    "# From Work \n",
    "#All_Routes = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//All_Routes_Complete.csv\", low_memory = False)\n",
    "#Bus_Stop_Info = pd.read_excel(\"C://Users//attardan.CBM//Data Visualisation//Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1450c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2 - Create 'Stop Island' column\n",
    "# To differentiate between stops in Malta and Gozo, stops with correspoding 'Route Number' belonging to the 'Gozitan_Route_Number'\n",
    "# list will be labelled as 'GOZO STOP' whilst all other stops will be labelled as 'MALTA STOP' using a column entitled 'Stop Island' \n",
    "\n",
    "Gozitan_Route_Number = ['301', '302', '303',\n",
    "                        '305', '306', '307',\n",
    "                        '308', '309', '310',\n",
    "                        '311', '312', '313',\n",
    "                        '322', '323', '330',\n",
    "                        'N301']\n",
    "\n",
    "All_Routes['Stop Island'] = np.where(All_Routes['Route Number'].isin(Gozitan_Route_Number), 'GOZO STOP', 'MALTA STOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6ddb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.3 - Create 'Time_Count' column\n",
    "# The 'Time_Count' column will be added to count the number of buses operating throughout one day for a particular route.\n",
    "# 'Time_Count' will be used as another method to identify between different routes having the same 'Route Number', 'Route Direction' and 'Date' column\n",
    "\n",
    "# Select all columns in 'All_Routes' that start with 'Stop Time'\n",
    "Stop_Time_Columns = [col for col in All_Routes.columns if col.startswith('Stop Time')]\n",
    "# Row-wise count all'Stop Time' columns which are filled in and populate the 'Time_Count' column with sum \n",
    "All_Routes['Time_Count'] = All_Routes[Stop_Time_Columns].notna().sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cddb65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.4 - Merge 'Longitude_Final' and 'Latitude_Final' columns from 'Bus_Stop_Info' dataframe to 'All_Routes' dataframe\n",
    "\n",
    "# Create column entitled 'Stops - City Name - Stop Island' (Concatenation of 'Stops', 'City Name' and 'Stop Island' columns) \n",
    "# in both 'All_Routes' and 'Bus_Stop_Info'\n",
    "All_Routes['Stops - City Name - Stop Island'] = All_Routes['Stops'] + ' - ' + All_Routes['City Name'] + ' - ' + All_Routes['Stop Island']\n",
    "Bus_Stop_Info['Stops - City Name - Stop Island'] = Bus_Stop_Info['Stops'] + ' - ' + Bus_Stop_Info['City Name'] + ' - ' + Bus_Stop_Info['Stop_Island']\n",
    "# Merge 'Bus_Stop_Info' Dataframe to 'All_Routes' such that 'All_Routes' dataframe will have 'Longitude_Final' and 'Latitude_Final' values for all corresponding entries\n",
    "All_Routes = pd.merge(All_Routes, Bus_Stop_Info[['Stops - City Name - Stop Island', 'Longitude_Final', 'Latitude_Final']], on = 'Stops - City Name - Stop Island', how = 'left', sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be9fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_29856\\3704762601.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Distinct_Coordinates['Stop ID'] = [f'Stop_{i}' for i in range(len(Distinct_Coordinates))]\n"
     ]
    }
   ],
   "source": [
    "# Step 1.5 - Create a unique identifier for all Bus Stops ('Stops') entitled 'Bus_Stop_ID'\n",
    "\n",
    "# Obtain Dataframe entitled 'Distinct_Coordinates' consisting only of entries with distinct 'Latitude_Final' \n",
    "# and 'Longitude_Final' pairs\n",
    "Distinct_Coordinates = All_Routes.drop_duplicates(subset = ['Latitude_Final','Longitude_Final'])\n",
    "# In 'Distinct_Coordinates' add column 'Stop ID' with entries with format Stop_X where X is a value from 0 up to length of \n",
    "# 'Distinct_Coordinates' dataframe\n",
    "Distinct_Coordinates['Stop ID'] = [f'Stop_{i}' for i in range(len(Distinct_Coordinates))]\n",
    "\n",
    "# Create Dictionary entitled 'Bus_Stop_ID' consisting of corresponding 'Latitude_Final', 'Longitude_Final' and 'Stop ID' values \n",
    "Bus_Stop_ID = dict(\n",
    "    zip(\n",
    "        zip(Distinct_Coordinates['Latitude_Final'], Distinct_Coordinates['Longitude_Final']),\n",
    "        Distinct_Coordinates['Stop ID']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Using 'Bus_Stop_ID' dictionary label Bus Stops ('Stops') with their corresponding unique identifier.\n",
    "# Column is labelled as 'Bus_Stop_ID'\n",
    "# 4 - Using 'Bus_Stop_ID' dict to label All_Routes\n",
    "All_Routes['Bus_Stop_ID'] = All_Routes.apply(\n",
    "    lambda row: Bus_Stop_ID.get((row['Latitude_Final'], row['Longitude_Final']), None), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98178002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.6 - Create Column entitled 'Next_Bus_Stop_ID' consisting of the unique identifier of the upcoming stop in the route\n",
    "\n",
    "# Since All_Routes ('All_Routes_Complete.csv') was extracted in sequential order from MPT website, the next row in All_Routes\n",
    "# corresponds to the upcoming Bus Stop (Given 'Route Number', 'Route Direction' and 'Date' columns remain the same).\n",
    "# Hence, 'Reset_Conditions' is defined such that if any of 'Route Number', 'Route Direction' or 'Date' are different in\n",
    "# in the upcoming stop then upcoming stop than it is not considered to be a continuation of the current route.\n",
    "Reset_Conditions = (\n",
    "    All_Routes['Route Number'].shift(-1) != All_Routes['Route Number']) | \\\n",
    "    (All_Routes['Route Direction'].shift(-1) != All_Routes['Route Direction']) | \\\n",
    "    (All_Routes['Date'].shift(-1) != All_Routes['Date'])\n",
    "\n",
    "# In 'All_Routes' create column 'Next_Bus_Stop_ID' consisting of the upcoming 'Bus_Stop_ID'\n",
    "All_Routes['Next_Bus_Stop_ID'] = All_Routes['Bus_Stop_ID'].shift(-1)\n",
    "# If conditions defined in 'Reset_Conditions' are met, then 'Next_Bus_Stop_ID' should be blank\n",
    "All_Routes.loc[Reset_Conditions, 'Next_Bus_Stop_ID'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7841dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.7 - Create a Unique identifier used to define connection between 'Bus_Stop_ID and 'Next_Bus_Stop_ID. \n",
    "# This is done by concatinating the 'Bus_Stop_ID' and 'Next_Bus_Stop_ID' columns\n",
    "\n",
    "All_Routes['Bus_Stop_Next_Bus_Stop'] = All_Routes['Bus_Stop_ID'] + '_to_' + All_Routes['Next_Bus_Stop_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0085c75-4bd6-449e-b045-627746292af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Adjusting All_Routes\n",
    "\n",
    "# Step 2.1 - To simply our work we will not be considering the following routes:\n",
    "# Night Routes - Not interested in specific Routes designed to work beyond the scheduled service\n",
    "# Direct Routes - Not interested in routes which make use of specially designed shorter paths\n",
    "\n",
    "#Defining list of Night Routes and Tallinja Direct Routes (Obtained from: https://www.publictransport.com.mt/en/timetables)\n",
    "Night_Direct_Routes = ['N11', 'N13', 'N212', 'N62', 'N82',\n",
    "                       'N91', 'N48', 'N301', 'TD2', 'TD10',\n",
    "                       'TD13']\n",
    "\n",
    "All_Routes = All_Routes[~All_Routes['Route Number'].isin(Night_Direct_Routes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8477fe-a48a-47e1-9257-2c7970d832ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monday' 'Tuesday, Wednesday, Thursday, Friday' 'Saturday' 'Sunday'\n",
      " 'Monday, Tuesday, Wednesday, Thursday, Friday' 'Monday - Friday'\n",
      " 'Saturday, Sunday' 'Monday - Saturday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday, Sunday'\n",
      " 'Wednesday, Thursday, Friday, Tuesday' 'Wednesday, Thursday, Tuesday'\n",
      " 'Friday, Monday']\n"
     ]
    }
   ],
   "source": [
    "# Step 2.2 - Adjust Date names to ensure we are able to split dates accordingly\n",
    "\n",
    "# Obtain the Date Names utilised in 'All_Routes'\n",
    "# This is done since in certain 'Date' entries a hypen is utilised (Ex. 'Monday - Friday' significes 'Monday, Tuesday, Wednesday, Thursday, Friday'\n",
    "# All day names need to be represented in 'Date' field such that 'All_Routes' can be split into specific dates.\n",
    "Unique_Dates = All_Routes['Date'].unique()\n",
    "print(Unique_Dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29710480-31de-45f5-8a24-064c12b92dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2.2.1 - Changes to be made\n",
    "# 1 - Change 'Monday - Friday' to 'Monday, Tuesday, Wednesday, Thursday, Friday'\n",
    "# 2 - Change 'Monday - Sunday' to 'Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday'\n",
    "# 3 - Change 'Monday - Saturday' to 'Monday, Tuesday, Wednesday, Thursday, Firday, Saturday'\n",
    "All_Routes_Copy = All_Routes.copy()\n",
    "All_Routes_Copy['Date'] = All_Routes_Copy['Date'].replace({'Monday - Friday': 'Monday, Tuesday, Wednesday, Thursday, Friday',\n",
    "                                                           'Monday - Sunday': 'Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday',\n",
    "                                                           'Monday - Saturday': 'Monday, Tuesday, Wednesday, Thursday, Friday, Saturday'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab72da9-9e0b-4fee-a849-fad3c00c9725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monday' 'Tuesday, Wednesday, Thursday, Friday' 'Saturday' 'Sunday'\n",
      " 'Monday, Tuesday, Wednesday, Thursday, Friday' 'Monday - Friday'\n",
      " 'Saturday, Sunday' 'Monday - Saturday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday, Sunday'\n",
      " 'Wednesday, Thursday, Friday, Tuesday' 'Wednesday, Thursday, Tuesday'\n",
      " 'Friday, Monday']\n"
     ]
    }
   ],
   "source": [
    "# Step 2.2.2 - Check changes have been carried out accordingly\n",
    "Unique_Dates_FollowingUpdate = All_Routes['Date'].unique()\n",
    "print(Unique_Dates_FollowingUpdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4933972b-6f7a-4a3c-ad8b-947fe8f44cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route Number</th>\n",
       "      <th>Route Direction</th>\n",
       "      <th>Stops</th>\n",
       "      <th>City Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Stop Time 1</th>\n",
       "      <th>Stop Time 2</th>\n",
       "      <th>Stop Time 3</th>\n",
       "      <th>Stop Time 4</th>\n",
       "      <th>Stop Time 5</th>\n",
       "      <th>...</th>\n",
       "      <th>Stop Time 77</th>\n",
       "      <th>Stop Time 78</th>\n",
       "      <th>Stop Island</th>\n",
       "      <th>Time_Count</th>\n",
       "      <th>Stops - City Name - Stop Island</th>\n",
       "      <th>Longitude_Final</th>\n",
       "      <th>Latitude_Final</th>\n",
       "      <th>Bus_Stop_ID</th>\n",
       "      <th>Next_Bus_Stop_ID</th>\n",
       "      <th>Bus_Stop_Next_Bus_Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Ajruport - Cirkewwa</td>\n",
       "      <td>Airport 1</td>\n",
       "      <td>Hal Luqa</td>\n",
       "      <td>Monday</td>\n",
       "      <td>05:08</td>\n",
       "      <td>05:38</td>\n",
       "      <td>05:53</td>\n",
       "      <td>06:38</td>\n",
       "      <td>07:23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALTA STOP</td>\n",
       "      <td>26</td>\n",
       "      <td>Airport 1 - Hal Luqa - MALTA STOP</td>\n",
       "      <td>14.495967</td>\n",
       "      <td>35.849412</td>\n",
       "      <td>Stop_0</td>\n",
       "      <td>Stop_1</td>\n",
       "      <td>Stop_0_to_Stop_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X1</td>\n",
       "      <td>Ajruport - Cirkewwa</td>\n",
       "      <td>Avjazzjoni</td>\n",
       "      <td>Hal Luqa</td>\n",
       "      <td>Monday</td>\n",
       "      <td>05:09</td>\n",
       "      <td>05:39</td>\n",
       "      <td>05:54</td>\n",
       "      <td>06:40</td>\n",
       "      <td>07:25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALTA STOP</td>\n",
       "      <td>26</td>\n",
       "      <td>Avjazzjoni - Hal Luqa - MALTA STOP</td>\n",
       "      <td>14.492289</td>\n",
       "      <td>35.854831</td>\n",
       "      <td>Stop_1</td>\n",
       "      <td>Stop_2</td>\n",
       "      <td>Stop_1_to_Stop_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X1</td>\n",
       "      <td>Ajruport - Cirkewwa</td>\n",
       "      <td>Mitjar</td>\n",
       "      <td>Hal Luqa</td>\n",
       "      <td>Monday</td>\n",
       "      <td>05:10</td>\n",
       "      <td>05:40</td>\n",
       "      <td>05:55</td>\n",
       "      <td>06:41</td>\n",
       "      <td>07:26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALTA STOP</td>\n",
       "      <td>26</td>\n",
       "      <td>Mitjar - Hal Luqa - MALTA STOP</td>\n",
       "      <td>14.486949</td>\n",
       "      <td>35.855699</td>\n",
       "      <td>Stop_2</td>\n",
       "      <td>Stop_3</td>\n",
       "      <td>Stop_2_to_Stop_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X1</td>\n",
       "      <td>Ajruport - Cirkewwa</td>\n",
       "      <td>Ingieret</td>\n",
       "      <td>San Vincenz</td>\n",
       "      <td>Monday</td>\n",
       "      <td>05:14</td>\n",
       "      <td>05:45</td>\n",
       "      <td>06:00</td>\n",
       "      <td>06:47</td>\n",
       "      <td>07:32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALTA STOP</td>\n",
       "      <td>26</td>\n",
       "      <td>Ingieret - San Vincenz - MALTA STOP</td>\n",
       "      <td>14.482673</td>\n",
       "      <td>35.870979</td>\n",
       "      <td>Stop_3</td>\n",
       "      <td>Stop_4</td>\n",
       "      <td>Stop_3_to_Stop_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X1</td>\n",
       "      <td>Ajruport - Cirkewwa</td>\n",
       "      <td>Marsa Park &amp; Ride 1</td>\n",
       "      <td>Il-Marsa</td>\n",
       "      <td>Monday</td>\n",
       "      <td>05:18</td>\n",
       "      <td>05:48</td>\n",
       "      <td>06:03</td>\n",
       "      <td>06:51</td>\n",
       "      <td>07:36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALTA STOP</td>\n",
       "      <td>26</td>\n",
       "      <td>Marsa Park &amp; Ride 1 - Il-Marsa - MALTA STOP</td>\n",
       "      <td>14.484522</td>\n",
       "      <td>35.878715</td>\n",
       "      <td>Stop_4</td>\n",
       "      <td>Stop_5</td>\n",
       "      <td>Stop_4_to_Stop_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26528</th>\n",
       "      <td>330</td>\n",
       "      <td>Xlendi - Victoria</td>\n",
       "      <td>Ghajn</td>\n",
       "      <td>Il-Fontana, Ghawdex</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>09:45</td>\n",
       "      <td>11:45</td>\n",
       "      <td>13:45</td>\n",
       "      <td>15:45</td>\n",
       "      <td>17:45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOZO STOP</td>\n",
       "      <td>5</td>\n",
       "      <td>Ghajn - Il-Fontana, Ghawdex - GOZO STOP</td>\n",
       "      <td>14.234934</td>\n",
       "      <td>36.037018</td>\n",
       "      <td>Stop_1250</td>\n",
       "      <td>Stop_1251</td>\n",
       "      <td>Stop_1250_to_Stop_1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26529</th>\n",
       "      <td>330</td>\n",
       "      <td>Xlendi - Victoria</td>\n",
       "      <td>Parrokkjali</td>\n",
       "      <td>Il-Fontana, Ghawdex</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>09:46</td>\n",
       "      <td>11:46</td>\n",
       "      <td>13:46</td>\n",
       "      <td>15:46</td>\n",
       "      <td>17:46</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOZO STOP</td>\n",
       "      <td>5</td>\n",
       "      <td>Parrokkjali - Il-Fontana, Ghawdex - GOZO STOP</td>\n",
       "      <td>14.236993</td>\n",
       "      <td>36.039296</td>\n",
       "      <td>Stop_1251</td>\n",
       "      <td>Stop_1252</td>\n",
       "      <td>Stop_1251_to_Stop_1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26530</th>\n",
       "      <td>330</td>\n",
       "      <td>Xlendi - Victoria</td>\n",
       "      <td>Andar</td>\n",
       "      <td>Il-Fontana, Ghawdex</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>09:47</td>\n",
       "      <td>11:47</td>\n",
       "      <td>13:47</td>\n",
       "      <td>15:47</td>\n",
       "      <td>17:47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOZO STOP</td>\n",
       "      <td>5</td>\n",
       "      <td>Andar - Il-Fontana, Ghawdex - GOZO STOP</td>\n",
       "      <td>14.237107</td>\n",
       "      <td>36.040683</td>\n",
       "      <td>Stop_1252</td>\n",
       "      <td>Stop_1253</td>\n",
       "      <td>Stop_1252_to_Stop_1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26531</th>\n",
       "      <td>330</td>\n",
       "      <td>Xlendi - Victoria</td>\n",
       "      <td>Vincenzo</td>\n",
       "      <td>Il-Fontana, Ghawdex</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>09:47</td>\n",
       "      <td>11:47</td>\n",
       "      <td>13:47</td>\n",
       "      <td>15:47</td>\n",
       "      <td>17:47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOZO STOP</td>\n",
       "      <td>5</td>\n",
       "      <td>Vincenzo - Il-Fontana, Ghawdex - GOZO STOP</td>\n",
       "      <td>14.239928</td>\n",
       "      <td>36.040968</td>\n",
       "      <td>Stop_1253</td>\n",
       "      <td>Stop_1161</td>\n",
       "      <td>Stop_1253_to_Stop_1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26532</th>\n",
       "      <td>330</td>\n",
       "      <td>Xlendi - Victoria</td>\n",
       "      <td>Seminarju</td>\n",
       "      <td>Ir-Rabat, Ghawdex</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>09:48</td>\n",
       "      <td>11:48</td>\n",
       "      <td>13:48</td>\n",
       "      <td>15:48</td>\n",
       "      <td>17:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOZO STOP</td>\n",
       "      <td>5</td>\n",
       "      <td>Seminarju - Ir-Rabat, Ghawdex - GOZO STOP</td>\n",
       "      <td>14.240284</td>\n",
       "      <td>36.041517</td>\n",
       "      <td>Stop_1161</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25991 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Route Number      Route Direction                Stops  \\\n",
       "0               X1  Ajruport - Cirkewwa            Airport 1   \n",
       "1               X1  Ajruport - Cirkewwa           Avjazzjoni   \n",
       "2               X1  Ajruport - Cirkewwa               Mitjar   \n",
       "3               X1  Ajruport - Cirkewwa             Ingieret   \n",
       "4               X1  Ajruport - Cirkewwa  Marsa Park & Ride 1   \n",
       "...            ...                  ...                  ...   \n",
       "26528          330    Xlendi - Victoria                Ghajn   \n",
       "26529          330    Xlendi - Victoria          Parrokkjali   \n",
       "26530          330    Xlendi - Victoria                Andar   \n",
       "26531          330    Xlendi - Victoria             Vincenzo   \n",
       "26532          330    Xlendi - Victoria            Seminarju   \n",
       "\n",
       "                 City Name      Date Stop Time 1 Stop Time 2 Stop Time 3  \\\n",
       "0                 Hal Luqa    Monday       05:08       05:38       05:53   \n",
       "1                 Hal Luqa    Monday       05:09       05:39       05:54   \n",
       "2                 Hal Luqa    Monday       05:10       05:40       05:55   \n",
       "3              San Vincenz    Monday       05:14       05:45       06:00   \n",
       "4                 Il-Marsa    Monday       05:18       05:48       06:03   \n",
       "...                    ...       ...         ...         ...         ...   \n",
       "26528  Il-Fontana, Ghawdex  Saturday       09:45       11:45       13:45   \n",
       "26529  Il-Fontana, Ghawdex  Saturday       09:46       11:46       13:46   \n",
       "26530  Il-Fontana, Ghawdex  Saturday       09:47       11:47       13:47   \n",
       "26531  Il-Fontana, Ghawdex  Saturday       09:47       11:47       13:47   \n",
       "26532    Ir-Rabat, Ghawdex  Saturday       09:48       11:48       13:48   \n",
       "\n",
       "      Stop Time 4 Stop Time 5  ... Stop Time 77 Stop Time 78 Stop Island  \\\n",
       "0           06:38       07:23  ...          NaN          NaN  MALTA STOP   \n",
       "1           06:40       07:25  ...          NaN          NaN  MALTA STOP   \n",
       "2           06:41       07:26  ...          NaN          NaN  MALTA STOP   \n",
       "3           06:47       07:32  ...          NaN          NaN  MALTA STOP   \n",
       "4           06:51       07:36  ...          NaN          NaN  MALTA STOP   \n",
       "...           ...         ...  ...          ...          ...         ...   \n",
       "26528       15:45       17:45  ...          NaN          NaN   GOZO STOP   \n",
       "26529       15:46       17:46  ...          NaN          NaN   GOZO STOP   \n",
       "26530       15:47       17:47  ...          NaN          NaN   GOZO STOP   \n",
       "26531       15:47       17:47  ...          NaN          NaN   GOZO STOP   \n",
       "26532       15:48       17:48  ...          NaN          NaN   GOZO STOP   \n",
       "\n",
       "      Time_Count                Stops - City Name - Stop Island  \\\n",
       "0             26              Airport 1 - Hal Luqa - MALTA STOP   \n",
       "1             26             Avjazzjoni - Hal Luqa - MALTA STOP   \n",
       "2             26                 Mitjar - Hal Luqa - MALTA STOP   \n",
       "3             26            Ingieret - San Vincenz - MALTA STOP   \n",
       "4             26    Marsa Park & Ride 1 - Il-Marsa - MALTA STOP   \n",
       "...          ...                                            ...   \n",
       "26528          5        Ghajn - Il-Fontana, Ghawdex - GOZO STOP   \n",
       "26529          5  Parrokkjali - Il-Fontana, Ghawdex - GOZO STOP   \n",
       "26530          5        Andar - Il-Fontana, Ghawdex - GOZO STOP   \n",
       "26531          5     Vincenzo - Il-Fontana, Ghawdex - GOZO STOP   \n",
       "26532          5      Seminarju - Ir-Rabat, Ghawdex - GOZO STOP   \n",
       "\n",
       "      Longitude_Final Latitude_Final Bus_Stop_ID Next_Bus_Stop_ID  \\\n",
       "0           14.495967      35.849412      Stop_0           Stop_1   \n",
       "1           14.492289      35.854831      Stop_1           Stop_2   \n",
       "2           14.486949      35.855699      Stop_2           Stop_3   \n",
       "3           14.482673      35.870979      Stop_3           Stop_4   \n",
       "4           14.484522      35.878715      Stop_4           Stop_5   \n",
       "...               ...            ...         ...              ...   \n",
       "26528       14.234934      36.037018   Stop_1250        Stop_1251   \n",
       "26529       14.236993      36.039296   Stop_1251        Stop_1252   \n",
       "26530       14.237107      36.040683   Stop_1252        Stop_1253   \n",
       "26531       14.239928      36.040968   Stop_1253        Stop_1161   \n",
       "26532       14.240284      36.041517   Stop_1161             None   \n",
       "\n",
       "       Bus_Stop_Next_Bus_Stop  \n",
       "0            Stop_0_to_Stop_1  \n",
       "1            Stop_1_to_Stop_2  \n",
       "2            Stop_2_to_Stop_3  \n",
       "3            Stop_3_to_Stop_4  \n",
       "4            Stop_4_to_Stop_5  \n",
       "...                       ...  \n",
       "26528  Stop_1250_to_Stop_1251  \n",
       "26529  Stop_1251_to_Stop_1252  \n",
       "26530  Stop_1252_to_Stop_1253  \n",
       "26531  Stop_1253_to_Stop_1161  \n",
       "26532                     NaN  \n",
       "\n",
       "[25991 rows x 91 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Routes_Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f28ec5-2606-4d62-a503-09d415bdc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1 - A DataFrame entitled 'Distinct_Edges' is created which considers entries in the 'All_Routes' DataFrame with unique entries in \n",
    "# 'Bus_Stop_Next_Bus_Stop' column\n",
    "Distinct_Edges = All_Routes_Copy.drop_duplicates(subset = ['Bus_Stop_Next_Bus_Stop'])\n",
    "# Index is reset due to removal of entries in 'All_Routes'\n",
    "Distinct_Edges = Distinct_Edges.reset_index(drop=True)\n",
    "# Creating Copy of 'Distinct_Edges' DataFrame entitled 'Distinct_Edges_2' (s.t. any changes made in 'Distinct_Edges_2' does not impact the original\n",
    "# DataFrame\n",
    "Distinct_Edges_2 = Distinct_Edges.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d9e9e06-4097-4f24-be49-a5e5bdb49eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distinct_Edges_2 = pd.merge(Distinct_Edges_2, Distinct_Edges_2[['Bus_Stop_ID', 'Longitude_Final', 'Latitude_Final']].drop_duplicates(subset=['Bus_Stop_ID']), left_on = 'Next_Bus_Stop_ID', right_on = 'Bus_Stop_ID', how = 'left', sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6afae94-49e8-447d-871d-950ff1acfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distinct_Edges_2 = Distinct_Edges_2.rename(columns={'Bus_Stop_ID_x': 'Bus_Stop_ID','Longitude_Final_x': 'Longitude_Final', 'Latitude_Final_x': 'Latitude_Final',\n",
    "                                                   'Longitude_Final_y': 'Longitude_Next', 'Latitude_Final_y': 'Latitude_Next'})\n",
    "Distinct_Edges_2 = Distinct_Edges_2.drop(columns = 'Bus_Stop_ID_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c4fcfea-95d7-4f16-9f9d-cc279e1e87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.3 - Free Version of TomTom API only Allows for 2500 Non-Tile Requests per-day. The entire datasets would require 2543 requests to complete.\n",
    "# As a result, the 'Distinc_Edges_2' Dataset will be split into two using the 'Stop Island' column. Following DataFrames are obtained:\n",
    "# 1 - Distinct_Edges_MALTA - Includes all entries in 'Distinct_Edges_2' where 'Stop Island' column has entries 'MALTA STOP'\n",
    "# 2 - Distinct_Edges_GOZO - Includes all entries in 'Distinct_Edges_2' where 'Stop Island' column has entries 'GOZO STOP'\n",
    "Distinct_Edges_MALTA = Distinct_Edges_2.loc[Distinct_Edges_2[\"Stop Island\"] == \"MALTA STOP\"]\n",
    "Distinct_Edges_GOZO = Distinct_Edges_2.loc[Distinct_Edges_2[\"Stop Island\"] == \"GOZO STOP\"]\n",
    "# Since file is obtained sequentially (Gozo routes are listed last in the MPT Website (https://www.publictransport.com.mt/en/timetables)\n",
    "# Then index is reset for 'Distinct_Edges_Gozo' to ensure for loops utilised will work correctly\n",
    "Distinct_Edges_GOZO = Distinct_Edges_GOZO.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78164687-adc6-4cea-a517-7ecce85f665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ef161b-e4ce-4e43-893a-7d98d682d2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing request 1 of 2118\n",
      "Processing request 2 of 2118\n",
      "Processing request 3 of 2118\n",
      "Processing request 4 of 2118\n",
      "Processing request 5 of 2118\n",
      "Processing request 6 of 2118\n",
      "Processing request 7 of 2118\n",
      "Processing request 8 of 2118\n",
      "Processing request 9 of 2118\n",
      "Processing request 10 of 2118\n",
      "Processing request 11 of 2118\n",
      "Processing request 12 of 2118\n",
      "Processing request 13 of 2118\n",
      "Processing request 14 of 2118\n",
      "Processing request 15 of 2118\n",
      "Processing request 16 of 2118\n",
      "Processing request 17 of 2118\n",
      "Processing request 18 of 2118\n",
      "Processing request 19 of 2118\n",
      "Processing request 20 of 2118\n",
      "Processing request 21 of 2118\n",
      "Processing request 22 of 2118\n",
      "Processing request 23 of 2118\n",
      "Processing request 24 of 2118\n",
      "Error: HTTP 400 - {\"formatVersion\":\"0.0.12\",\"detailedError\":{\"message\":\"Invalid request: malformed coordinate at index [1]: [nan,nan]\",\"code\":\"BAD_INPUT\"}}\n",
      "Processing request 25 of 2118\n",
      "Processing request 26 of 2118\n",
      "Processing request 27 of 2118\n",
      "Processing request 28 of 2118\n",
      "Processing request 29 of 2118\n",
      "Processing request 30 of 2118\n",
      "Processing request 31 of 2118\n",
      "Processing request 32 of 2118\n",
      "Processing request 33 of 2118\n",
      "Processing request 34 of 2118\n",
      "Processing request 35 of 2118\n",
      "Processing request 36 of 2118\n",
      "Processing request 37 of 2118\n",
      "Processing request 38 of 2118\n",
      "Processing request 39 of 2118\n",
      "Processing request 40 of 2118\n",
      "Processing request 41 of 2118\n",
      "Processing request 42 of 2118\n",
      "Processing request 43 of 2118\n",
      "Processing request 44 of 2118\n",
      "Processing request 45 of 2118\n",
      "Processing request 46 of 2118\n",
      "Processing request 47 of 2118\n",
      "Processing request 48 of 2118\n",
      "Processing request 49 of 2118\n",
      "Processing request 50 of 2118\n",
      "Processing request 51 of 2118\n",
      "Processing request 52 of 2118\n",
      "Processing request 53 of 2118\n",
      "Processing request 54 of 2118\n",
      "Processing request 55 of 2118\n",
      "Processing request 56 of 2118\n",
      "Processing request 57 of 2118\n",
      "Processing request 58 of 2118\n",
      "Processing request 59 of 2118\n",
      "Processing request 60 of 2118\n",
      "Processing request 61 of 2118\n",
      "Processing request 62 of 2118\n",
      "Processing request 63 of 2118\n",
      "Processing request 64 of 2118\n",
      "Processing request 65 of 2118\n",
      "Processing request 66 of 2118\n",
      "Processing request 67 of 2118\n",
      "Processing request 68 of 2118\n",
      "Processing request 69 of 2118\n",
      "Processing request 70 of 2118\n",
      "Processing request 71 of 2118\n",
      "Processing request 72 of 2118\n",
      "Processing request 73 of 2118\n",
      "Processing request 74 of 2118\n",
      "Processing request 75 of 2118\n",
      "Processing request 76 of 2118\n",
      "Processing request 77 of 2118\n",
      "Processing request 78 of 2118\n",
      "Processing request 79 of 2118\n",
      "Processing request 80 of 2118\n",
      "Processing request 81 of 2118\n",
      "Processing request 82 of 2118\n",
      "Processing request 83 of 2118\n",
      "Processing request 84 of 2118\n",
      "Processing request 85 of 2118\n",
      "Processing request 86 of 2118\n",
      "Processing request 87 of 2118\n",
      "Processing request 88 of 2118\n",
      "Processing request 89 of 2118\n",
      "Processing request 90 of 2118\n",
      "Processing request 91 of 2118\n",
      "Processing request 92 of 2118\n",
      "Processing request 93 of 2118\n",
      "Processing request 94 of 2118\n",
      "Processing request 95 of 2118\n",
      "Processing request 96 of 2118\n",
      "Processing request 97 of 2118\n",
      "Processing request 98 of 2118\n",
      "Processing request 99 of 2118\n",
      "Processing request 100 of 2118\n",
      "Processing request 101 of 2118\n",
      "Processing request 102 of 2118\n",
      "Processing request 103 of 2118\n",
      "Processing request 104 of 2118\n",
      "Processing request 105 of 2118\n",
      "Processing request 106 of 2118\n",
      "Processing request 107 of 2118\n",
      "Processing request 108 of 2118\n",
      "Processing request 109 of 2118\n",
      "Processing request 110 of 2118\n",
      "Processing request 111 of 2118\n",
      "Processing request 112 of 2118\n",
      "Processing request 113 of 2118\n",
      "Processing request 114 of 2118\n",
      "Processing request 115 of 2118\n",
      "Processing request 116 of 2118\n",
      "Processing request 117 of 2118\n",
      "Processing request 118 of 2118\n",
      "Processing request 119 of 2118\n",
      "Processing request 120 of 2118\n",
      "Processing request 121 of 2118\n",
      "Processing request 122 of 2118\n",
      "Processing request 123 of 2118\n",
      "Processing request 124 of 2118\n",
      "Processing request 125 of 2118\n",
      "Processing request 126 of 2118\n",
      "Processing request 127 of 2118\n",
      "Processing request 128 of 2118\n",
      "Processing request 129 of 2118\n",
      "Processing request 130 of 2118\n",
      "Processing request 131 of 2118\n",
      "Processing request 132 of 2118\n",
      "Processing request 133 of 2118\n",
      "Processing request 134 of 2118\n",
      "Processing request 135 of 2118\n",
      "Processing request 136 of 2118\n",
      "Processing request 137 of 2118\n",
      "Processing request 138 of 2118\n",
      "Processing request 139 of 2118\n",
      "Processing request 140 of 2118\n",
      "Processing request 141 of 2118\n",
      "Processing request 142 of 2118\n",
      "Processing request 143 of 2118\n",
      "Processing request 144 of 2118\n",
      "Processing request 145 of 2118\n",
      "Processing request 146 of 2118\n",
      "Processing request 147 of 2118\n",
      "Processing request 148 of 2118\n",
      "Processing request 149 of 2118\n",
      "Processing request 150 of 2118\n",
      "Processing request 151 of 2118\n",
      "Processing request 152 of 2118\n",
      "Processing request 153 of 2118\n",
      "Processing request 154 of 2118\n",
      "Processing request 155 of 2118\n",
      "Processing request 156 of 2118\n",
      "Processing request 157 of 2118\n",
      "Processing request 158 of 2118\n",
      "Processing request 159 of 2118\n",
      "Processing request 160 of 2118\n",
      "Processing request 161 of 2118\n",
      "Processing request 162 of 2118\n",
      "Processing request 163 of 2118\n",
      "Processing request 164 of 2118\n",
      "Processing request 165 of 2118\n",
      "Processing request 166 of 2118\n",
      "Processing request 167 of 2118\n",
      "Processing request 168 of 2118\n",
      "Processing request 169 of 2118\n",
      "Processing request 170 of 2118\n",
      "Processing request 171 of 2118\n",
      "Processing request 172 of 2118\n",
      "Processing request 173 of 2118\n",
      "Processing request 174 of 2118\n",
      "Processing request 175 of 2118\n",
      "Processing request 176 of 2118\n",
      "Processing request 177 of 2118\n",
      "Processing request 178 of 2118\n",
      "Processing request 179 of 2118\n",
      "Processing request 180 of 2118\n",
      "Processing request 181 of 2118\n",
      "Processing request 182 of 2118\n",
      "Processing request 183 of 2118\n",
      "Processing request 184 of 2118\n",
      "Processing request 185 of 2118\n",
      "Processing request 186 of 2118\n",
      "Processing request 187 of 2118\n",
      "Processing request 188 of 2118\n",
      "Processing request 189 of 2118\n",
      "Processing request 190 of 2118\n",
      "Processing request 191 of 2118\n",
      "Processing request 192 of 2118\n",
      "Processing request 193 of 2118\n",
      "Processing request 194 of 2118\n",
      "Processing request 195 of 2118\n",
      "Processing request 196 of 2118\n",
      "Processing request 197 of 2118\n",
      "Processing request 198 of 2118\n",
      "Processing request 199 of 2118\n",
      "Processing request 200 of 2118\n",
      "Processing request 201 of 2118\n",
      "Processing request 202 of 2118\n",
      "Processing request 203 of 2118\n",
      "Processing request 204 of 2118\n",
      "Processing request 205 of 2118\n",
      "Processing request 206 of 2118\n",
      "Processing request 207 of 2118\n",
      "Processing request 208 of 2118\n",
      "Processing request 209 of 2118\n",
      "Processing request 210 of 2118\n",
      "Processing request 211 of 2118\n",
      "Processing request 212 of 2118\n",
      "Processing request 213 of 2118\n",
      "Processing request 214 of 2118\n",
      "Processing request 215 of 2118\n",
      "Processing request 216 of 2118\n",
      "Processing request 217 of 2118\n",
      "Processing request 218 of 2118\n",
      "Processing request 219 of 2118\n",
      "Processing request 220 of 2118\n",
      "Processing request 221 of 2118\n",
      "Processing request 222 of 2118\n",
      "Processing request 223 of 2118\n",
      "Processing request 224 of 2118\n",
      "Error: HTTP 400 - {\"formatVersion\":\"0.0.12\",\"detailedError\":{\"message\":\"Invalid request: malformed coordinate at index [1]: [nan,nan]\",\"code\":\"BAD_INPUT\"}}\n",
      "Processing request 225 of 2118\n",
      "Processing request 226 of 2118\n",
      "Processing request 227 of 2118\n",
      "Processing request 228 of 2118\n",
      "Processing request 229 of 2118\n",
      "Processing request 230 of 2118\n",
      "Processing request 231 of 2118\n",
      "Processing request 232 of 2118\n",
      "Processing request 233 of 2118\n",
      "Processing request 234 of 2118\n",
      "Processing request 235 of 2118\n",
      "Processing request 236 of 2118\n",
      "Processing request 237 of 2118\n",
      "Processing request 238 of 2118\n",
      "Processing request 239 of 2118\n",
      "Processing request 240 of 2118\n",
      "Processing request 241 of 2118\n",
      "Processing request 242 of 2118\n",
      "Processing request 243 of 2118\n",
      "Processing request 244 of 2118\n",
      "Processing request 245 of 2118\n",
      "Processing request 246 of 2118\n",
      "Processing request 247 of 2118\n",
      "Processing request 248 of 2118\n",
      "Processing request 249 of 2118\n",
      "Processing request 250 of 2118\n",
      "Processing request 251 of 2118\n",
      "Processing request 252 of 2118\n",
      "Processing request 253 of 2118\n",
      "Processing request 254 of 2118\n",
      "Processing request 255 of 2118\n",
      "Processing request 256 of 2118\n",
      "Processing request 257 of 2118\n",
      "Processing request 258 of 2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing request 259 of 2118\n",
      "Processing request 260 of 2118\n",
      "Processing request 261 of 2118\n",
      "Processing request 262 of 2118\n",
      "Processing request 263 of 2118\n",
      "Processing request 264 of 2118\n",
      "Processing request 265 of 2118\n",
      "Processing request 266 of 2118\n",
      "Processing request 267 of 2118\n",
      "Processing request 268 of 2118\n",
      "Processing request 269 of 2118\n",
      "Processing request 270 of 2118\n",
      "Processing request 271 of 2118\n",
      "Processing request 272 of 2118\n",
      "Processing request 273 of 2118\n",
      "Processing request 274 of 2118\n",
      "Processing request 275 of 2118\n",
      "Processing request 276 of 2118\n",
      "Processing request 277 of 2118\n",
      "Processing request 278 of 2118\n",
      "Processing request 279 of 2118\n",
      "Processing request 280 of 2118\n",
      "Processing request 281 of 2118\n",
      "Processing request 282 of 2118\n",
      "Processing request 283 of 2118\n",
      "Processing request 284 of 2118\n",
      "Processing request 285 of 2118\n",
      "Error: HTTP 400 - {\"formatVersion\":\"0.0.12\",\"detailedError\":{\"message\":\"Invalid request: malformed coordinate at index [1]: [nan,nan]\",\"code\":\"BAD_INPUT\"}}\n",
      "Processing request 286 of 2118\n",
      "Processing request 287 of 2118\n",
      "Processing request 288 of 2118\n",
      "Processing request 289 of 2118\n",
      "Processing request 290 of 2118\n",
      "Processing request 291 of 2118\n",
      "Processing request 292 of 2118\n",
      "Processing request 293 of 2118\n",
      "Processing request 294 of 2118\n",
      "Processing request 295 of 2118\n",
      "Processing request 296 of 2118\n",
      "Processing request 297 of 2118\n",
      "Processing request 298 of 2118\n",
      "Processing request 299 of 2118\n",
      "Processing request 300 of 2118\n",
      "Processing request 301 of 2118\n",
      "Processing request 302 of 2118\n",
      "Processing request 303 of 2118\n",
      "Processing request 304 of 2118\n",
      "Processing request 305 of 2118\n",
      "Processing request 306 of 2118\n",
      "Processing request 307 of 2118\n",
      "Processing request 308 of 2118\n",
      "Processing request 309 of 2118\n",
      "Processing request 310 of 2118\n",
      "Processing request 311 of 2118\n",
      "Processing request 312 of 2118\n",
      "Processing request 313 of 2118\n",
      "Processing request 314 of 2118\n",
      "Processing request 315 of 2118\n",
      "Processing request 316 of 2118\n",
      "Processing request 317 of 2118\n",
      "Processing request 318 of 2118\n",
      "Processing request 319 of 2118\n",
      "Processing request 320 of 2118\n",
      "Processing request 321 of 2118\n",
      "Processing request 322 of 2118\n",
      "Processing request 323 of 2118\n",
      "Processing request 324 of 2118\n",
      "Processing request 325 of 2118\n",
      "Processing request 326 of 2118\n",
      "Processing request 327 of 2118\n",
      "Processing request 328 of 2118\n",
      "Processing request 329 of 2118\n",
      "Processing request 330 of 2118\n",
      "Processing request 331 of 2118\n",
      "Processing request 332 of 2118\n",
      "Processing request 333 of 2118\n",
      "Processing request 334 of 2118\n",
      "Processing request 335 of 2118\n",
      "Processing request 336 of 2118\n",
      "Processing request 337 of 2118\n",
      "Processing request 338 of 2118\n",
      "Processing request 339 of 2118\n",
      "Processing request 340 of 2118\n",
      "Processing request 341 of 2118\n",
      "Processing request 342 of 2118\n",
      "Processing request 343 of 2118\n",
      "Processing request 344 of 2118\n",
      "Processing request 345 of 2118\n",
      "Processing request 346 of 2118\n",
      "Processing request 347 of 2118\n",
      "Processing request 348 of 2118\n",
      "Processing request 349 of 2118\n",
      "Processing request 350 of 2118\n",
      "Processing request 351 of 2118\n",
      "Processing request 352 of 2118\n",
      "Processing request 353 of 2118\n",
      "Processing request 354 of 2118\n",
      "Processing request 355 of 2118\n",
      "Processing request 356 of 2118\n",
      "Processing request 357 of 2118\n",
      "Processing request 358 of 2118\n",
      "Processing request 359 of 2118\n",
      "Processing request 360 of 2118\n",
      "Processing request 361 of 2118\n",
      "Processing request 362 of 2118\n",
      "Processing request 363 of 2118\n",
      "Processing request 364 of 2118\n",
      "Processing request 365 of 2118\n",
      "Processing request 366 of 2118\n",
      "Processing request 367 of 2118\n",
      "Processing request 368 of 2118\n",
      "Processing request 369 of 2118\n",
      "Processing request 370 of 2118\n",
      "Processing request 371 of 2118\n",
      "Processing request 372 of 2118\n",
      "Processing request 373 of 2118\n",
      "Processing request 374 of 2118\n",
      "Processing request 375 of 2118\n",
      "Processing request 376 of 2118\n",
      "Processing request 377 of 2118\n",
      "Processing request 378 of 2118\n",
      "Processing request 379 of 2118\n",
      "Processing request 380 of 2118\n",
      "Processing request 381 of 2118\n",
      "Processing request 382 of 2118\n",
      "Processing request 383 of 2118\n",
      "Processing request 384 of 2118\n",
      "Processing request 385 of 2118\n",
      "Processing request 386 of 2118\n",
      "Processing request 387 of 2118\n",
      "Processing request 388 of 2118\n",
      "Processing request 389 of 2118\n",
      "Processing request 390 of 2118\n",
      "Processing request 391 of 2118\n",
      "Processing request 392 of 2118\n",
      "Processing request 393 of 2118\n",
      "Processing request 394 of 2118\n",
      "Processing request 395 of 2118\n",
      "Processing request 396 of 2118\n",
      "Processing request 397 of 2118\n",
      "Processing request 398 of 2118\n",
      "Processing request 399 of 2118\n",
      "Processing request 400 of 2118\n",
      "Processing request 401 of 2118\n",
      "Processing request 402 of 2118\n",
      "Processing request 403 of 2118\n",
      "Processing request 404 of 2118\n",
      "Processing request 405 of 2118\n",
      "Processing request 406 of 2118\n",
      "Processing request 407 of 2118\n",
      "Processing request 408 of 2118\n",
      "Processing request 409 of 2118\n",
      "Processing request 410 of 2118\n",
      "Processing request 411 of 2118\n",
      "Processing request 412 of 2118\n",
      "Processing request 413 of 2118\n",
      "Processing request 414 of 2118\n",
      "Processing request 415 of 2118\n",
      "Processing request 416 of 2118\n",
      "Processing request 417 of 2118\n",
      "Processing request 418 of 2118\n",
      "Processing request 419 of 2118\n",
      "Processing request 420 of 2118\n",
      "Processing request 421 of 2118\n",
      "Processing request 422 of 2118\n",
      "Processing request 423 of 2118\n",
      "Processing request 424 of 2118\n",
      "Processing request 425 of 2118\n",
      "Processing request 426 of 2118\n",
      "Processing request 427 of 2118\n",
      "Processing request 428 of 2118\n",
      "Processing request 429 of 2118\n",
      "Processing request 430 of 2118\n",
      "Processing request 431 of 2118\n",
      "Processing request 432 of 2118\n",
      "Processing request 433 of 2118\n",
      "Processing request 434 of 2118\n",
      "Processing request 435 of 2118\n",
      "Processing request 436 of 2118\n",
      "Processing request 437 of 2118\n",
      "Processing request 438 of 2118\n",
      "Processing request 439 of 2118\n",
      "Processing request 440 of 2118\n",
      "Processing request 441 of 2118\n",
      "Processing request 442 of 2118\n",
      "Processing request 443 of 2118\n",
      "Processing request 444 of 2118\n",
      "Processing request 445 of 2118\n",
      "Processing request 446 of 2118\n",
      "Processing request 447 of 2118\n",
      "Processing request 448 of 2118\n",
      "Processing request 449 of 2118\n",
      "Error: HTTP 400 - {\"formatVersion\":\"0.0.12\",\"detailedError\":{\"message\":\"Invalid request: malformed coordinate at index [1]: [nan,nan]\",\"code\":\"BAD_INPUT\"}}\n",
      "Processing request 450 of 2118\n",
      "Processing request 451 of 2118\n",
      "Processing request 452 of 2118\n",
      "Processing request 453 of 2118\n",
      "Processing request 454 of 2118\n",
      "Processing request 455 of 2118\n",
      "Processing request 456 of 2118\n",
      "Processing request 457 of 2118\n",
      "Processing request 458 of 2118\n",
      "Processing request 459 of 2118\n",
      "Processing request 460 of 2118\n",
      "Processing request 461 of 2118\n",
      "Processing request 462 of 2118\n",
      "Processing request 463 of 2118\n",
      "Processing request 464 of 2118\n",
      "Processing request 465 of 2118\n",
      "Processing request 466 of 2118\n",
      "Processing request 467 of 2118\n",
      "Processing request 468 of 2118\n",
      "Processing request 469 of 2118\n",
      "Processing request 470 of 2118\n",
      "Processing request 471 of 2118\n",
      "Processing request 472 of 2118\n",
      "Processing request 473 of 2118\n",
      "Processing request 474 of 2118\n",
      "Processing request 475 of 2118\n",
      "Processing request 476 of 2118\n",
      "Processing request 477 of 2118\n",
      "Processing request 478 of 2118\n",
      "Processing request 479 of 2118\n",
      "Processing request 480 of 2118\n",
      "Processing request 481 of 2118\n",
      "Processing request 482 of 2118\n",
      "Processing request 483 of 2118\n",
      "Processing request 484 of 2118\n",
      "Processing request 485 of 2118\n",
      "Processing request 486 of 2118\n",
      "Processing request 487 of 2118\n",
      "Processing request 488 of 2118\n",
      "Processing request 489 of 2118\n",
      "Processing request 490 of 2118\n",
      "Processing request 491 of 2118\n",
      "Processing request 492 of 2118\n",
      "Processing request 493 of 2118\n",
      "Processing request 494 of 2118\n",
      "Processing request 495 of 2118\n",
      "Processing request 496 of 2118\n",
      "Processing request 497 of 2118\n",
      "Processing request 498 of 2118\n",
      "Processing request 499 of 2118\n",
      "Processing request 500 of 2118\n",
      "Processing request 501 of 2118\n",
      "Processing request 502 of 2118\n",
      "Processing request 503 of 2118\n",
      "Processing request 504 of 2118\n",
      "Processing request 505 of 2118\n",
      "Processing request 506 of 2118\n",
      "Processing request 507 of 2118\n",
      "Processing request 508 of 2118\n",
      "Processing request 509 of 2118\n",
      "Processing request 510 of 2118\n",
      "Processing request 511 of 2118\n",
      "Processing request 512 of 2118\n",
      "Processing request 513 of 2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing request 514 of 2118\n",
      "Processing request 515 of 2118\n",
      "Processing request 516 of 2118\n",
      "Processing request 517 of 2118\n",
      "Processing request 518 of 2118\n",
      "Processing request 519 of 2118\n",
      "Processing request 520 of 2118\n",
      "Processing request 521 of 2118\n",
      "Processing request 522 of 2118\n",
      "Processing request 523 of 2118\n",
      "Processing request 524 of 2118\n",
      "Processing request 525 of 2118\n",
      "Processing request 526 of 2118\n",
      "Processing request 527 of 2118\n",
      "Processing request 528 of 2118\n",
      "Processing request 529 of 2118\n",
      "Processing request 530 of 2118\n",
      "Processing request 531 of 2118\n",
      "Processing request 532 of 2118\n",
      "Processing request 533 of 2118\n",
      "Processing request 534 of 2118\n",
      "Processing request 535 of 2118\n",
      "Processing request 536 of 2118\n",
      "Processing request 537 of 2118\n",
      "Processing request 538 of 2118\n",
      "Processing request 539 of 2118\n",
      "Processing request 540 of 2118\n",
      "Processing request 541 of 2118\n",
      "Processing request 542 of 2118\n",
      "Processing request 543 of 2118\n",
      "Processing request 544 of 2118\n",
      "Processing request 545 of 2118\n",
      "Processing request 546 of 2118\n",
      "Processing request 547 of 2118\n",
      "Processing request 548 of 2118\n",
      "Processing request 549 of 2118\n",
      "Processing request 550 of 2118\n",
      "Processing request 551 of 2118\n",
      "Processing request 552 of 2118\n",
      "Processing request 553 of 2118\n",
      "Processing request 554 of 2118\n",
      "Processing request 555 of 2118\n",
      "Processing request 556 of 2118\n",
      "Processing request 557 of 2118\n",
      "Processing request 558 of 2118\n",
      "Processing request 559 of 2118\n",
      "Processing request 560 of 2118\n",
      "Processing request 561 of 2118\n",
      "Processing request 562 of 2118\n",
      "Processing request 563 of 2118\n",
      "Processing request 564 of 2118\n",
      "Processing request 565 of 2118\n",
      "Processing request 566 of 2118\n",
      "Processing request 567 of 2118\n",
      "Processing request 568 of 2118\n",
      "Processing request 569 of 2118\n",
      "Processing request 570 of 2118\n",
      "Processing request 571 of 2118\n",
      "Processing request 572 of 2118\n",
      "Processing request 573 of 2118\n",
      "Processing request 574 of 2118\n",
      "Processing request 575 of 2118\n",
      "Processing request 576 of 2118\n",
      "Processing request 577 of 2118\n",
      "Processing request 578 of 2118\n",
      "Processing request 579 of 2118\n",
      "Processing request 580 of 2118\n",
      "Processing request 581 of 2118\n",
      "Processing request 582 of 2118\n",
      "Processing request 583 of 2118\n",
      "Processing request 584 of 2118\n",
      "Processing request 585 of 2118\n",
      "Processing request 586 of 2118\n",
      "Processing request 587 of 2118\n",
      "Processing request 588 of 2118\n",
      "Processing request 589 of 2118\n",
      "Processing request 590 of 2118\n",
      "Processing request 591 of 2118\n",
      "Processing request 592 of 2118\n",
      "Processing request 593 of 2118\n",
      "Processing request 594 of 2118\n",
      "Processing request 595 of 2118\n",
      "Processing request 596 of 2118\n",
      "Processing request 597 of 2118\n",
      "Processing request 598 of 2118\n",
      "Processing request 599 of 2118\n",
      "Processing request 600 of 2118\n",
      "Processing request 601 of 2118\n",
      "Processing request 602 of 2118\n",
      "Processing request 603 of 2118\n",
      "Processing request 604 of 2118\n",
      "Processing request 605 of 2118\n",
      "Processing request 606 of 2118\n",
      "Processing request 607 of 2118\n",
      "Processing request 608 of 2118\n",
      "Processing request 609 of 2118\n",
      "Processing request 610 of 2118\n",
      "Processing request 611 of 2118\n",
      "Processing request 612 of 2118\n",
      "Processing request 613 of 2118\n",
      "Processing request 614 of 2118\n",
      "Processing request 615 of 2118\n",
      "Processing request 616 of 2118\n",
      "Processing request 617 of 2118\n",
      "Processing request 618 of 2118\n",
      "Processing request 619 of 2118\n",
      "Processing request 620 of 2118\n",
      "Processing request 621 of 2118\n",
      "Processing request 622 of 2118\n",
      "Processing request 623 of 2118\n",
      "Processing request 624 of 2118\n",
      "Processing request 625 of 2118\n",
      "Processing request 626 of 2118\n",
      "Processing request 627 of 2118\n",
      "Processing request 628 of 2118\n",
      "Processing request 629 of 2118\n",
      "Processing request 630 of 2118\n",
      "Processing request 631 of 2118\n",
      "Processing request 632 of 2118\n",
      "Processing request 633 of 2118\n",
      "Processing request 634 of 2118\n",
      "Processing request 635 of 2118\n",
      "Processing request 636 of 2118\n",
      "Processing request 637 of 2118\n",
      "Processing request 638 of 2118\n",
      "Processing request 639 of 2118\n",
      "Processing request 640 of 2118\n",
      "Processing request 641 of 2118\n",
      "Processing request 642 of 2118\n",
      "Processing request 643 of 2118\n",
      "Processing request 644 of 2118\n",
      "Processing request 645 of 2118\n",
      "Processing request 646 of 2118\n",
      "Processing request 647 of 2118\n",
      "Processing request 648 of 2118\n",
      "Processing request 649 of 2118\n",
      "Processing request 650 of 2118\n",
      "Processing request 651 of 2118\n",
      "Processing request 652 of 2118\n",
      "Processing request 653 of 2118\n",
      "Processing request 654 of 2118\n",
      "Processing request 655 of 2118\n",
      "Processing request 656 of 2118\n",
      "Processing request 657 of 2118\n",
      "Processing request 658 of 2118\n",
      "Processing request 659 of 2118\n",
      "Processing request 660 of 2118\n",
      "Processing request 661 of 2118\n",
      "Processing request 662 of 2118\n",
      "Processing request 663 of 2118\n",
      "Processing request 664 of 2118\n",
      "Processing request 665 of 2118\n",
      "Processing request 666 of 2118\n",
      "Processing request 667 of 2118\n",
      "Processing request 668 of 2118\n",
      "Processing request 669 of 2118\n",
      "Processing request 670 of 2118\n",
      "Processing request 671 of 2118\n",
      "Processing request 672 of 2118\n",
      "Processing request 673 of 2118\n",
      "Processing request 674 of 2118\n",
      "Processing request 675 of 2118\n",
      "Processing request 676 of 2118\n",
      "Processing request 677 of 2118\n",
      "Processing request 678 of 2118\n",
      "Processing request 679 of 2118\n",
      "Processing request 680 of 2118\n",
      "Processing request 681 of 2118\n",
      "Processing request 682 of 2118\n",
      "Processing request 683 of 2118\n",
      "Processing request 684 of 2118\n",
      "Processing request 685 of 2118\n",
      "Processing request 686 of 2118\n",
      "Processing request 687 of 2118\n",
      "Processing request 688 of 2118\n",
      "Processing request 689 of 2118\n",
      "Processing request 690 of 2118\n",
      "Processing request 691 of 2118\n",
      "Processing request 692 of 2118\n",
      "Processing request 693 of 2118\n",
      "Processing request 694 of 2118\n",
      "Processing request 695 of 2118\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.tomtom.com', port=443): Max retries exceeded with url: /routing/1/calculateRoute/35.9473111%2C14.3931026%3A35.9462932%2C14.3904814/json?maxAlternatives=1&computeTravelTimeFor=all&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key=uA2d36BEe5Xby9As7hUgrBmGL34u4n0h (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002458B8BDAF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000002458B8BDAF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.tomtom.com', port=443): Max retries exceeded with url: /routing/1/calculateRoute/35.9473111%2C14.3931026%3A35.9462932%2C14.3904814/json?maxAlternatives=1&computeTravelTimeFor=all&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key=uA2d36BEe5Xby9As7hUgrBmGL34u4n0h (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002458B8BDAF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing request \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(Distinct_Edges_MALTA)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.tomtom.com/routing/1/calculateRoute/\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3A\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C\u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m/json?maxAlternatives=1&computeTravelTimeFor=all&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key=\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(Distinct_Edges_MALTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude_Final\u001b[39m\u001b[38;5;124m'\u001b[39m][i], Distinct_Edges_MALTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude_Final\u001b[39m\u001b[38;5;124m'\u001b[39m][i], Distinct_Edges_MALTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude_Next\u001b[39m\u001b[38;5;124m'\u001b[39m][i], Distinct_Edges_MALTA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude_Next\u001b[39m\u001b[38;5;124m'\u001b[39m][i], TOMTOM_API_Key)\n\u001b[1;32m---> 34\u001b[0m Response_Website \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# If Status_code value is 200 this implies TomTom has completed succesfully.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# If status_code is not 200, the provided status_code and error message will be printed by the code.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Response_Website\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.tomtom.com', port=443): Max retries exceeded with url: /routing/1/calculateRoute/35.9473111%2C14.3931026%3A35.9462932%2C14.3904814/json?maxAlternatives=1&computeTravelTimeFor=all&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key=uA2d36BEe5Xby9As7hUgrBmGL34u4n0h (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002458B8BDAF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))"
     ]
    }
   ],
   "source": [
    "# Step 4.4 - Utilise TomTom to obtain the following edge treversal information:\n",
    "# 1. Length_In_Metres - The route or leg length in meters.\n",
    "# 2. Travel_Time_Value - The estimated travel time in seconds. \n",
    "# Note that even when traffic=false, travelTimeInSeconds still includes the delay due to traffic.\n",
    "# 3. Travel_Time_No_Traffic_Value - The estimated travel time in seconds calculated as if there are no delays on the route due to traffic conditions (e.g., congestion).\n",
    "# 4. Historic_Traffic_Travel_Time - The estimated travel time in seconds calculated using time-dependent historic traffic data.\n",
    "# 5. Live_Traffic_Travel_Time - The estimated travel time in seconds calculated using real-time speed data.\n",
    "# 6. Traffic_Delay - Traffic delay is the difference between the travel time calculated using all available traffic information and \n",
    "# travel time calculated without the influence of current and historic traffic data.\n",
    "# 7. Departure_Time - Time Bus leaves origin \n",
    "# 8. Arrival_Time - Time Bus arrives at origin\n",
    "\n",
    "# TomTom API Key \n",
    "TOMTOM_API_Key = '4x14GdbcGGsXeen6yUhicscKFbz28iMj'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(Distinct_Edges_MALTA)):\n",
    "    print(f\"Processing request {i+1} of {len(Distinct_Edges_MALTA)}\")\n",
    "    url = \"https://api.tomtom.com/routing/1/calculateRoute/{0}%2C{1}%3A{2}%2C{3}/json?maxAlternatives=1&computeTravelTimeFor=all&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={4}\".format(Distinct_Edges_MALTA['Latitude_Final'][i], Distinct_Edges_MALTA['Longitude_Final'][i], Distinct_Edges_MALTA['Latitude_Next'][i], Distinct_Edges_MALTA['Longitude_Next'][i], TOMTOM_API_Key)\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "        \n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143c9c9-8494-4586-896a-dd8fe78a131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.5 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "Distinct_Edges_MALTA_IncTravelTimes = Distinct_Edges_MALTA.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "Distinct_Edges_MALTA_IncTravelTimes.to_csv('C://Users//Owner//ICT5012 - Disseration//Distinct_Edges_MALTA_IncTravelTimes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6c7c19b-556f-4606-8903-7a135dbcb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing request 1 of 390\n",
      "Processing request 2 of 390\n",
      "Processing request 3 of 390\n",
      "Processing request 4 of 390\n",
      "Processing request 5 of 390\n",
      "Processing request 6 of 390\n",
      "Processing request 7 of 390\n",
      "Processing request 8 of 390\n",
      "Processing request 9 of 390\n",
      "Processing request 10 of 390\n",
      "Processing request 11 of 390\n",
      "Processing request 12 of 390\n",
      "Processing request 13 of 390\n",
      "Processing request 14 of 390\n",
      "Processing request 15 of 390\n",
      "Processing request 16 of 390\n",
      "Processing request 17 of 390\n",
      "Processing request 18 of 390\n",
      "Processing request 19 of 390\n",
      "Processing request 20 of 390\n",
      "Processing request 21 of 390\n",
      "Processing request 22 of 390\n",
      "Processing request 23 of 390\n",
      "Processing request 24 of 390\n",
      "Error: HTTP 400 - {\"formatVersion\":\"0.0.12\",\"detailedError\":{\"message\":\"Invalid request: malformed coordinate at index [1]: [nan,nan]\",\"code\":\"BAD_INPUT\"}}\n",
      "Processing request 25 of 390\n",
      "Processing request 26 of 390\n",
      "Processing request 27 of 390\n",
      "Processing request 28 of 390\n",
      "Processing request 29 of 390\n",
      "Processing request 30 of 390\n",
      "Processing request 31 of 390\n",
      "Processing request 32 of 390\n",
      "Processing request 33 of 390\n",
      "Processing request 34 of 390\n",
      "Processing request 35 of 390\n",
      "Processing request 36 of 390\n",
      "Processing request 37 of 390\n",
      "Processing request 38 of 390\n",
      "Processing request 39 of 390\n",
      "Processing request 40 of 390\n",
      "Processing request 41 of 390\n",
      "Processing request 42 of 390\n",
      "Processing request 43 of 390\n",
      "Processing request 44 of 390\n",
      "Processing request 45 of 390\n",
      "Processing request 46 of 390\n",
      "Processing request 47 of 390\n",
      "Processing request 48 of 390\n",
      "Processing request 49 of 390\n",
      "Processing request 50 of 390\n",
      "Processing request 51 of 390\n",
      "Processing request 52 of 390\n",
      "Processing request 53 of 390\n",
      "Processing request 54 of 390\n",
      "Processing request 55 of 390\n",
      "Processing request 56 of 390\n",
      "Processing request 57 of 390\n",
      "Processing request 58 of 390\n",
      "Processing request 59 of 390\n",
      "Processing request 60 of 390\n",
      "Processing request 61 of 390\n",
      "Processing request 62 of 390\n",
      "Processing request 63 of 390\n",
      "Processing request 64 of 390\n",
      "Processing request 65 of 390\n",
      "Processing request 66 of 390\n",
      "Processing request 67 of 390\n",
      "Processing request 68 of 390\n",
      "Processing request 69 of 390\n",
      "Processing request 70 of 390\n",
      "Processing request 71 of 390\n",
      "Processing request 72 of 390\n",
      "Processing request 73 of 390\n",
      "Processing request 74 of 390\n",
      "Processing request 75 of 390\n",
      "Processing request 76 of 390\n",
      "Processing request 77 of 390\n",
      "Processing request 78 of 390\n",
      "Processing request 79 of 390\n",
      "Processing request 80 of 390\n",
      "Processing request 81 of 390\n",
      "Processing request 82 of 390\n",
      "Processing request 83 of 390\n",
      "Processing request 84 of 390\n",
      "Processing request 85 of 390\n",
      "Processing request 86 of 390\n",
      "Processing request 87 of 390\n",
      "Processing request 88 of 390\n",
      "Processing request 89 of 390\n",
      "Processing request 90 of 390\n",
      "Processing request 91 of 390\n",
      "Processing request 92 of 390\n",
      "Processing request 93 of 390\n",
      "Processing request 94 of 390\n",
      "Processing request 95 of 390\n",
      "Processing request 96 of 390\n",
      "Processing request 97 of 390\n",
      "Processing request 98 of 390\n",
      "Processing request 99 of 390\n",
      "Processing request 100 of 390\n",
      "Processing request 101 of 390\n",
      "Processing request 102 of 390\n",
      "Processing request 103 of 390\n",
      "Processing request 104 of 390\n",
      "Processing request 105 of 390\n",
      "Processing request 106 of 390\n",
      "Processing request 107 of 390\n",
      "Processing request 108 of 390\n",
      "Processing request 109 of 390\n",
      "Processing request 110 of 390\n",
      "Processing request 111 of 390\n",
      "Processing request 112 of 390\n",
      "Processing request 113 of 390\n",
      "Processing request 114 of 390\n",
      "Processing request 115 of 390\n",
      "Processing request 116 of 390\n",
      "Processing request 117 of 390\n",
      "Processing request 118 of 390\n",
      "Processing request 119 of 390\n",
      "Processing request 120 of 390\n",
      "Processing request 121 of 390\n",
      "Processing request 122 of 390\n",
      "Processing request 123 of 390\n",
      "Processing request 124 of 390\n",
      "Processing request 125 of 390\n",
      "Processing request 126 of 390\n",
      "Processing request 127 of 390\n",
      "Processing request 128 of 390\n",
      "Processing request 129 of 390\n",
      "Processing request 130 of 390\n",
      "Processing request 131 of 390\n",
      "Processing request 132 of 390\n",
      "Processing request 133 of 390\n",
      "Processing request 134 of 390\n",
      "Processing request 135 of 390\n",
      "Processing request 136 of 390\n",
      "Processing request 137 of 390\n",
      "Processing request 138 of 390\n",
      "Processing request 139 of 390\n",
      "Processing request 140 of 390\n",
      "Processing request 141 of 390\n",
      "Processing request 142 of 390\n",
      "Processing request 143 of 390\n",
      "Processing request 144 of 390\n",
      "Processing request 145 of 390\n",
      "Processing request 146 of 390\n",
      "Processing request 147 of 390\n",
      "Processing request 148 of 390\n",
      "Processing request 149 of 390\n",
      "Processing request 150 of 390\n",
      "Processing request 151 of 390\n",
      "Processing request 152 of 390\n",
      "Processing request 153 of 390\n",
      "Processing request 154 of 390\n",
      "Processing request 155 of 390\n",
      "Processing request 156 of 390\n",
      "Processing request 157 of 390\n",
      "Processing request 158 of 390\n",
      "Processing request 159 of 390\n",
      "Processing request 160 of 390\n",
      "Processing request 161 of 390\n",
      "Processing request 162 of 390\n",
      "Processing request 163 of 390\n",
      "Processing request 164 of 390\n",
      "Processing request 165 of 390\n",
      "Processing request 166 of 390\n",
      "Processing request 167 of 390\n",
      "Processing request 168 of 390\n",
      "Processing request 169 of 390\n",
      "Processing request 170 of 390\n",
      "Processing request 171 of 390\n",
      "Processing request 172 of 390\n",
      "Processing request 173 of 390\n",
      "Processing request 174 of 390\n",
      "Processing request 175 of 390\n",
      "Processing request 176 of 390\n",
      "Processing request 177 of 390\n",
      "Processing request 178 of 390\n",
      "Processing request 179 of 390\n",
      "Processing request 180 of 390\n",
      "Processing request 181 of 390\n",
      "Processing request 182 of 390\n",
      "Processing request 183 of 390\n",
      "Processing request 184 of 390\n",
      "Processing request 185 of 390\n",
      "Processing request 186 of 390\n",
      "Processing request 187 of 390\n",
      "Processing request 188 of 390\n",
      "Processing request 189 of 390\n",
      "Processing request 190 of 390\n",
      "Processing request 191 of 390\n",
      "Processing request 192 of 390\n",
      "Processing request 193 of 390\n",
      "Processing request 194 of 390\n",
      "Processing request 195 of 390\n",
      "Processing request 196 of 390\n",
      "Processing request 197 of 390\n",
      "Processing request 198 of 390\n",
      "Processing request 199 of 390\n",
      "Processing request 200 of 390\n",
      "Processing request 201 of 390\n",
      "Processing request 202 of 390\n",
      "Processing request 203 of 390\n",
      "Processing request 204 of 390\n",
      "Processing request 205 of 390\n",
      "Processing request 206 of 390\n",
      "Processing request 207 of 390\n",
      "Processing request 208 of 390\n",
      "Processing request 209 of 390\n",
      "Processing request 210 of 390\n",
      "Processing request 211 of 390\n",
      "Processing request 212 of 390\n",
      "Processing request 213 of 390\n",
      "Processing request 214 of 390\n",
      "Processing request 215 of 390\n",
      "Processing request 216 of 390\n",
      "Processing request 217 of 390\n",
      "Processing request 218 of 390\n",
      "Processing request 219 of 390\n",
      "Processing request 220 of 390\n",
      "Processing request 221 of 390\n",
      "Processing request 222 of 390\n",
      "Processing request 223 of 390\n",
      "Processing request 224 of 390\n",
      "Error: HTTP 400 - {\"formatVersion\":\"0.0.12\",\"detailedError\":{\"message\":\"Invalid request: malformed coordinate at index [1]: [nan,nan]\",\"code\":\"BAD_INPUT\"}}\n",
      "Processing request 225 of 390\n",
      "Processing request 226 of 390\n",
      "Processing request 227 of 390\n",
      "Processing request 228 of 390\n",
      "Processing request 229 of 390\n",
      "Processing request 230 of 390\n",
      "Processing request 231 of 390\n",
      "Processing request 232 of 390\n",
      "Processing request 233 of 390\n",
      "Processing request 234 of 390\n",
      "Processing request 235 of 390\n",
      "Processing request 236 of 390\n",
      "Processing request 237 of 390\n",
      "Processing request 238 of 390\n",
      "Processing request 239 of 390\n",
      "Processing request 240 of 390\n",
      "Processing request 241 of 390\n",
      "Processing request 242 of 390\n",
      "Processing request 243 of 390\n",
      "Processing request 244 of 390\n",
      "Processing request 245 of 390\n",
      "Processing request 246 of 390\n",
      "Processing request 247 of 390\n",
      "Processing request 248 of 390\n",
      "Processing request 249 of 390\n",
      "Processing request 250 of 390\n",
      "Processing request 251 of 390\n",
      "Processing request 252 of 390\n",
      "Processing request 253 of 390\n",
      "Processing request 254 of 390\n",
      "Processing request 255 of 390\n",
      "Processing request 256 of 390\n",
      "Processing request 257 of 390\n",
      "Processing request 258 of 390\n",
      "Processing request 259 of 390\n",
      "Processing request 260 of 390\n",
      "Processing request 261 of 390\n",
      "Processing request 262 of 390\n",
      "Processing request 263 of 390\n",
      "Processing request 264 of 390\n",
      "Processing request 265 of 390\n",
      "Processing request 266 of 390\n",
      "Processing request 267 of 390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing request 268 of 390\n",
      "Processing request 269 of 390\n",
      "Processing request 270 of 390\n",
      "Processing request 271 of 390\n",
      "Processing request 272 of 390\n",
      "Processing request 273 of 390\n",
      "Processing request 274 of 390\n",
      "Processing request 275 of 390\n",
      "Processing request 276 of 390\n",
      "Processing request 277 of 390\n",
      "Processing request 278 of 390\n",
      "Processing request 279 of 390\n",
      "Processing request 280 of 390\n",
      "Processing request 281 of 390\n",
      "Processing request 282 of 390\n",
      "Processing request 283 of 390\n",
      "Processing request 284 of 390\n",
      "Processing request 285 of 390\n",
      "Error: HTTP 400 - {\"formatVersion\":\"0.0.12\",\"detailedError\":{\"message\":\"Invalid request: malformed coordinate at index [1]: [nan,nan]\",\"code\":\"BAD_INPUT\"}}\n",
      "Processing request 286 of 390\n",
      "Processing request 287 of 390\n",
      "Processing request 288 of 390\n",
      "Processing request 289 of 390\n",
      "Processing request 290 of 390\n",
      "Processing request 291 of 390\n",
      "Processing request 292 of 390\n",
      "Processing request 293 of 390\n",
      "Processing request 294 of 390\n",
      "Processing request 295 of 390\n",
      "Processing request 296 of 390\n",
      "Processing request 297 of 390\n",
      "Processing request 298 of 390\n",
      "Processing request 299 of 390\n",
      "Processing request 300 of 390\n",
      "Processing request 301 of 390\n",
      "Processing request 302 of 390\n",
      "Processing request 303 of 390\n",
      "Processing request 304 of 390\n",
      "Processing request 305 of 390\n",
      "Processing request 306 of 390\n",
      "Processing request 307 of 390\n",
      "Processing request 308 of 390\n",
      "Processing request 309 of 390\n",
      "Processing request 310 of 390\n",
      "Processing request 311 of 390\n",
      "Processing request 312 of 390\n",
      "Processing request 313 of 390\n",
      "Processing request 314 of 390\n",
      "Processing request 315 of 390\n",
      "Processing request 316 of 390\n",
      "Processing request 317 of 390\n",
      "Processing request 318 of 390\n",
      "Processing request 319 of 390\n",
      "Processing request 320 of 390\n",
      "Processing request 321 of 390\n",
      "Processing request 322 of 390\n",
      "Processing request 323 of 390\n",
      "Processing request 324 of 390\n",
      "Processing request 325 of 390\n",
      "Processing request 326 of 390\n",
      "Processing request 327 of 390\n",
      "Processing request 328 of 390\n",
      "Processing request 329 of 390\n",
      "Processing request 330 of 390\n",
      "Processing request 331 of 390\n",
      "Processing request 332 of 390\n",
      "Processing request 333 of 390\n",
      "Processing request 334 of 390\n",
      "Processing request 335 of 390\n",
      "Processing request 336 of 390\n",
      "Processing request 337 of 390\n",
      "Processing request 338 of 390\n",
      "Processing request 339 of 390\n",
      "Processing request 340 of 390\n",
      "Processing request 341 of 390\n",
      "Processing request 342 of 390\n",
      "Processing request 343 of 390\n",
      "Processing request 344 of 390\n",
      "Processing request 345 of 390\n",
      "Processing request 346 of 390\n",
      "Processing request 347 of 390\n",
      "Processing request 348 of 390\n",
      "Processing request 349 of 390\n",
      "Processing request 350 of 390\n",
      "Processing request 351 of 390\n",
      "Processing request 352 of 390\n",
      "Processing request 353 of 390\n",
      "Processing request 354 of 390\n",
      "Processing request 355 of 390\n",
      "Processing request 356 of 390\n",
      "Processing request 357 of 390\n",
      "Processing request 358 of 390\n",
      "Processing request 359 of 390\n",
      "Processing request 360 of 390\n",
      "Processing request 361 of 390\n",
      "Processing request 362 of 390\n",
      "Processing request 363 of 390\n",
      "Processing request 364 of 390\n",
      "Processing request 365 of 390\n",
      "Processing request 366 of 390\n",
      "Processing request 367 of 390\n",
      "Processing request 368 of 390\n",
      "Processing request 369 of 390\n",
      "Processing request 370 of 390\n",
      "Processing request 371 of 390\n",
      "Processing request 372 of 390\n",
      "Processing request 373 of 390\n",
      "Processing request 374 of 390\n",
      "Processing request 375 of 390\n",
      "Processing request 376 of 390\n",
      "Processing request 377 of 390\n",
      "Processing request 378 of 390\n",
      "Processing request 379 of 390\n",
      "Processing request 380 of 390\n",
      "Processing request 381 of 390\n",
      "Processing request 382 of 390\n",
      "Processing request 383 of 390\n",
      "Processing request 384 of 390\n",
      "Processing request 385 of 390\n",
      "Processing request 386 of 390\n",
      "Processing request 387 of 390\n",
      "Processing request 388 of 390\n",
      "Processing request 389 of 390\n",
      "Processing request 390 of 390\n"
     ]
    }
   ],
   "source": [
    "# Step 4.6 - Repeat process for 'Distinct_Edges_GOZO'\n",
    "\n",
    "# TomTom API Key \n",
    "TOMTOM_API_Key = 'uA2d36BEe5Xby9As7hUgrBmGL34u4n0h'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(Distinct_Edges_GOZO)):\n",
    "    print(f\"Processing request {i+1} of {len(Distinct_Edges_GOZO)}\")\n",
    "    url = \"https://api.tomtom.com/routing/1/calculateRoute/{0}%2C{1}%3A{2}%2C{3}/json?maxAlternatives=1&computeTravelTimeFor=all&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={4}\".format(Distinct_Edges_MALTA['Latitude_Final'][i], Distinct_Edges_MALTA['Longitude_Final'][i], Distinct_Edges_MALTA['Latitude_Next'][i], Distinct_Edges_MALTA['Longitude_Next'][i], TOMTOM_API_Key)\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "        \n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf22500",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distinct_Edges_GOZO.to_csv('Donkey.csy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37dcb3d7-f076-48c5-8915-acc1a22729a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (387) does not match length of index (390)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 4.7 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 'Travel_Time' Column - Travel_Time\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m Distinct_Edges_GOZO_IncTravelTimes \u001b[38;5;241m=\u001b[39m \u001b[43mDistinct_Edges_GOZO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTravel_Time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTravel_Time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTravel_Time_No_Traffic\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTravel_Time_No_Traffic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mHistoric_Traffic_Travel_Time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mHistoric_Traffic_Travel_Time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLive_Traffic_Travel_Time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLive_Traffic_Travel_Time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mTraffic_Delay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTraffic_Delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLength_In_Metres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLength_In_Metres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDeparture_Time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDeparture_Time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mArrival_Time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mArrival_Time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4889\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   4886\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m   4888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m-> 4889\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(v, data)\n\u001b[0;32m   4890\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4167\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4180\u001b[0m     ):\n\u001b[0;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (387) does not match length of index (390)"
     ]
    }
   ],
   "source": [
    "# Step 4.7 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "Distinct_Edges_GOZO_IncTravelTimes = Distinct_Edges_GOZO.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "#Distinct_Edges_GOZO_IncTravelTimes.to_csv('C://Users//Owner//ICT5012 - Disseration//Creating SUMO Simulation & Obtaining Travel Times//Results//Distinct_Edges_GOZO_IncTravelTimes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3302ba3-dabd-441c-8d12-6180711c8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e561b-c651-4981-ae69-ecf2e8292839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc0887-ddff-440e-b3fc-d95097a1343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Routes\n",
    "min_value = All_Routes['Stop Time 1'].min()\n",
    "min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cbfab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e179c4-c692-4dc8-98b2-9e607ae7c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - We will proceed by splitting the 'All_Routes_Copy' into the following fourteen separate dataframes:\n",
    " # 1 - Monday_Routes_Malta\n",
    " # 2 - Tuesday_Routes_Malta\n",
    " # 3 - Wednesday_Routes_Malta\n",
    " # 4 - Thursday_Routes_Malta\n",
    " # 5 - Friday_Routes_Malta\n",
    " # 6 - Saturday_Routes_Malta\n",
    " # 7 - Sunday_Routes_Malta\n",
    " # 8 - Monday_Routes_Gozo\n",
    " # 9 - Tuesday_Routes_Gozo\n",
    " # 10 - Wednesday_Routes_Gozo\n",
    " # 11 - Thursday_Routes_Gozo\n",
    " # 12 - Friday_Routes_Gozo\n",
    " # 13 - Saturday_Routes_Gozo\n",
    " # 14 - Sunday_Routes_Gozo\n",
    "\n",
    "# List of days in which Public Transportation System Functions\n",
    "List_Dates = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# 'Rows_Date_Dict' - Dictionary to store only instances of the same date \n",
    "Rows_Date_Dict = {}\n",
    "# 'Malta_Dict' - Dictionary to store only instances of the same date operating in Malta\n",
    "Malta_Dict = {}\n",
    "# 'Gozo_Dict' - Dictionary to store only instances of the same date operating in Gozo\n",
    "Gozo_Dict = {}\n",
    "\n",
    "# for loop going over List_Dates defined above\n",
    "for c in List_Dates:\n",
    "    # filter rows according to date 'c' currently being considered\n",
    "    Rows_Date_Dict[c] = All_Routes_Copy[All_Routes_Copy['Date'].astype(str).str.contains(c, na=False)]\n",
    "\n",
    "    # split entries present in 'Rows_Date_Dict[c]' accordng to 'Stop Island' value\n",
    "    Malta_Dict[c] = Rows_Date_Dict[c][Rows_Date_Dict[c]['Stop Island'] == 'MALTA STOP'].reset_index(drop=True)\n",
    "    Gozo_Dict[c] = Rows_Date_Dict[c][Rows_Date_Dict[c]['Stop Island'] == 'GOZO STOP'].reset_index(drop=True)\n",
    "\n",
    "# Naming Dataframes \n",
    "Monday_Routes_Malta = Malta_Dict['Monday']\n",
    "Tuesday_Routes_Malta = Malta_Dict['Tuesday']\n",
    "Wednesday_Routes_Malta = Malta_Dict['Wednesday']\n",
    "Thursday_Routes_Malta = Malta_Dict['Thursday']\n",
    "Friday_Routes_Malta = Malta_Dict['Friday']\n",
    "Saturday_Routes_Malta = Malta_Dict['Saturday']\n",
    "Sunday_Routes_Malta = Malta_Dict['Sunday']\n",
    "Monday_Routes_Gozo = Gozo_Dict['Monday']\n",
    "Tuesday_Routes_Gozo = Gozo_Dict['Tuesday']\n",
    "Wednesday_Routes_Gozo = Gozo_Dict['Wednesday']\n",
    "Thursday_Routes_Gozo = Gozo_Dict['Thursday']\n",
    "Friday_Routes_Gozo = Gozo_Dict['Friday']\n",
    "Saturday_Routes_Gozo = Gozo_Dict['Saturday']\n",
    "Sunday_Routes_Gozo = Gozo_Dict['Sunday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbb105-c90d-469f-8289-037acdda6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1 - Obtain Number of Routes Covered each day\n",
    "\n",
    "Malta_Route_DataFrames_List = [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta]\n",
    "Gozo_Route_DataFrames_List = [Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "# Used to select Date from 'List_Dates'\n",
    "j = 0\n",
    "\n",
    "for i in Malta_Route_DataFrames_List:\n",
    "    Unique_Route_Length = len(i['Route Number'].unique())\n",
    "    print(f'Number of Routes for Malta in {List_Dates[j]} is {Unique_Route_Length}')\n",
    "    j += 1\n",
    "\n",
    "c = 0 \n",
    "\n",
    "for i in Gozo_Route_DataFrames_List:\n",
    "    Unique_Route_Length = len(i['Route Number'].unique())\n",
    "    print(f'Number of Routes for Gozo in {List_Dates[c]} is {Unique_Route_Length}')\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f95e39-c27c-47bd-9417-38985beca25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.2 - Obtain table indicating number of bus stops traversed by each route \n",
    "# To simplify problem, for any non-circular stops we will consider only the maximum number of stops in any one direction\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store result of number of stops of each route per day\n",
    "Malta_Stops_Per_Route_PerDay = {}\n",
    "Gozo_Stops_Per_Route_PerDay = {}\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in Malta_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    i_copy['Concatenated_Columns'] = (i_copy['Route Number'] + '-' + i_copy['Route Direction'])\n",
    "    # Count the number of rows in each group\n",
    "    group_sizes = i_copy.groupby('Concatenated_Columns').size()\n",
    "    # Map group sizes back to the original DataFrame\n",
    "    i_copy['Group'] = i_copy['Concatenated_Columns'].map(group_sizes)\n",
    "    # Drop temporary columns if not needed\n",
    "    i_copy.drop(columns=['Concatenated_Columns'], inplace=True)\n",
    "    # Count the size of each group\n",
    "    Partition_Count = i_copy.groupby(['Route Number', 'Group']).size()\n",
    "    # Find the maximum size for each Route Number\n",
    "    Malta_Stops_Per_Route = Partition_Count.groupby('Route Number').max()\n",
    "    Malta_Stops_Per_Route_PerDay[List_Dates[j]] = Malta_Stops_Per_Route\n",
    "    j += 1\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in Gozo_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    i_copy['Concatenated_Columns'] = (i_copy['Route Number'] + '-' + i_copy['Route Direction'])\n",
    "    # Count the number of rows in each group\n",
    "    group_sizes = i_copy.groupby('Concatenated_Columns').size()\n",
    "    # Map group sizes back to the original DataFrame\n",
    "    i_copy['Group'] = i_copy['Concatenated_Columns'].map(group_sizes)\n",
    "    # Drop temporary columns if not needed\n",
    "    i_copy.drop(columns=['Concatenated_Columns'], inplace=True)\n",
    "    # Count the size of each group\n",
    "    Partition_Count = i_copy.groupby(['Route Number', 'Group']).size()\n",
    "    # Find the maximum size for each Route Number\n",
    "    Gozo_Stops_Per_Route = Partition_Count.groupby('Route Number').max()\n",
    "    Gozo_Stops_Per_Route_PerDay[List_Dates[k]] = Gozo_Stops_Per_Route\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# Naming Dataframes \n",
    "Monday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Monday']\n",
    "Tuesday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Tuesday']\n",
    "Wednesday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Wednesday']\n",
    "Thursday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Thursday']\n",
    "Friday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Friday']\n",
    "Saturday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Saturday']\n",
    "Sunday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Sunday']\n",
    "Monday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Monday']\n",
    "Tuesday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Tuesday']\n",
    "Wednesday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Wednesday']\n",
    "Thursday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Thursday']\n",
    "Friday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Friday']\n",
    "Saturday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Saturday']\n",
    "Sunday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93fca8-8b98-4c73-9d60-005be1f824da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data in One DataFrame\n",
    "# Column - Day of the week\n",
    "# Rows - Route Number\n",
    "# Entries in DataFrame show the number of Bus Stops traverrsed by each Route\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Malta_RoutePresencePerDay__and_BusStopsVisited'\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited = pd.concat([Monday_NoStopsPerRoute_Malta, Tuesday_NoStopsPerRoute_Malta, Wednesday_NoStopsPerRoute_Malta,\n",
    "                                                           Thursday_NoStopsPerRoute_Malta, Friday_NoStopsPerRoute_Malta, Saturday_NoStopsPerRoute_Malta,\n",
    "                                                           Sunday_NoStopsPerRoute_Malta], axis=1)\n",
    "# Replace 'N/A' with NaN \n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited = Malta_RoutePresencePerDay__and_BusStopsVisited.astype('Int64')\n",
    "# Rename Columns\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited.columns = List_Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b657608-8a3d-4281-b1de-6f096e80cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data in One DataFrame\n",
    "# Column - Day of the week\n",
    "# Rows - Route Number\n",
    "# Entries in DataFrame show the number of Bus Stops traverrsed by each Route\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Malta_RoutePresencePerDay__and_BusStopsVisited'\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited = pd.concat([Monday_NoStopsPerRoute_Gozo, Tuesday_NoStopsPerRoute_Gozo, Wednesday_NoStopsPerRoute_Gozo,\n",
    "                                                           Thursday_NoStopsPerRoute_Gozo, Friday_NoStopsPerRoute_Gozo, Saturday_NoStopsPerRoute_Gozo,\n",
    "                                                           Sunday_NoStopsPerRoute_Gozo], axis=1)\n",
    "# Replace 'N/A' with NaN \n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited = Gozo_RoutePresencePerDay__and_BusStopsVisited.astype('Int64')\n",
    "# Rename Columns\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited.columns = List_Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d812ed7-b477-49ca-80c2-5b7de278e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.3 - Obtain table indicating number of times route runs throughout a day \n",
    "# (It is expected that circular routes will run more frequently compared to routes going in one direction_\n",
    "# To simplify problem, for any non-circular stops we will consider only the maximum frequency between directions\n",
    "# Frequency is given per working day\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store result of number of stops of each route per day\n",
    "Malta_Frequency_Of_Route_PerDay = {}\n",
    "Gozo_Frequency_Of_Route_PerDay = {}\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in Malta_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    Grouped = i_copy.groupby('Route Number')\n",
    "    # Find the maximum size for each Route Number\n",
    "    Malta_Frequency_Of_Route = Grouped['Time_Count'].max()\n",
    "    Malta_Frequency_Of_Route_PerDay[List_Dates[j]] = Malta_Frequency_Of_Route\n",
    "    j += 1\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in Gozo_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    Grouped = i_copy.groupby('Route Number')\n",
    "    # Find the maximum size for each Route Number\n",
    "    Gozo_Frequency_Of_Route = Grouped['Time_Count'].max()\n",
    "    Gozo_Frequency_Of_Route_PerDay[List_Dates[k]] = Gozo_Frequency_Of_Route\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# Naming Dataframes \n",
    "Monday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Monday']\n",
    "Tuesday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Tuesday']\n",
    "Wednesday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Wednesday']\n",
    "Thursday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Thursday']\n",
    "Friday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Friday']\n",
    "Saturday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Saturday']\n",
    "Sunday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Sunday']\n",
    "Monday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Monday']\n",
    "Tuesday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Tuesday']\n",
    "Wednesday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Wednesday']\n",
    "Thursday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Thursday']\n",
    "Friday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Friday']\n",
    "Saturday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Saturday']\n",
    "Sunday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbd53f-0ef7-4989-89b3-35b76c55606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data in One DataFrame\n",
    "# Column - Day of the week\n",
    "# Rows - Route Number\n",
    "# Entries in DataFrame show the Frequency per day of each Route\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Malta_RoutePresencePerDay__and_BusStopsVisited'\n",
    "Malta_FrequencyPerDay = pd.concat([Monday_FrequencyofRoute_Malta, Tuesday_FrequencyofRoute_Malta, Wednesday_FrequencyofRoute_Malta,\n",
    "                                                           Thursday_FrequencyofRoute_Malta, Friday_FrequencyofRoute_Malta, Saturday_FrequencyofRoute_Malta,\n",
    "                                                           Sunday_FrequencyofRoute_Malta], axis=1)\n",
    "# Replace 'N/A' with NaN \n",
    "Malta_FrequencyPerDay.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Malta_FrequencyPerDay = Malta_FrequencyPerDay.astype('Int64')\n",
    "# Rename Columns\n",
    "Malta_FrequencyPerDay.columns = List_Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4835f1-2f9f-4776-966f-cb74cfc1db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data in One DataFrame\n",
    "# Column - Day of the week\n",
    "# Rows - Route Number\n",
    "# Entries in DataFrame show the Frequency per day of each Route\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Malta_RoutePresencePerDay__and_BusStopsVisited'\n",
    "Gozo_FrequencyPerDay = pd.concat([Monday_FrequencyofRoute_Gozo, Tuesday_FrequencyofRoute_Gozo, Wednesday_FrequencyofRoute_Gozo,\n",
    "                                                           Thursday_FrequencyofRoute_Gozo, Friday_FrequencyofRoute_Gozo, Saturday_FrequencyofRoute_Gozo,\n",
    "                                                           Sunday_FrequencyofRoute_Gozo], axis=1)\n",
    "# Replace 'N/A' with NaN \n",
    "Gozo_FrequencyPerDay.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Gozo_FrequencyPerDay = Gozo_FrequencyPerDay.astype('Int64')\n",
    "# Rename Columns\n",
    "Gozo_FrequencyPerDay.columns = List_Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e475d-e4c5-4a82-8faf-23dec31d7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download DataFrames\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited.to_csv('C://Users//Owner//ICT5012 - Disseration//Untitled Folder//Malta_RoutePresencePerDay__and_BusStopsVisited.csv')\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited.to_csv('C://Users//Owner//ICT5012 - Disseration//Untitled Folder//Gozo_RoutePresencePerDay__and_BusStopsVisited.csv')\n",
    "Malta_FrequencyPerDay.to_csv('C://Users//Owner//ICT5012 - Disseration//Untitled Folder//Malta_FrequencyPerDay.csv')\n",
    "Gozo_FrequencyPerDay.to_csv('C://Users//Owner//ICT5012 - Disseration//Untitled Folder//Gozo_FrequencyPerDay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Malta_RoutePresencePerDay__and_BusStopsVisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d66336-64c3-49b3-aa84-6cd36f55ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Routes_Copy.to_csv('C://Users//attardan.CBM//Data Visualisation//All_Routes_Copies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27ff61-3098-482e-bb11-fa24f0bd2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Obtain List of Bus Terminals (Malta & Gozo)\n",
    "\n",
    "Malta_Route_DataFrames_List = [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta]\n",
    "Gozo_Route_DataFrames_List = [Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "Day_Names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# Save Path Home\n",
    "#save_path = \"C://Users//Owner//ICT5012 - Disseration//Untitled Folder//\"\n",
    "# Save Path Work\n",
    "save_path = \"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//\"\n",
    "\n",
    "\n",
    "for i, day in zip(Malta_Route_DataFrames_List, Day_Names):\n",
    "    \n",
    "    print(day)\n",
    "    \n",
    "    Reset_Condition_SepDay = (\n",
    "        i['Route Number'].shift(-1) != i['Route Number']) | \\\n",
    "        (i['Route Direction'].shift(-1) != i['Route Direction'])\n",
    "\n",
    "    # Initialise all entries in 'Bus_Terminal' as 0\n",
    "    i['Bus_Terminal'] = 0\n",
    "    # If Reset_Conditions defined above fails, then Bus Stop considered in 'Bus_Stop_ID' is a Bus Terminal\n",
    "    i.loc[Reset_Condition_SepDay, 'Bus_Terminal'] = 1\n",
    "    OG_BUS_Terminal_COLUMN = i['Bus_Terminal'].copy()\n",
    "    # Iterate through the original column\n",
    "    for j in range(len(OG_BUS_Terminal_COLUMN) - 1):\n",
    "        if OG_BUS_Terminal_COLUMN[j] == 1:\n",
    "            i.loc[j + 1, 'Bus_Terminal'] = 1\n",
    "    # Initialising First Row as Bus Terminal\n",
    "    i.loc[0, 'Bus_Terminal'] = 1\n",
    "    \n",
    "    Bus_Terminals_DataFrame = i[i['Bus_Terminal'] == 1]\n",
    "\n",
    "    # Contain List of traversed Bus_Stop_ID ('bus_stop_ids' - All Bus Stops identified as terminal stops)\n",
    "    bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Bus_Terminals_DataFrame)):\n",
    "        bus_stop_id = Bus_Terminals_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id not in bus_stop_ids:\n",
    "            bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "            \n",
    "    # Obtain only entries which correspond to a Bus Terminals. \n",
    "    # Duplicates will be present since the same Bus Terminals may be utilised for multiple 'Route Numebr' and 'Route Direction'\n",
    "    Normal_Bus_DataFrame = i[i['Bus_Terminal'] == 0]\n",
    "    \n",
    "    # Contain List of traversed Bus_Stop_ID ('Normal_bus_stop_ids' - All Bus Stops identified as normal stops)\n",
    "    Normal_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Normal_Bus_DataFrame)):\n",
    "        Normal_bus_stop_id = Normal_Bus_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Normal_bus_stop_id not in Normal_bus_stop_ids:\n",
    "            Normal_bus_stop_ids.append(Normal_bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "    \n",
    "    # Bus Stops used in terminals/terminals used as Bus Stops\n",
    "    # Find items in common between the two lists produced above 'bus_stop_ids' and 'Normal_bus_stop_ids'\n",
    "    #Normal_and_BusTerminals_ids = [item for item in Normal_bus_stop_ids if item in bus_stop_ids]\n",
    "    Normal_and_BusTerminals_ids = list(set(bus_stop_ids) & set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    Normal_and_BusTerminals_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "    \n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    compare_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        bus_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id in Normal_and_BusTerminals_ids and bus_stop_id not in compare_bus_stop_ids:\n",
    "            compare_bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            Normal_and_BusTerminals_DataFrame_Malta = pd.concat([Normal_and_BusTerminals_DataFrame_Malta, i.iloc[[c]]],\n",
    "                                                                ignore_index=True)\n",
    " \n",
    "    file_name = f\"AllNormalBusStopsUsedAsTerminalsMalta_{day}.csv\" \n",
    "    Normal_and_BusTerminals_DataFrame_Malta.to_csv(save_path + file_name, index=False)\n",
    "    \n",
    "    # Obtaining Stops which are only used as Terminals\n",
    "    BusTerminals_Only_ids = list(set(bus_stop_ids) - set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    BusTerminals_Only_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Terminal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Terminal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Terminal_stop_id in BusTerminals_Only_ids and Only_Terminal_stop_id not in Only_Terminal_stop_ids:\n",
    "            Only_Terminal_stop_ids.append(Only_Terminal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            BusTerminals_Only_DataFrame_Malta = pd.concat([BusTerminals_Only_DataFrame_Malta, i.iloc[[c]]],\n",
    "                                                          ignore_index=True)\n",
    "\n",
    "    file_name = f\"BusTerminalsOnlyMalta_{day}.csv\" \n",
    "    BusTerminals_Only_DataFrame_Malta.to_csv(save_path + file_name, index=False)\n",
    "\n",
    "    # Obtaining Stops which are only used as Normal Stops\n",
    "    NormalStops_Only_ids = list(set(Normal_bus_stop_ids) - set(bus_stop_ids))\n",
    "    \n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    NormalStops_Only_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Normal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Normal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Normal_stop_id in NormalStops_Only_ids and Only_Normal_stop_id not in Only_Normal_stop_ids:\n",
    "            Only_Normal_stop_ids.append(Only_Normal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            NormalStops_Only_DataFrame_Malta = pd.concat([NormalStops_Only_DataFrame_Malta, i.iloc[[c]]],\n",
    "                                                         ignore_index=True)\n",
    "      \n",
    "    file_name = f\"NormalStopsOnlyMalta_{day}.csv\" \n",
    "    NormalStops_Only_DataFrame_Malta.to_csv(save_path + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Obtain List of Bus Terminals (Malta & Gozo)\n",
    "\n",
    "Malta_Route_DataFrames_List = [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta]\n",
    "Gozo_Route_DataFrames_List = [Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "Day_Names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# Save Path Home\n",
    "#save_path = \"C://Users//Owner//ICT5012 - Disseration//Untitled Folder//\"\n",
    "# Save Path Work\n",
    "save_path = \"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//\"\n",
    "\n",
    "\n",
    "for i, day in zip(Gozo_Route_DataFrames_List, Day_Names):\n",
    "    \n",
    "    print(day)\n",
    "    \n",
    "    Reset_Condition_SepDay = (\n",
    "        i['Route Number'].shift(-1) != i['Route Number']) | \\\n",
    "        (i['Route Direction'].shift(-1) != i['Route Direction'])\n",
    "\n",
    "    # Initialise all entries in 'Bus_Terminal' as 0\n",
    "    i['Bus_Terminal'] = 0\n",
    "    # If Reset_Conditions defined above fails, then Bus Stop considered in 'Bus_Stop_ID' is a Bus Terminal\n",
    "    i.loc[Reset_Condition_SepDay, 'Bus_Terminal'] = 1\n",
    "    OG_BUS_Terminal_COLUMN = i['Bus_Terminal'].copy()\n",
    "    # Iterate through the original column\n",
    "    for j in range(len(OG_BUS_Terminal_COLUMN) - 1):\n",
    "        if OG_BUS_Terminal_COLUMN[j] == 1:\n",
    "            i.loc[j + 1, 'Bus_Terminal'] = 1\n",
    "    # Initialising First Row as Bus Terminal\n",
    "    i.loc[0, 'Bus_Terminal'] = 1\n",
    "    \n",
    "    Bus_Terminals_DataFrame = i[i['Bus_Terminal'] == 1]\n",
    "\n",
    "    # Contain List of traversed Bus_Stop_ID ('bus_stop_ids' - All Bus Stops identified as terminal stops)\n",
    "    bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Bus_Terminals_DataFrame)):\n",
    "        bus_stop_id = Bus_Terminals_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id not in bus_stop_ids:\n",
    "            bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "            \n",
    "    # Obtain only entries which correspond to a Bus Terminals. \n",
    "    # Duplicates will be present since the same Bus Terminals may be utilised for multiple 'Route Numebr' and 'Route Direction'\n",
    "    Normal_Bus_DataFrame = i[i['Bus_Terminal'] == 0]\n",
    "    \n",
    "    # Contain List of traversed Bus_Stop_ID ('Normal_bus_stop_ids' - All Bus Stops identified as normal stops)\n",
    "    Normal_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Normal_Bus_DataFrame)):\n",
    "        Normal_bus_stop_id = Normal_Bus_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Normal_bus_stop_id not in Normal_bus_stop_ids:\n",
    "            Normal_bus_stop_ids.append(Normal_bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "    \n",
    "    # Bus Stops used in terminals/terminals used as Bus Stops\n",
    "    # Find items in common between the two lists produced above 'bus_stop_ids' and 'Normal_bus_stop_ids'\n",
    "    #Normal_and_BusTerminals_ids = [item for item in Normal_bus_stop_ids if item in bus_stop_ids]\n",
    "    Normal_and_BusTerminals_ids = list(set(bus_stop_ids) & set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    Normal_and_BusTerminals_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "    \n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    compare_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        bus_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id in Normal_and_BusTerminals_ids and bus_stop_id not in compare_bus_stop_ids:\n",
    "            compare_bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            Normal_and_BusTerminals_DataFrame_Gozo = pd.concat([Normal_and_BusTerminals_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                                                                ignore_index=True)\n",
    " \n",
    "    file_name = f\"AllNormalBusStopsUsedAsTerminalsGozo_{day}.csv\" \n",
    "    Normal_and_BusTerminals_DataFrame_Gozo.to_csv(save_path + file_name, index=False)\n",
    "    \n",
    "    # Obtaining Stops which are only used as Terminals\n",
    "    BusTerminals_Only_ids = list(set(bus_stop_ids) - set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    BusTerminals_Only_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Terminal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Terminal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Terminal_stop_id in BusTerminals_Only_ids and Only_Terminal_stop_id not in Only_Terminal_stop_ids:\n",
    "            Only_Terminal_stop_ids.append(Only_Terminal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            BusTerminals_Only_DataFrame_Gozo = pd.concat([BusTerminals_Only_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                                                          ignore_index=True)\n",
    "\n",
    "    file_name = f\"BusTerminalsOnlyGozo_{day}.csv\" \n",
    "    BusTerminals_Only_DataFrame_Gozo.to_csv(save_path + file_name, index=False)\n",
    "\n",
    "    # Obtaining Stops which are only used as Normal Stops\n",
    "    NormalStops_Only_ids = list(set(Normal_bus_stop_ids) - set(bus_stop_ids))\n",
    "    \n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    NormalStops_Only_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Normal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Normal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Normal_stop_id in NormalStops_Only_ids and Only_Normal_stop_id not in Only_Normal_stop_ids:\n",
    "            Only_Normal_stop_ids.append(Only_Normal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            NormalStops_Only_DataFrame_Gozo = pd.concat([NormalStops_Only_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                                                         ignore_index=True)\n",
    "      \n",
    "    file_name = f\"NormalStopsOnlyGozo_{day}.csv\" \n",
    "    NormalStops_Only_DataFrame_Gozo.to_csv(save_path + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2c348-ee06-4f8a-9d16-e1871ea4c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all datasets created (for Malta)\n",
    "Malta_NormalStops_Monday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Monday.csv\")\n",
    "Malta_NormalStops_Tuesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Tuesday.csv\")\n",
    "Malta_NormalStops_Wednesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Wednesday.csv\")\n",
    "Malta_NormalStops_Thursday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Thursday.csv\")\n",
    "Malta_NormalStops_Friday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Friday.csv\")\n",
    "Malta_NormalStops_Saturday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Saturday.csv\")\n",
    "Malta_NormalStops_Sunday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Sunday.csv\")\n",
    "\n",
    "Malta_TerminalStops_Monday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Monday.csv\")\n",
    "Malta_TerminalStops_Tuesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Tuesday.csv\")\n",
    "Malta_TerminalStops_Wednesday =pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Wednesday.csv\")\n",
    "Malta_TerminalStops_Thursday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Thursday.csv\")\n",
    "Malta_TerminalStops_Friday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Friday.csv\")\n",
    "Malta_TerminalStops_Saturday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Saturday.csv\")\n",
    "Malta_TerminalStops_Sunday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Sunday.csv\")\n",
    "\n",
    "Malta_NormalandTerminalStops_Monday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Monday.csv\")\n",
    "Malta_NormalandTerminalStops_Tuesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Tuesday.csv\")\n",
    "Malta_NormalandTerminalStops_Wednesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Wednesday.csv\")\n",
    "Malta_NormalandTerminalStops_Thursday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Thursday.csv\")\n",
    "Malta_NormalandTerminalStops_Friday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Friday.csv\")\n",
    "Malta_NormalandTerminalStops_Saturday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Saturday.csv\")\n",
    "Malta_NormalandTerminalStops_Sunday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Sunday.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a47c2-d619-4610-a127-b5bb6f84ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all datasets created (for Gozo)\n",
    "Gozo_NormalStops_Monday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Monday.csv\")\n",
    "Gozo_NormalStops_Tuesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Tuesday.csv\")\n",
    "Gozo_NormalStops_Wednesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Wednesday.csv\")\n",
    "Gozo_NormalStops_Thursday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Thursday.csv\")\n",
    "Gozo_NormalStops_Friday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Friday.csv\")\n",
    "Gozo_NormalStops_Saturday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Saturday.csv\")\n",
    "Gozo_NormalStops_Sunday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Sunday.csv\")\n",
    "\n",
    "Gozo_TerminalStops_Monday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Monday.csv\")\n",
    "Gozo_TerminalStops_Tuesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Tuesday.csv\")\n",
    "Gozo_TerminalStops_Wednesday =pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Wednesday.csv\")\n",
    "Gozo_TerminalStops_Thursday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Thursday.csv\")\n",
    "Gozo_TerminalStops_Friday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Friday.csv\")\n",
    "Gozo_TerminalStops_Saturday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Saturday.csv\")\n",
    "Gozo_TerminalStops_Sunday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Sunday.csv\")\n",
    "\n",
    "Gozo_NormalandTerminalStops_Monday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Monday.csv\")\n",
    "Gozo_NormalandTerminalStops_Tuesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Tuesday.csv\")\n",
    "Gozo_NormalandTerminalStops_Wednesday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Wednesday.csv\")\n",
    "Gozo_NormalandTerminalStops_Thursday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Thursday.csv\")\n",
    "Gozo_NormalandTerminalStops_Friday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Friday.csv\")\n",
    "Gozo_NormalandTerminalStops_Saturday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Saturday.csv\")\n",
    "Gozo_NormalandTerminalStops_Sunday = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Sunday.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a3767-c29f-470d-8e8a-f661bfe72c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pandas Dataframes to show Data in table form\n",
    "\n",
    "List_Original_DataFrames =  [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta,\n",
    "                            Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "List_NormalStopsOnly_DataFrames = [Malta_NormalStops_Monday, Malta_NormalStops_Tuesday, Malta_NormalStops_Wednesday, Malta_NormalStops_Thursday, Malta_NormalStops_Friday, Malta_NormalStops_Saturday,\n",
    "                                   Malta_NormalStops_Sunday, Gozo_NormalStops_Monday, Gozo_NormalStops_Tuesday, Gozo_NormalStops_Wednesday, Gozo_NormalStops_Thursday, Gozo_NormalStops_Friday, Gozo_NormalStops_Saturday,\n",
    "                                   Gozo_NormalStops_Sunday]\n",
    "\n",
    "List_TerminalStopsOnly_DataFrames = [Malta_TerminalStops_Monday, Malta_TerminalStops_Tuesday, Malta_TerminalStops_Wednesday, Malta_TerminalStops_Thursday,\n",
    "                                    Malta_TerminalStops_Friday, Malta_TerminalStops_Saturday, Malta_TerminalStops_Sunday, Gozo_TerminalStops_Monday, Gozo_TerminalStops_Tuesday, Gozo_TerminalStops_Wednesday, Gozo_TerminalStops_Thursday,\n",
    "                                    Gozo_TerminalStops_Friday, Gozo_TerminalStops_Saturday, Gozo_TerminalStops_Sunday]\n",
    "\n",
    "List_NormalandTerminalStops_DataFrames = [Malta_NormalandTerminalStops_Monday, Malta_NormalandTerminalStops_Tuesday, Malta_NormalandTerminalStops_Wednesday, Malta_NormalandTerminalStops_Thursday,\n",
    "                                          Malta_NormalandTerminalStops_Friday, Malta_NormalandTerminalStops_Saturday, Malta_NormalandTerminalStops_Sunday, Gozo_NormalandTerminalStops_Monday, Gozo_NormalandTerminalStops_Tuesday, Gozo_NormalandTerminalStops_Wednesday, Gozo_NormalandTerminalStops_Thursday,\n",
    "                                          Gozo_NormalandTerminalStops_Friday, Gozo_NormalandTerminalStops_Saturday, Gozo_NormalandTerminalStops_Sunday]\n",
    "\n",
    "Column_List = ['Malta_Monday', 'Malta_Tuesday', 'Malta_Wednesday', 'Malta_Thursday', 'Malta_Friday',\n",
    "               'Malta_Saturday', 'Malta_Sunday', 'Gozo_Monday', 'Gozo_Tuesday', 'Gozo_Wednesday', 'Gozo_Thursday', 'Gozo_Friday',\n",
    "               'Gozo_Saturday', 'Gozo_Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875a356-1863-4344-b325-392e83df0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Total_Nodes = []\n",
    "for c in List_Original_DataFrames:\n",
    "    Total_Nodes.append(c['Bus_Stop_ID'].nunique())\n",
    "    \n",
    "Total_NormalStopsOnly = []\n",
    "for c in List_NormalStopsOnly_DataFrames:\n",
    "    Total_NormalStopsOnly.append(c['Bus_Stop_ID'].nunique())\n",
    "    \n",
    "Total_TerminalStopsOnly = []\n",
    "for c in List_TerminalStopsOnly_DataFrames:\n",
    "    Total_TerminalStopsOnly.append(c['Bus_Stop_ID'].nunique()) \n",
    "    \n",
    "Total_NormalandTerminalStops = []\n",
    "for c in List_NormalandTerminalStops_DataFrames:\n",
    "    Total_NormalandTerminalStops.append(c['Bus_Stop_ID'].nunique()) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945b44d-28d5-4150-bef7-9e81feb0ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NodeInfo_SplitByDay = pd.DataFrame([Total_Nodes, Total_NormalStopsOnly, Total_TerminalStopsOnly, Total_NormalandTerminalStops],\n",
    "                                   index=['Total Number of unique Nodes', 'Total Number of Unique Normal Stops', 'Total Number of Unique Bus Terminals',\n",
    "                                          'Total Number of Unique Stops used as both Regular Stops and Terminals'], columns= Column_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc7ab6-44b4-4f3e-9336-1c7c683fb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NodeInfo_SplitByDay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5a0c4-406c-4e51-bd9f-0c93fa33d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NodeInfo_SplitByDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15995ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446d87c-b645-43f8-b17e-9a8d25710eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Monday_Routes_Malta.to_csv(\"C://Users//attardan.CBM//Data Visualisation//Monday_Routes_Malta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3aa17-14ef-4e2f-81dd-62126a684d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Average Time Taken to traverse each 'edge' ('link')\n",
    "\n",
    "#At Home\n",
    "# Load data from 'Distinct_Edges_MALTA_IncTravelTimes' (renamed to 'Malta_DistinctEdges_IncTravelTimes') and \n",
    "# 'Distinct_Edges_GOZO_IncTravelTimes' (renamed to 'Gozo_DistinctEdges_IncTravelTimes')\n",
    "#Malta_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Creating SUMO Simulation & Obtaining Travel Times//Results//Distinct_Edges_MALTA_IncTravelTimes.csv\")\n",
    "#Gozo_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Creating SUMO Simulation & Obtaining Travel Times\\Results//Distinct_Edges_GOZO_IncTravelTimes.csv\")\n",
    "\n",
    "\n",
    "# At Work\n",
    "# Load data from 'Distinct_Edges_MALTA_IncTravelTimes' (renamed to 'Malta_DistinctEdges_IncTravelTimes') and \n",
    "# 'Distinct_Edges_GOZO_IncTravelTimes' (renamed to 'Gozo_DistinctEdges_IncTravelTimes')\n",
    "Malta_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e0771-31ee-491c-9915-cac63c9277f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning (Take shortest path if available\n",
    "# Ex. Stop 3 to Stop 819 is 56 seconds long\n",
    "# on the otherhand Stop 819 to Stop 3 is 1019 seconds long (The former is correct)\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Malta_DistinctEdges_IncTravelTimes['Standardized_Route'] = Malta_DistinctEdges_IncTravelTimes['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Malta_DistinctEdges_IncTravelTimes_Min = Malta_DistinctEdges_IncTravelTimes.loc[Malta_DistinctEdges_IncTravelTimes.groupby('Standardized_Route')['Travel_Time'].idxmin()]\n",
    "# Drop the helper column if not needed\n",
    "Malta_DistinctEdges_IncTravelTimes_Min = Malta_DistinctEdges_IncTravelTimes_Min.drop(columns=['Standardized_Route'])\n",
    "\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Gozo_DistinctEdges_IncTravelTimes['Standardized_Route'] = Gozo_DistinctEdges_IncTravelTimes['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Gozo_DistinctEdges_IncTravelTimes_Min = Gozo_DistinctEdges_IncTravelTimes.loc[Gozo_DistinctEdges_IncTravelTimes.groupby('Standardized_Route')['Travel_Time'].idxmin()]\n",
    "# Drop the helper column if not needed\n",
    "Gozo_DistinctEdges_IncTravelTimes_Min = Gozo_DistinctEdges_IncTravelTimes_Min.drop(columns=['Standardized_Route'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa203651-303c-4acc-927c-b4229bc2b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "Malta_DistinctEdges_IncTravelTimes_Min.to_csv(\"C://Users//attardan.CBM//Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes_WrongPathFix.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes_Min.to_csv(\"C://Users//attardan.CBM//Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes_WrongPathFix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd4918-94e8-4966-8357-9401220a144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.1 - Obtaining Information related to Malta\n",
    "\n",
    "# Step 5.1.1 - Find edge with maximum travel time \n",
    "Malta_DistinctEdges_IncTravelTimes_Min[Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'] == Malta_DistinctEdges_IncTravelTimes['Travel_Time'].max()]\n",
    "# Step 5.2 - Find average travelling time throughout all edges\n",
    "Average_TravelTime = Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'].mean()\n",
    "# Step 5.3 - Find median travelling time throughout all edges\n",
    "Median_TravelTime = Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'].median()\n",
    "# Step 5.4 - Obtain box plot of Travel Time\n",
    "\n",
    "# Example data (replace this with your actual DataFrame column)\n",
    "Travel_TimeData = pd.to_numeric(Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'], errors='coerce').dropna()\n",
    "\n",
    "\n",
    "# Obtaining further statistics\n",
    "minimum = np.min(Travel_TimeData)\n",
    "Q1 = np.percentile(Travel_TimeData, 25)\n",
    "median = np.median(Travel_TimeData)\n",
    "Q3 = np.percentile(Travel_TimeData, 75)\n",
    "maximum = np.max(Travel_TimeData)\n",
    "# Compute interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "# Compute whiskers (last values before outliers)\n",
    "lower_whisker = np.min(Travel_TimeData[Travel_TimeData >= (Q1 - 1.5 * IQR)].astype(float))\n",
    "upper_whisker = np.max(Travel_TimeData[Travel_TimeData <= (Q3 + 1.5 * IQR)].astype(float))\n",
    "\n",
    "# Defining figure size\n",
    "Figure = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(Travel_TimeData, vert = True, patch_artist = True)\n",
    "\n",
    "# Add title, y-axis and x-axis\n",
    "plt.xlabel(\"Edge Travel Time Date\", fontsize = 12)\n",
    "plt.ylabel(\"Travel Time (seconds)\", fontsize = 12)\n",
    "plt.title(\"Box Plot of Travel Time in Malta\", fontsize = 14)\n",
    "\n",
    "\n",
    "plt.annotate(f\"Min/Lower Whisker: {minimum:.2f}\", \n",
    "             xy=(1, minimum), \n",
    "             xytext=(1.1, minimum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Q1: {Q1:.2f}\", \n",
    "             xy=(1, Q1), \n",
    "             xytext=(1.1, Q1 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Median: {median:.2f}\", \n",
    "             xy=(1, median), \n",
    "             xytext=(1.1, median + 2),\n",
    "             fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.annotate(f\"Q3: {Q3:.2f}\", \n",
    "             xy=(1, Q3), \n",
    "             xytext=(1.1, Q3 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Max: {maximum:.2f}\", \n",
    "             xy=(1, maximum), \n",
    "             xytext=(1.1, maximum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Upper Whisker: {upper_whisker:.2f}\", \n",
    "             xy=(1, upper_whisker), \n",
    "             xytext=(1.1, upper_whisker + 2), \n",
    "             fontsize=8)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5f0bf-b8ab-4d20-94cd-e5046592c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.1 - Obtaining Information related to Malta\n",
    "\n",
    "# Step 5.1.1 - Find edge with maximum travel time \n",
    "Malta_DistinctEdges_IncTravelTimes_Min[Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'] == Malta_DistinctEdges_IncTravelTimes['Travel_Time'].max()]\n",
    "# Step 5.2 - Find average travelling time throughout all edges\n",
    "Average_TravelTime = Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'].mean()\n",
    "# Step 5.3 - Find median travelling time throughout all edges\n",
    "Median_TravelTime = Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'].median()\n",
    "# Step 5.4 - Obtain box plot of Travel Time\n",
    "\n",
    "# Example data (replace this with your actual DataFrame column)\n",
    "Travel_TimeData = pd.to_numeric(Gozo_DistinctEdges_IncTravelTimes_Min['Travel_Time'], errors='coerce').dropna()\n",
    "\n",
    "\n",
    "# Obtaining further statistics\n",
    "minimum = np.min(Travel_TimeData)\n",
    "Q1 = np.percentile(Travel_TimeData, 25)\n",
    "median = np.median(Travel_TimeData)\n",
    "Q3 = np.percentile(Travel_TimeData, 75)\n",
    "maximum = np.max(Travel_TimeData)\n",
    "# Compute interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "# Compute whiskers (last values before outliers)\n",
    "lower_whisker = np.min(Travel_TimeData[Travel_TimeData >= (Q1 - 1.5 * IQR)].astype(float))\n",
    "upper_whisker = np.max(Travel_TimeData[Travel_TimeData <= (Q3 + 1.5 * IQR)].astype(float))\n",
    "\n",
    "# Defining figure size\n",
    "Figure = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(Travel_TimeData, vert = True, patch_artist = True)\n",
    "\n",
    "# Add title, y-axis and x-axis\n",
    "plt.xlabel(\"Edge Travel Time Date\", fontsize = 12)\n",
    "plt.ylabel(\"Travel Time (seconds)\", fontsize = 12)\n",
    "plt.title(\"Box Plot of Travel Time in Gozo\", fontsize = 14)\n",
    "\n",
    "#Annotate Values to Box Plot\n",
    "plt.annotate(f\"Min/Lower Whisker: {minimum:.2f}\", \n",
    "             xy=(1, minimum), \n",
    "             xytext=(1.1, minimum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Q1: {Q1:.2f}\", \n",
    "             xy=(1, Q1), \n",
    "             xytext=(1.1, Q1 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Median: {median:.2f}\", \n",
    "             xy=(1, median), \n",
    "             xytext=(1.1, median + 2),\n",
    "             fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.annotate(f\"Q3: {Q3:.2f}\", \n",
    "             xy=(1, Q3), \n",
    "             xytext=(1.1, Q3 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Max: {maximum:.2f}\", \n",
    "             xy=(1, maximum), \n",
    "             xytext=(1.1, maximum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Upper Whisker: {upper_whisker:.2f}\", \n",
    "             xy=(1, upper_whisker), \n",
    "             xytext=(1.1, upper_whisker + 2), \n",
    "             fontsize=8)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "Bus_Stop_Info_Malta = pd.DataFrame(columns=Bus_Stop_Info.columns)\n",
    "Bus_Stop_Info_Gozo = pd.DataFrame(columns=Bus_Stop_Info.columns)\n",
    "\n",
    "\n",
    "# Store Bus Stops to avoid duplicates\n",
    "Only_Normal_stop_ids = []\n",
    "\n",
    "# Consider only Distinct Bus Terminals\n",
    "for i in range(len(Bus_Stop_Info)):\n",
    "    if Bus_Stop_Info.iloc[i]['Stop_Island'] == 'MALTA STOP':\n",
    "        Bus_Stop_Info_Malta = pd.concat([Bus_Stop_Info_Malta, Bus_Stop_Info.iloc[[i]]],\n",
    "                                                     ignore_index=True)\n",
    "    else:\n",
    "        Bus_Stop_Info_Gozo = pd.concat([Bus_Stop_Info_Gozo, Bus_Stop_Info.iloc[[i]]],\n",
    "                                                    ignore_index=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93683c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DataFrames\n",
    "Bus_Stop_Info.to_csv('C://Users//Owner//ICT5012 - Disseration//Untitled Folder//Bus_Stop_Info.csv')\n",
    "Bus_Stop_Info_Malta.to_csv('C://Users//Owner//ICT5012 - Disseration//Untitled Folder//Bus_Stop_Info_Malta.csv')\n",
    "Bus_Stop_Info_Gozo.to_csv('C://Users//Owner//ICT5012 - Disseration//Untitled Folder//Bus_Stop_Info_Gozo.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
