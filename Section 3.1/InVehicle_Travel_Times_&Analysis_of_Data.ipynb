{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c614eab",
   "metadata": {
    "id": "4c614eab"
   },
   "outputs": [],
   "source": [
    "# Importing Required Packages\n",
    "\n",
    "# Importing 'pandas' to handle datasets\n",
    "import pandas as pd\n",
    "# Importing 'numpy' to handle arrays\n",
    "import numpy as np\n",
    "\n",
    "# Importing 're' package - Python Regular Expressions\n",
    "import re\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Importing Matplotlib to visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Remove Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e369ebc",
   "metadata": {
    "id": "2e369ebc"
   },
   "source": [
    "### Step 1 - Preparing Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00cdb64",
   "metadata": {
    "id": "f00cdb64"
   },
   "source": [
    "Appending the following columns to the 'All_Routes_Complete.csv' file obtained from the Malta public transport (MPT) website\n",
    "\n",
    "    1. 'Stop Island' - Defines the island (Malta/Gozo) the corresponding Route Number operates in.\n",
    "    2. 'Time_Count' - Number of buses operating on a particular Route Number and Route Direction from the start till the end of the bus service.\n",
    "    3. 'Stops - City Name - Stop Island' - Key column used to compare data in 'All_Routes_Complete.csv' to data in Bus_Stop_Info ('Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx')\n",
    "    4. 'Longitude_Final' - Longitude value of corresponding Bus Stop entry ('Stops') obtained from Bus_Stop_Info\n",
    "    5. 'Latitude_Final' - Latitude value of corresponding Bus Stop entry ('Stops') obtained from Bus_Stop_Info\n",
    "    6. 'Bus_Stop_ID' - Unique identifier for all Bus Stops ('Stops')\n",
    "    7. 'Next_Bus_Stop_ID' - Since All_Routes ('All_Routes_Complete.csv') was extracted in sequential order from MPT website, the next row in All_Routes corresponds to the upcoming Bus Stop (Given 'Route Number', 'Route Direction' and 'Date' columns remain the same). Hence, 'Next_Bus_Stop_ID' is the unique identifier of the upcoming Bus Stop ('Stops')\n",
    "    8. 'Bus_Stop_Next_Bus_Stop'- Unique identifier used to define connection between 'Bus_Stop_ID and 'Next_Bus_Stop_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521fc3a2",
   "metadata": {
    "id": "521fc3a2"
   },
   "outputs": [],
   "source": [
    "# Step 1.1 - Load Datasets\n",
    "# Loading 'All_Routes_Complete.csv' (All_Routes) and 'Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx' (Bus_Stop_Info) Datasets\n",
    "# Recall 'All_Routes_Complete.csv' is the file which was obtained from MPT website consisting of all Bus Schedules in sequential order\n",
    "# Recall 'Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx' consits of the Longitude and Latitude data of all Bus Stops defined in 'All_Routes_Complete.csv'\n",
    "\n",
    "All_Routes = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Scraping Route Names from MPT Website//Results//All_Routes_Complete.csv\", low_memory = False)\n",
    "Bus_Stop_Info = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Obtaining Longitude and Latitude for all Bus Stops//Results (Checks Done + Manual Adjustment)//Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx\")\n",
    "\n",
    "\n",
    "# At work\n",
    "#All_Routes = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Files Used for Data Visualisation//All_Routes_Complete.csv\", low_memory = False)\n",
    "#Bus_Stop_Info = pd.read_excel(\"C://Users//attardan.CBM//Data Visualisation//Files Used for Data Visualisation//Bus_Stop_Lon_Lat_Data_Final_Manual_Update.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1450c070",
   "metadata": {
    "id": "1450c070"
   },
   "outputs": [],
   "source": [
    "# Step 1.2 - Create 'Stop Island' column\n",
    "# To differentiate between stops in Malta and Gozo, stops with correspoding 'Route Number' belonging to the 'Gozitan_Route_Number'\n",
    "# list will be labelled as 'GOZO STOP' whilst all other stops will be labelled as 'MALTA STOP' using a column entitled 'Stop Island'\n",
    "\n",
    "Gozitan_Route_Number = ['301', '302', '303',\n",
    "                        '305', '306', '307',\n",
    "                        '308', '309', '310',\n",
    "                        '311', '312', '313',\n",
    "                        '322', '323', '330',\n",
    "                        'N301']\n",
    "\n",
    "All_Routes['Stop Island'] = np.where(All_Routes['Route Number'].isin(Gozitan_Route_Number), 'GOZO STOP', 'MALTA STOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6ddb70",
   "metadata": {
    "id": "4e6ddb70"
   },
   "outputs": [],
   "source": [
    "# Step 1.3 - Create 'Time_Count' column\n",
    "# The 'Time_Count' column will be added to count the number of buses operating throughout one day for a particular route.\n",
    "# 'Time_Count' will be used as another method to identify between different routes having the same 'Route Number', 'Route Direction' and 'Date' column\n",
    "\n",
    "# Select all columns in 'All_Routes' that start with 'Stop Time'\n",
    "Stop_Time_Columns = [col for col in All_Routes.columns if col.startswith('Stop Time')]\n",
    "# Row-wise count all'Stop Time' columns which are filled in and populate the 'Time_Count' column with sum\n",
    "All_Routes['Time_Count'] = All_Routes[Stop_Time_Columns].notna().sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cddb65b5",
   "metadata": {
    "id": "cddb65b5"
   },
   "outputs": [],
   "source": [
    "# Step 1.4 - Merge 'Longitude_Final' and 'Latitude_Final' columns from 'Bus_Stop_Info' dataframe to 'All_Routes' dataframe\n",
    "\n",
    "# Create column entitled 'Stops - City Name - Stop Island' (Concatenation of 'Stops', 'City Name' and 'Stop Island' columns)\n",
    "# in both 'All_Routes' and 'Bus_Stop_Info'\n",
    "All_Routes['Stops - City Name - Stop Island'] = All_Routes['Stops'] + ' - ' + All_Routes['City Name'] + ' - ' + All_Routes['Stop Island']\n",
    "Bus_Stop_Info['Stops - City Name - Stop Island'] = Bus_Stop_Info['Stops'] + ' - ' + Bus_Stop_Info['City Name'] + ' - ' + Bus_Stop_Info['Stop_Island']\n",
    "# Merge 'Bus_Stop_Info' Dataframe to 'All_Routes' such that 'All_Routes' dataframe will have 'Longitude_Final' and 'Latitude_Final' values for all corresponding entries\n",
    "All_Routes = pd.merge(All_Routes, Bus_Stop_Info[['Stops - City Name - Stop Island', 'Longitude_Final', 'Latitude_Final']], on = 'Stops - City Name - Stop Island', how = 'left', sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be9fd82",
   "metadata": {
    "id": "4be9fd82"
   },
   "outputs": [],
   "source": [
    "# Step 1.5 - Create a unique identifier for all Bus Stops ('Stops') entitled 'Bus_Stop_ID'\n",
    "\n",
    "# Obtain Dataframe entitled 'Distinct_Coordinates' consisting only of entries with distinct 'Latitude_Final'\n",
    "# and 'Longitude_Final' pairs\n",
    "Distinct_Coordinates = All_Routes.drop_duplicates(subset = ['Latitude_Final','Longitude_Final']).copy()\n",
    "# In 'Distinct_Coordinates' add column 'Stop ID' with entries with format Stop_X where X is a value from 0 up to length of\n",
    "# 'Distinct_Coordinates' dataframe\n",
    "Distinct_Coordinates['Stop ID'] = [f'Stop_{i}' for i in range(len(Distinct_Coordinates))]\n",
    "\n",
    "# Create Dictionary entitled 'Bus_Stop_ID' consisting of corresponding 'Latitude_Final', 'Longitude_Final' and 'Stop ID' values\n",
    "Bus_Stop_ID = dict(\n",
    "    zip(\n",
    "        zip(Distinct_Coordinates['Latitude_Final'], Distinct_Coordinates['Longitude_Final']),\n",
    "        Distinct_Coordinates['Stop ID']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Using 'Bus_Stop_ID' dictionary label Bus Stops ('Stops') with their corresponding unique identifier.\n",
    "# Column is labelled as 'Bus_Stop_ID'\n",
    "# 4 - Using 'Bus_Stop_ID' dict to label All_Routes\n",
    "All_Routes['Bus_Stop_ID'] = All_Routes.apply(\n",
    "    lambda row: Bus_Stop_ID.get((row['Latitude_Final'], row['Longitude_Final']), None), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98178002",
   "metadata": {
    "id": "98178002"
   },
   "outputs": [],
   "source": [
    "# Step 1.6 - Create Column entitled 'Next_Bus_Stop_ID' consisting of the unique identifier of the upcoming stop in the route\n",
    "\n",
    "# Since All_Routes ('All_Routes_Complete.csv') was extracted in sequential order from MPT website, the next row in All_Routes\n",
    "# corresponds to the upcoming Bus Stop (Given 'Route Number', 'Route Direction' and 'Date' columns remain the same).\n",
    "# Hence, 'Reset_Conditions' is defined such that if any of 'Route Number', 'Route Direction' or 'Date' are different in\n",
    "# in the upcoming stop then upcoming stop than it is not considered to be a continuation of the current route.\n",
    "Reset_Conditions = (\n",
    "    All_Routes['Route Number'].shift(-1) != All_Routes['Route Number']) | \\\n",
    "    (All_Routes['Route Direction'].shift(-1) != All_Routes['Route Direction']) | \\\n",
    "    (All_Routes['Date'].shift(-1) != All_Routes['Date'])\n",
    "\n",
    "# In 'All_Routes' create column 'Next_Bus_Stop_ID' consisting of the upcoming 'Bus_Stop_ID'\n",
    "All_Routes['Next_Bus_Stop_ID'] = All_Routes['Bus_Stop_ID'].shift(-1)\n",
    "# If conditions defined in 'Reset_Conditions' are met, then 'Next_Bus_Stop_ID' should be blank\n",
    "All_Routes.loc[Reset_Conditions, 'Next_Bus_Stop_ID'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7841dd",
   "metadata": {
    "id": "9f7841dd"
   },
   "outputs": [],
   "source": [
    "# Step 1.7 - Create a Unique identifier used to define connection between 'Bus_Stop_ID and 'Next_Bus_Stop_ID.\n",
    "# This is done by concatinating the 'Bus_Stop_ID' and 'Next_Bus_Stop_ID' columns\n",
    "\n",
    "All_Routes['Bus_Stop_Next_Bus_Stop'] = All_Routes['Bus_Stop_ID'] + '_to_' + All_Routes['Next_Bus_Stop_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b65ddc-5f50-47d5-b89c-6120f24171d3",
   "metadata": {
    "id": "01b65ddc-5f50-47d5-b89c-6120f24171d3"
   },
   "source": [
    "### Step 2 - Adjusting All_Routes DataFrame to facilitate further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0085c75-4bd6-449e-b045-627746292af2",
   "metadata": {
    "id": "e0085c75-4bd6-449e-b045-627746292af2"
   },
   "outputs": [],
   "source": [
    "# Step 2.1 - To simply our work we will not be considering the following routes:\n",
    "# Night Routes - Not interested in specific Routes designed to work beyond the scheduled service\n",
    "# Direct Routes - Not interested in routes which make use of specially designed shorter paths\n",
    "\n",
    "#Defining list of Night Routes and Tallinja Direct Routes (Obtained from: https://www.publictransport.com.mt/en/timetables)\n",
    "Night_Direct_Routes = ['N11', 'N13', 'N212', 'N62', 'N82',\n",
    "                       'N91', 'N48', 'N301', 'TD2', 'TD10',\n",
    "                       'TD13']\n",
    "\n",
    "# Removing Night and Direct Routes from All_Routes DataFrame\n",
    "All_Routes = All_Routes[~All_Routes['Route Number'].isin(Night_Direct_Routes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8477fe-a48a-47e1-9257-2c7970d832ca",
   "metadata": {
    "id": "ac8477fe-a48a-47e1-9257-2c7970d832ca",
    "outputId": "293dcc99-df49-4614-fa4f-2e1353e903ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monday' 'Tuesday, Wednesday, Thursday, Friday' 'Saturday' 'Sunday'\n",
      " 'Monday, Tuesday, Wednesday, Thursday, Friday' 'Monday - Friday'\n",
      " 'Saturday, Sunday' 'Monday - Saturday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday, Sunday'\n",
      " 'Wednesday, Thursday, Friday, Tuesday' 'Wednesday, Thursday, Tuesday'\n",
      " 'Friday, Monday']\n"
     ]
    }
   ],
   "source": [
    "# Step 2.2 - Adjust Date names to ensure we are able to split dates accordingly\n",
    "\n",
    "# Obtain the Date Names utilised in 'All_Routes'\n",
    "# This is done since in certain 'Date' entries a hypen is utilised (Ex. 'Monday - Friday' significes 'Monday, Tuesday, Wednesday, Thursday, Friday'\n",
    "# All day names need to be represented in 'Date' field such that 'All_Routes' can be split into specific dates.\n",
    "Unique_Dates = All_Routes['Date'].unique()\n",
    "print(Unique_Dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29710480-31de-45f5-8a24-064c12b92dad",
   "metadata": {
    "id": "29710480-31de-45f5-8a24-064c12b92dad"
   },
   "outputs": [],
   "source": [
    "#Step 2.2.1 - Changes to be made\n",
    "# 1 - Change 'Monday - Friday' to 'Monday, Tuesday, Wednesday, Thursday, Friday'\n",
    "# 2 - Change 'Monday - Sunday' to 'Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday'\n",
    "# 3 - Change 'Monday - Saturday' to 'Monday, Tuesday, Wednesday, Thursday, Firday, Saturday'\n",
    "All_Routes_Copy = All_Routes.copy()\n",
    "All_Routes_Copy['Date'] = All_Routes_Copy['Date'].replace({'Monday - Friday': 'Monday, Tuesday, Wednesday, Thursday, Friday',\n",
    "                                                           'Monday - Sunday': 'Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday',\n",
    "                                                           'Monday - Saturday': 'Monday, Tuesday, Wednesday, Thursday, Friday, Saturday'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab72da9-9e0b-4fee-a849-fad3c00c9725",
   "metadata": {
    "id": "bab72da9-9e0b-4fee-a849-fad3c00c9725",
    "outputId": "aa1ae37e-c51c-45f5-8d8b-9b165d96bc9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monday' 'Tuesday, Wednesday, Thursday, Friday' 'Saturday' 'Sunday'\n",
      " 'Monday, Tuesday, Wednesday, Thursday, Friday' 'Monday - Friday'\n",
      " 'Saturday, Sunday' 'Monday - Saturday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday'\n",
      " 'Wednesday, Thursday, Friday, Monday, Tuesday, Sunday'\n",
      " 'Wednesday, Thursday, Friday, Tuesday' 'Wednesday, Thursday, Tuesday'\n",
      " 'Friday, Monday']\n"
     ]
    }
   ],
   "source": [
    "# Step 2.2.2 - Check changes have been carried out accordingly\n",
    "Unique_Dates_FollowingUpdate = All_Routes['Date'].unique()\n",
    "print(Unique_Dates_FollowingUpdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a2b46-0ddd-43f9-bde5-a3a87b245156",
   "metadata": {
    "id": "8d9a2b46-0ddd-43f9-bde5-a3a87b245156"
   },
   "source": [
    "### Step 3 - Obtaining Travel Time taken to traverse from Origin Bus Stop to Destination Bus Stop (Morning Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175da664-1827-420d-a855-afcd1669154e",
   "metadata": {
    "id": "175da664-1827-420d-a855-afcd1669154e"
   },
   "source": [
    "Using TomTom API, the following travel time metrics between an Origin Bus Stop ('Bus_Stop') and Destination Bus Stop ('Next_Bus_Stop') are obtained:\n",
    "\n",
    "    1. lengthInMeters - The route length in metres\n",
    "    2. travelTimeInSeconds - The estimated travel time in seconds (Based on current traffic levels)\n",
    "    3. noTrafficTravelTimeInSeconds - The estimated travel time in seconds excluding traffic\n",
    "    4. historicTrafficTravelTimeInSeconds - The estimated travel time in seconds (Based on historical traffic levels)\n",
    "    5. liveTrafficIncidentsTravelTimeInSeconds - The estimated travel time in seconds (Based on current traffic levels and accidents)\n",
    "    6. trafficDelayInSeconds - The delay in seconds based on real-time traffic when compared to free-flow conditions\n",
    "    7. departureTime - The estimated time of departure\n",
    "    8. arrivalTime - The estimated time of arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42c47d-b402-4fe2-a6f7-02d8d16bb67d",
   "metadata": {
    "id": "ab42c47d-b402-4fe2-a6f7-02d8d16bb67d"
   },
   "outputs": [],
   "source": [
    "# Step 3.1 - 'Bus_Stop_ID' dictionary is transformed into a dataframe entitled 'Bus_Stop_ID_Info' so that it may be referenced later on\n",
    "Bus_Stop_ID_Info = pd.DataFrame(\n",
    "    [(lat, lon, bus_stop) for (lat, lon), bus_stop in Bus_Stop_ID.items()],\n",
    "    columns=['Latitude_Final', 'Longitude_Final', 'Bus_Stop_ID']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f28ec5-2606-4d62-a503-09d415bdc1ac",
   "metadata": {
    "id": "f8f28ec5-2606-4d62-a503-09d415bdc1ac"
   },
   "outputs": [],
   "source": [
    "# Step 3.2 - A DataFrame entitled 'Distinct_Edges' is created which considers entries in the 'All_Routes' DataFrame with unique entries in\n",
    "# 'Bus_Stop_Next_Bus_Stop' column\n",
    "Distinct_Edges = All_Routes_Copy.drop_duplicates(subset = ['Bus_Stop_Next_Bus_Stop'])\n",
    "# Index is reset due to removal of entries in 'All_Routes'\n",
    "Distinct_Edges = Distinct_Edges.reset_index(drop=True)\n",
    "# Creating Copy of 'Distinct_Edges' DataFrame entitled 'Distinct_Edges_2' (s.t. any changes made in 'Distinct_Edges_2' does not impact the original\n",
    "# DataFrame\n",
    "Distinct_Edges_2 = Distinct_Edges.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c5b25-2a61-489b-884f-960b46c796e1",
   "metadata": {
    "id": "c22c5b25-2a61-489b-884f-960b46c796e1"
   },
   "outputs": [],
   "source": [
    "# Step 3.3 - Merging 'Bus_Stop_ID_Info' with 'Distinct_Edges_2'. Currently 'Bus_Stop_ID_Info' consists of coordinate data related to the origin\n",
    "# Bus Stop. Hence, coordinate data related to the destination Bus Stop will also be added.\n",
    "\n",
    "# Change Column Names of 'Bus_Stop_ID_Info' DataFrame such that it is apparent that coordinate values and Bus_Stop_ID values are referring to the\n",
    "# destination Bus Stop. In addition, 'Bus_Stop_ID_Info' is renamed to 'Bus_Stop_ID_Info_2'\n",
    "Bus_Stop_ID_Info_2 = Bus_Stop_ID_Info.rename(columns = {'Latitude_Final': 'Latitude_Next', 'Longitude_Final': 'Longitude_Next', 'Bus_Stop_ID': 'Bus_Stop_ID_2'})\n",
    "# The 'Bus_Stop_ID_2', 'Latitude_Next', 'Longitude_Next' columns from 'Bus_Stop_ID_Info_2' are merged with 'Distinct_Edges_2' DataFrame.\n",
    "# Corresponding entries should have identical entries in 'Next_Bus_Stop_ID' and 'Bus_Stop_ID_2' columns\n",
    "Distinct_Edges_2 = pd.merge(Distinct_Edges_2, Bus_Stop_ID_Info_2[['Bus_Stop_ID_2', 'Latitude_Next', 'Longitude_Next']], left_on = 'Next_Bus_Stop_ID', right_on = 'Bus_Stop_ID_2', how = 'left', sort = False)\n",
    "# Entries in 'Bus_Stop_ID_2' Column are replicated by entries in 'Next_Bus_Stop_ID' hence the former can be removed\n",
    "Distinct_Edges_2 = Distinct_Edges_2.drop(columns = 'Bus_Stop_ID_2')\n",
    "# Remove entries if 'Next_Bus_Stop_ID' is blank\n",
    "Distinct_Edges_2 = Distinct_Edges_2.dropna(subset=['Next_Bus_Stop_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a29c3a-7d96-4d89-8544-613fd42e0a0f",
   "metadata": {
    "id": "62a29c3a-7d96-4d89-8544-613fd42e0a0f"
   },
   "outputs": [],
   "source": [
    "# Step 3.4 - Free Version of TomTom API only Allows for 2500 Non-Tile Requests per-day. The entire datasets would require 2516 requests to complete.\n",
    "# As a result, the 'Distinc_Edges_2' Dataset will be split into two using the 'Stop Island' column. Following DataFrames are obtained:\n",
    "# 1 - Distinct_Edges_MALTA - Includes all entries in 'Distinct_Edges_2' where 'Stop Island' column has entries 'MALTA STOP'\n",
    "# 2 - Distinct_Edges_GOZO - Includes all entries in 'Distinct_Edges_2' where 'Stop Island' column has entries 'GOZO STOP'\n",
    "Distinct_Edges_MALTA = Distinct_Edges_2.loc[Distinct_Edges_2[\"Stop Island\"] == \"MALTA STOP\"]\n",
    "Distinct_Edges_GOZO = Distinct_Edges_2.loc[Distinct_Edges_2[\"Stop Island\"] == \"GOZO STOP\"]\n",
    "# Since file is obtained sequentially (Gozo routes are listed last in the MPT Website (https://www.publictransport.com.mt/en/timetables)\n",
    "# Then index is reset for 'Distinct_Edges_Gozo' to ensure for loops utilised will work correctly\n",
    "Distinct_Edges_MALTA = Distinct_Edges_MALTA.reset_index(drop=True)\n",
    "Distinct_Edges_GOZO = Distinct_Edges_GOZO.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a9f2b",
   "metadata": {},
   "source": [
    "### Obtaining Travel Time for Malta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b68e4",
   "metadata": {},
   "source": [
    "#### Step 1 - All Maltese Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef161b-e4ce-4e43-893a-7d98d682d2fe",
   "metadata": {
    "id": "e3ef161b-e4ce-4e43-893a-7d98d682d2fe",
    "outputId": "3b1d15cc-3cfc-4e12-f2ad-7b1c89a6050b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3.5 - Obtaining travel time metrics for Malta\n",
    "\n",
    "# Step 3.5.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = '4x14GdbcGGsXeen6yUhicscKFbz28iMj'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(Distinct_Edges_MALTA)):\n",
    "    print(f\"Processing request {i+1} of {len(Distinct_Edges_MALTA)}\")\n",
    "    departure_time = \"2025-03-10T07:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{Distinct_Edges_MALTA['Latitude_Final'][i]}%2C{Distinct_Edges_MALTA['Longitude_Final'][i]}%3A{Distinct_Edges_MALTA['Latitude_Next'][i]}%2C{Distinct_Edges_MALTA['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970aff0-985b-4f13-bce2-c3e90497509c",
   "metadata": {
    "id": "9970aff0-985b-4f13-bce2-c3e90497509c"
   },
   "outputs": [],
   "source": [
    "# Step 3.5.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "Distinct_Edges_MALTA_IncTravelTimes_Morning = Distinct_Edges_MALTA.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "Distinct_Edges_MALTA_IncTravelTimes_Morning.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes_Morning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f3271",
   "metadata": {},
   "source": [
    "#### Step 2 - All Necessary Maltese Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76957f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "New_Distinct_Edges_Malta = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_To_Be_Added_Malta.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a43fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3.5 - Obtaining travel time metrics for Malta\n",
    "\n",
    "# Step 3.5.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = '4x14GdbcGGsXeen6yUhicscKFbz28iMj'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(New_Distinct_Edges_Malta)):\n",
    "    print(f\"Processing request {i+1} of {len(New_Distinct_Edges_Malta)}\")\n",
    "    departure_time = \"2025-03-10T07:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{New_Distinct_Edges_Malta['Latitude_Final'][i]}%2C{New_Distinct_Edges_Malta['Longitude_Final'][i]}%3A{New_Distinct_Edges_Malta['Latitude_Next'][i]}%2C{New_Distinct_Edges_Malta['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.5.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Morning = New_Distinct_Edges_Malta.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Morning.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Malta_IncTravelTimes_Morning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d40fbb",
   "metadata": {},
   "source": [
    "### Obtaining Travel Time for Gozo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c7c19b-556f-4606-8903-7a135dbcb471",
   "metadata": {
    "id": "f6c7c19b-556f-4606-8903-7a135dbcb471",
    "outputId": "a9e9c7b4-7a89-4fc2-e7d3-04d00818f332",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3.6 - Obtaining travel time metrics for Gozo\n",
    "\n",
    "# Step 3.6.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = 'uA2d36BEe5Xby9As7hUgrBmGL34u4n0h'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(Distinct_Edges_GOZO)):\n",
    "    print(f\"Processing request {i+1} of {len(Distinct_Edges_GOZO)}\")\n",
    "    departure_time = \"2025-03-10T07:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{Distinct_Edges_GOZO['Latitude_Final'][i]}%2C{Distinct_Edges_GOZO['Longitude_Final'][i]}%3A{Distinct_Edges_GOZO['Latitude_Next'][i]}%2C{Distinct_Edges_GOZO['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcb3d7-f076-48c5-8915-acc1a22729a3",
   "metadata": {
    "id": "37dcb3d7-f076-48c5-8915-acc1a22729a3"
   },
   "outputs": [],
   "source": [
    "# Step 3.6.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_GOZO' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "Distinct_Edges_GOZO_IncTravelTimes_Morning = Distinct_Edges_GOZO.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "Distinct_Edges_GOZO_IncTravelTimes_Morning.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes_Morning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7807aed",
   "metadata": {},
   "source": [
    "#### Step 2 - All Necessary Gozitan Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "New_Distinct_Edges_Gozo = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_To_Be_Added_Gozo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.5 - Obtaining travel time metrics for Malta\n",
    "\n",
    "# Step 3.5.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = '4x14GdbcGGsXeen6yUhicscKFbz28iMj'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(New_Distinct_Edges_Gozo)):\n",
    "    print(f\"Processing request {i+1} of {len(New_Distinct_Edges_Gozo)}\")\n",
    "    departure_time = \"2025-03-10T07:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{New_Distinct_Edges_Gozo['Latitude_Final'][i]}%2C{New_Distinct_Edges_Gozo['Longitude_Final'][i]}%3A{New_Distinct_Edges_Gozo['Latitude_Next'][i]}%2C{New_Distinct_Edges_Gozo['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.5.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Morning = New_Distinct_Edges_Gozo.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Morning.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Gozo_IncTravelTimes_Morning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe082c6",
   "metadata": {},
   "source": [
    "### Step 3 - Obtaining Travel Time taken to traverse from Origin Bus Stop to Destination Bus Stop (Evening Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae1b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3.1 - 'Bus_Stop_ID' dictionary is transformed into a dataframe entitled 'Bus_Stop_ID_Info' so that it may be referenced later on\n",
    "Bus_Stop_ID_Info = pd.DataFrame(\n",
    "    [(lat, lon, bus_stop) for (lat, lon), bus_stop in Bus_Stop_ID.items()],\n",
    "    columns=['Latitude_Final', 'Longitude_Final', 'Bus_Stop_ID']\n",
    ")\n",
    "\n",
    "# Step 3.2 - A DataFrame entitled 'Distinct_Edges' is created which considers entries in the 'All_Routes' DataFrame with unique entries in\n",
    "# 'Bus_Stop_Next_Bus_Stop' column\n",
    "Distinct_Edges = All_Routes_Copy.drop_duplicates(subset = ['Bus_Stop_Next_Bus_Stop'])\n",
    "# Index is reset due to removal of entries in 'All_Routes'\n",
    "Distinct_Edges = Distinct_Edges.reset_index(drop=True)\n",
    "# Creating Copy of 'Distinct_Edges' DataFrame entitled 'Distinct_Edges_2' (s.t. any changes made in 'Distinct_Edges_2' does not impact the original\n",
    "# DataFrame\n",
    "Distinct_Edges_2 = Distinct_Edges.copy()\n",
    "\n",
    "# Step 3.3 - Merging 'Bus_Stop_ID_Info' with 'Distinct_Edges_2'. Currently 'Bus_Stop_ID_Info' consists of coordinate data related to the origin\n",
    "# Bus Stop. Hence, coordinate data related to the destination Bus Stop will also be added.\n",
    "\n",
    "# Change Column Names of 'Bus_Stop_ID_Info' DataFrame such that it is apparent that coordinate values and Bus_Stop_ID values are referring to the\n",
    "# destination Bus Stop. In addition, 'Bus_Stop_ID_Info' is renamed to 'Bus_Stop_ID_Info_2'\n",
    "Bus_Stop_ID_Info_2 = Bus_Stop_ID_Info.rename(columns = {'Latitude_Final': 'Latitude_Next', 'Longitude_Final': 'Longitude_Next', 'Bus_Stop_ID': 'Bus_Stop_ID_2'})\n",
    "# The 'Bus_Stop_ID_2', 'Latitude_Next', 'Longitude_Next' columns from 'Bus_Stop_ID_Info_2' are merged with 'Distinct_Edges_2' DataFrame.\n",
    "# Corresponding entries should have identical entries in 'Next_Bus_Stop_ID' and 'Bus_Stop_ID_2' columns\n",
    "Distinct_Edges_2 = pd.merge(Distinct_Edges_2, Bus_Stop_ID_Info_2[['Bus_Stop_ID_2', 'Latitude_Next', 'Longitude_Next']], left_on = 'Next_Bus_Stop_ID', right_on = 'Bus_Stop_ID_2', how = 'left', sort = False)\n",
    "# Entries in 'Bus_Stop_ID_2' Column are replicated by entries in 'Next_Bus_Stop_ID' hence the former can be removed\n",
    "Distinct_Edges_2 = Distinct_Edges_2.drop(columns = 'Bus_Stop_ID_2')\n",
    "# Remove entries if 'Next_Bus_Stop_ID' is blank\n",
    "Distinct_Edges_2 = Distinct_Edges_2.dropna(subset=['Next_Bus_Stop_ID'])\n",
    "\n",
    "# Step 3.4 - Free Version of TomTom API only Allows for 2500 Non-Tile Requests per-day. The entire datasets would require 2516 requests to complete.\n",
    "# As a result, the 'Distinc_Edges_2' Dataset will be split into two using the 'Stop Island' column. Following DataFrames are obtained:\n",
    "# 1 - Distinct_Edges_MALTA - Includes all entries in 'Distinct_Edges_2' where 'Stop Island' column has entries 'MALTA STOP'\n",
    "# 2 - Distinct_Edges_GOZO - Includes all entries in 'Distinct_Edges_2' where 'Stop Island' column has entries 'GOZO STOP'\n",
    "Distinct_Edges_MALTA = Distinct_Edges_2.loc[Distinct_Edges_2[\"Stop Island\"] == \"MALTA STOP\"]\n",
    "Distinct_Edges_GOZO = Distinct_Edges_2.loc[Distinct_Edges_2[\"Stop Island\"] == \"GOZO STOP\"]\n",
    "# Since file is obtained sequentially (Gozo routes are listed last in the MPT Website (https://www.publictransport.com.mt/en/timetables)\n",
    "# Then index is reset for 'Distinct_Edges_Gozo' to ensure for loops utilised will work correctly\n",
    "Distinct_Edges_MALTA = Distinct_Edges_MALTA.reset_index(drop=True)\n",
    "Distinct_Edges_GOZO = Distinct_Edges_GOZO.reset_index(drop=True)\n",
    "\n",
    "### Obtaining Travel Time for Malta\n",
    "\n",
    "#### Step 1 - All Maltese Connections\n",
    "\n",
    "# Step 3.5 - Obtaining travel time metrics for Malta\n",
    "\n",
    "# Step 3.5.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = 'Q3ZiGJ3NOOqTLUjevY067wJa9EUcUNzL'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(Distinct_Edges_MALTA)):\n",
    "    print(f\"Processing request {i+1} of {len(Distinct_Edges_MALTA)}\")\n",
    "    departure_time = \"2025-03-10T16:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{Distinct_Edges_MALTA['Latitude_Final'][i]}%2C{Distinct_Edges_MALTA['Longitude_Final'][i]}%3A{Distinct_Edges_MALTA['Latitude_Next'][i]}%2C{Distinct_Edges_MALTA['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n",
    "\n",
    "\n",
    "# Step 3.5.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "Distinct_Edges_MALTA_IncTravelTimes_Evening = Distinct_Edges_MALTA.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "Distinct_Edges_MALTA_IncTravelTimes_Evening.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes_Evening.csv\")\n",
    "\n",
    "#### Step 2 - All Necessary Maltese Connections\n",
    "\n",
    "# Load Dataset\n",
    "New_Distinct_Edges_Malta = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_To_Be_Added_Malta.xlsx\")\n",
    "\n",
    "# Step 3.5 - Obtaining travel time metrics for Malta\n",
    "\n",
    "# Step 3.5.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = 'Q3ZiGJ3NOOqTLUjevY067wJa9EUcUNzL'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(New_Distinct_Edges_Malta)):\n",
    "    print(f\"Processing request {i+1} of {len(New_Distinct_Edges_Malta)}\")\n",
    "    departure_time = \"2025-03-10T16:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{New_Distinct_Edges_Malta['Latitude_Final'][i]}%2C{New_Distinct_Edges_Malta['Longitude_Final'][i]}%3A{New_Distinct_Edges_Malta['Latitude_Next'][i]}%2C{New_Distinct_Edges_Malta['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n",
    "\n",
    "\n",
    "# Step 3.5.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Evening = New_Distinct_Edges_Malta.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Evening.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Malta_IncTravelTimes_Evening.csv\")\n",
    "\n",
    "### Obtaining Travel Time for Gozo\n",
    "\n",
    "# Step 3.6 - Obtaining travel time metrics for Gozo\n",
    "\n",
    "# Step 3.6.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = 'uA2d36BEe5Xby9As7hUgrBmGL34u4n0h'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(Distinct_Edges_GOZO)):\n",
    "    print(f\"Processing request {i+1} of {len(Distinct_Edges_GOZO)}\")\n",
    "    departure_time = \"2025-03-10T16:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{Distinct_Edges_GOZO['Latitude_Final'][i]}%2C{Distinct_Edges_GOZO['Longitude_Final'][i]}%3A{Distinct_Edges_GOZO['Latitude_Next'][i]}%2C{Distinct_Edges_GOZO['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n",
    "\n",
    "\n",
    "# Step 3.6.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_GOZO' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "Distinct_Edges_GOZO_IncTravelTimes_Evening = Distinct_Edges_GOZO.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "Distinct_Edges_GOZO_IncTravelTimes_Evening.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes_Evening.csv\")\n",
    "\n",
    "#### Step 2 - All Necessary Gozitan Connections\n",
    "\n",
    "# Load Dataset\n",
    "New_Distinct_Edges_Gozo = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_To_Be_Added_Gozo.xlsx\")\n",
    "\n",
    "# Step 3.5 - Obtaining travel time metrics for Malta\n",
    "\n",
    "# Step 3.5.1 - Utilise TomTom to obtain the edge treversal metrics described in introduction of Step 3.\n",
    "# TomTom API Key\n",
    "TOMTOM_API_Key = '4x14GdbcGGsXeen6yUhicscKFbz28iMj'\n",
    "\n",
    "#Defining empty lists to be used to append data to\n",
    "Length_In_Metres = []\n",
    "Travel_Time = []\n",
    "Travel_Time_No_Traffic = []\n",
    "Historic_Traffic_Travel_Time = []\n",
    "Live_Traffic_Travel_Time = []\n",
    "Traffic_Delay = []\n",
    "Departure_Time = []\n",
    "Arrival_Time = []\n",
    "\n",
    "# for loop going over all entries in 'Distinct_Edges_MALTA' and passing the following information as a request using TomTom API:\n",
    "# 1. Latitude_Final - Latitiude of origin\n",
    "# 2. Longitude_Final - Longitude of origin\n",
    "# 3. Latitude_Next - Latitude of destination\n",
    "# 4. Longitude_Next - Longitude of destination\n",
    "for i in range(len(New_Distinct_Edges_Gozo)):\n",
    "    print(f\"Processing request {i+1} of {len(New_Distinct_Edges_Gozo)}\")\n",
    "    departure_time = \"2025-03-10T16:00:00Z\"\n",
    "    url = f\"https://api.tomtom.com/routing/1/calculateRoute/{New_Distinct_Edges_Gozo['Latitude_Final'][i]}%2C{New_Distinct_Edges_Gozo['Longitude_Final'][i]}%3A{New_Distinct_Edges_Gozo['Latitude_Next'][i]}%2C{New_Distinct_Edges_Gozo['Longitude_Next'][i]}/json?maxAlternatives=1&computeTravelTimeFor=all&departAt={departure_time}&includeTollPaymentTypes=none&routeType=shortest&traffic=true&travelMode=bus&key={TOMTOM_API_Key}\"\n",
    "    Response_Website = requests.get(url)\n",
    "\n",
    "    # If Status_code value is 200 this implies TomTom has completed succesfully.\n",
    "    # If status_code is not 200, the provided status_code and error message will be printed by the code.\n",
    "    if Response_Website.status_code == 200:\n",
    "        Result = Response_Website.json()\n",
    "\n",
    "\n",
    "        # Extract values from the 'Result' given by TomTom API for the corresponding edge\n",
    "        Length_In_Metres_Value = Result['routes'][0]['summary']['lengthInMeters']\n",
    "        Travel_Time_Value = Result['routes'][0]['summary']['travelTimeInSeconds']\n",
    "        Travel_Time_No_Traffic_Value = Result['routes'][0]['summary']['noTrafficTravelTimeInSeconds']\n",
    "        Historic_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['historicTrafficTravelTimeInSeconds']\n",
    "        Live_Traffic_Travel_Time_Value = Result['routes'][0]['summary']['liveTrafficIncidentsTravelTimeInSeconds']\n",
    "        Traffic_Delay_Value = Result['routes'][0]['summary']['trafficDelayInSeconds']\n",
    "        Departure_Time_Value = Result['routes'][0]['summary']['departureTime']\n",
    "        Arrival_Time_Value = Result['routes'][0]['summary']['arrivalTime']\n",
    "\n",
    "        # Append values to list\n",
    "        Length_In_Metres.append(Length_In_Metres_Value)\n",
    "        Travel_Time.append(Travel_Time_Value)\n",
    "        Travel_Time_No_Traffic.append(Travel_Time_No_Traffic_Value)\n",
    "        Historic_Traffic_Travel_Time.append(Historic_Traffic_Travel_Time_Value)\n",
    "        Live_Traffic_Travel_Time.append(Live_Traffic_Travel_Time_Value)\n",
    "        Traffic_Delay.append(Traffic_Delay_Value)\n",
    "        Departure_Time.append(Departure_Time_Value)\n",
    "        Arrival_Time.append(Arrival_Time_Value)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: HTTP {Response_Website.status_code} - {Response_Website.text}\")\n",
    "\n",
    "    # Introduce a delay of 1 second between each request to avoid too many requests per second\n",
    "    time.sleep(0.25)\n",
    "\n",
    "\n",
    "# Step 3.5.2 - Assign edge traversal information obtained via TomTom API to 'Distinct_Edges_MALTA' as follows:\n",
    "# 'Travel_Time' Column - Travel_Time\n",
    "# 'Travel_Time_No_Traffic' Column - 'Travel_Time_No_Traffic' list\n",
    "# 'Historic_Traffic_Travel_Time' Column - 'Historic_Traffic_Travel_Time' list\n",
    "# 'Live_Traffic_Travel_Time' Column - 'Live_Traffic_Travel_Time' list\n",
    "# 'Traffic_Delay' Column - 'Traffic_Delay' list\n",
    "# 'Length_In_Metres' Column - 'Length_In_Metres' list\n",
    "# 'Departure_Time' Column - 'Departure_Time' list\n",
    "# 'Arrival_Time' Column - 'Arrival_Time' list\n",
    "\n",
    "#NB: Result DataFrame is renamed to 'Distinct_Edges_MALTA_IncTravelTimes'\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Evening = New_Distinct_Edges_Gozo.assign(Travel_Time = Travel_Time, Travel_Time_No_Traffic = Travel_Time_No_Traffic,\n",
    "                                                          Historic_Traffic_Travel_Time = Historic_Traffic_Travel_Time, Live_Traffic_Travel_Time = Live_Traffic_Travel_Time,\n",
    "                                                          Traffic_Delay = Traffic_Delay, Length_In_Metres=Length_In_Metres, Departure_Time = Departure_Time, Arrival_Time = Arrival_Time)\n",
    "\n",
    "# 'Distinct_Edges_MALTA_IncTravelTimes' is saved such that it can be loaded in future instances\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Evening.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Gozo_IncTravelTimes_Evening.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84047b2-9b82-499b-92b6-ae06983969aa",
   "metadata": {
    "id": "e84047b2-9b82-499b-92b6-ae06983969aa"
   },
   "source": [
    "### Step 4.1 - Analysing Route, both in Malta and Gozo, according to day of the week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966bbbfe-310c-49e9-ab5a-bb9524395732",
   "metadata": {
    "id": "966bbbfe-310c-49e9-ab5a-bb9524395732"
   },
   "source": [
    "This is being done, since routes of the Maltese Public Transport Network experiences changes depending on the day being considered. Hence, we will consider the following DataFrames extracted from All_Routes:\n",
    "\n",
    "    1. Monday_Routes_Malta - Routes operating in Malta on a Monday\n",
    "    2. Tuesday_Routes_Malta - Routes operating in Malta on a Tuesday\n",
    "    3. Wednesday_Routes_Malta - Routes operating in Malta on a Wednesday\n",
    "    4. Thursday_Routes_Malta - Routes operating in Malta on a Thursday\n",
    "    5. Friday_Routes_Malta - Routes operating in Malta on a Friday\n",
    "    6. Saturday_Routes_Malta - Routes operating in Malta on a Saturday\n",
    "    7. Sunday_Routes_Malta - Routes operating in Malta on a Sunday\n",
    "    8. Monday_Routes_Gozo - Routes operating in Gozo on a Monday\n",
    "    9. Tuesday_Routes_Gozo - Routes operating in Gozo on a Tuesday\n",
    "    10. Wednesday_Routes_Gozo - Routes operating in Gozo on a Wendesday\n",
    "    11. Thursday_Routes_Gozo - Routes operating in Gozo on a Thursday\n",
    "    12. Friday_Routes_Gozo - Routes operating in Gozo on a Friday\n",
    "    13. Saturday_Routes_Gozo - Routes operating in Gozo on a Saturday\n",
    "    14. Sunday_Routes_Gozo - Routes operating in Gozo on a Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e179c4-c692-4dc8-98b2-9e607ae7c022",
   "metadata": {
    "id": "82e179c4-c692-4dc8-98b2-9e607ae7c022"
   },
   "outputs": [],
   "source": [
    "# Step 4 - We will proceed by splitting the 'All_Routes_Copy' into the following fourteen separate dataframes described above.\n",
    "\n",
    "# List of days in which Public Transportation System Functions\n",
    "List_Dates = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# 'Rows_Date_Dict' - Dictionary to store only instances of the same date\n",
    "Rows_Date_Dict = {}\n",
    "# 'Malta_Dict' - Dictionary to store only instances of the same date operating in Malta\n",
    "Malta_Dict = {}\n",
    "# 'Gozo_Dict' - Dictionary to store only instances of the same date operating in Gozo\n",
    "Gozo_Dict = {}\n",
    "\n",
    "# for loop going over List_Dates defined above\n",
    "for c in List_Dates:\n",
    "    # filter rows according to date 'c' currently being considered\n",
    "    Rows_Date_Dict[c] = All_Routes_Copy[All_Routes_Copy['Date'].astype(str).str.contains(c, na=False)]\n",
    "\n",
    "    # split entries present in 'Rows_Date_Dict[c]' accordng to 'Stop Island' value\n",
    "    Malta_Dict[c] = Rows_Date_Dict[c][Rows_Date_Dict[c]['Stop Island'] == 'MALTA STOP'].reset_index(drop=True)\n",
    "    Gozo_Dict[c] = Rows_Date_Dict[c][Rows_Date_Dict[c]['Stop Island'] == 'GOZO STOP'].reset_index(drop=True)\n",
    "\n",
    "# Naming Dataframes\n",
    "Monday_Routes_Malta = Malta_Dict['Monday']\n",
    "Tuesday_Routes_Malta = Malta_Dict['Tuesday']\n",
    "Wednesday_Routes_Malta = Malta_Dict['Wednesday']\n",
    "Thursday_Routes_Malta = Malta_Dict['Thursday']\n",
    "Friday_Routes_Malta = Malta_Dict['Friday']\n",
    "Saturday_Routes_Malta = Malta_Dict['Saturday']\n",
    "Sunday_Routes_Malta = Malta_Dict['Sunday']\n",
    "Monday_Routes_Gozo = Gozo_Dict['Monday']\n",
    "Tuesday_Routes_Gozo = Gozo_Dict['Tuesday']\n",
    "Wednesday_Routes_Gozo = Gozo_Dict['Wednesday']\n",
    "Thursday_Routes_Gozo = Gozo_Dict['Thursday']\n",
    "Friday_Routes_Gozo = Gozo_Dict['Friday']\n",
    "Saturday_Routes_Gozo = Gozo_Dict['Saturday']\n",
    "Sunday_Routes_Gozo = Gozo_Dict['Sunday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5fbb105-c90d-469f-8289-037acdda6644",
   "metadata": {
    "id": "c5fbb105-c90d-469f-8289-037acdda6644",
    "outputId": "84301d1a-4559-49fc-c502-d9da5c3f7858"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Malta Routes</th>\n",
       "      <th>Gozo Routes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>92</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>92</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day  Malta Routes  Gozo Routes\n",
       "0     Monday            97           15\n",
       "1    Tuesday            97           15\n",
       "2  Wednesday            97           15\n",
       "3   Thursday            97           15\n",
       "4     Friday            97           15\n",
       "5   Saturday            92           15\n",
       "6     Sunday            92           15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4.1 - Obtain Number of routes covered each day both in Malta and Gozo\n",
    "\n",
    "Malta_Route_DataFrames_List = [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta]\n",
    "Gozo_Route_DataFrames_List = [Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "# List of days\n",
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# Compute number of unique routes per day for Malta\n",
    "malta_routes = [len(df['Route Number'].unique()) for df in Malta_Route_DataFrames_List]\n",
    "# Compute number of unique routes per day for Gozo\n",
    "gozo_routes = [len(df['Route Number'].unique()) for df in Gozo_Route_DataFrames_List]\n",
    "\n",
    "# Create DataFrame\n",
    "route_data = pd.DataFrame({\n",
    "    \"Day\": days,\n",
    "    \"Malta Routes\": malta_routes,\n",
    "    \"Gozo Routes\": gozo_routes\n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "route_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f95e39-c27c-47bd-9417-38985beca25d",
   "metadata": {
    "id": "17f95e39-c27c-47bd-9417-38985beca25d"
   },
   "outputs": [],
   "source": [
    "# Step 4.2 - Obtain table indicating number of bus stops traversed by each route, also taking into account day of the week (To simplify problem,\n",
    "#for any non-circular stops we will consider only the maximum number of stops in any one direction)\n",
    "\n",
    "# Initialize an empty dictionary to store result of number of stops of each route per day\n",
    "Malta_Stops_Per_Route_PerDay = {}\n",
    "Gozo_Stops_Per_Route_PerDay = {}\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in Malta_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    i_copy['Concatenated_Columns'] = (i_copy['Route Number'] + '-' + i_copy['Route Direction'] + '-' + i_copy['Time_Count'].astype(str))\n",
    "    # Count the number of rows in each group\n",
    "    group_sizes = i_copy.groupby('Concatenated_Columns').size()\n",
    "    # Map group sizes back to the original DataFrame\n",
    "    i_copy['Group'] = i_copy['Concatenated_Columns'].map(group_sizes)\n",
    "    # Drop temporary columns if not needed\n",
    "    i_copy.drop(columns=['Concatenated_Columns'], inplace=True)\n",
    "    # Count the size of each group\n",
    "    Partition_Count = i_copy.groupby(['Route Number', 'Group']).size()\n",
    "    #Convert Partition_Count to a DataFrame\n",
    "    Partition_Count = Partition_Count.reset_index(name='Count')\n",
    "    # Find the maximum size for each Route Number (Group)\n",
    "    Malta_Stops_Per_Route = Partition_Count.groupby('Route Number')['Group'].max()\n",
    "    Malta_Stops_Per_Route_PerDay[List_Dates[j]] = Malta_Stops_Per_Route\n",
    "    j += 1\n",
    "\n",
    "\n",
    "k = 0\n",
    "Gozo_Stops_Per_Route_PerDay = {}  # Ensure dictionary is initialized\n",
    "for i in Gozo_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    i_copy['Concatenated_Columns'] = (i_copy['Route Number'] + '-' + i_copy['Route Direction'] + i_copy['Time_Count'].astype(str))\n",
    "    # Count the number of rows in each group\n",
    "    group_sizes = i_copy.groupby('Concatenated_Columns').size()\n",
    "    # Map group sizes back to the original DataFrame\n",
    "    i_copy['Group'] = i_copy['Concatenated_Columns'].map(group_sizes)\n",
    "    # Drop temporary columns if not needed\n",
    "    i_copy.drop(columns=['Concatenated_Columns'], inplace=True)\n",
    "    # Count the size of each group\n",
    "    Partition_Count = i_copy.groupby(['Route Number', 'Group']).size()\n",
    "    Partition_Count = Partition_Count.reset_index(name='Count')\n",
    "    # Find the maximum size for each Route Number\n",
    "    Gozo_Stops_Per_Route = Partition_Count.groupby('Route Number')['Group'].max()\n",
    "    Gozo_Stops_Per_Route_PerDay[List_Dates[k]] = Gozo_Stops_Per_Route\n",
    "    k += 1\n",
    "\n",
    "# Naming Dataframes\n",
    "Monday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Monday']\n",
    "Tuesday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Tuesday']\n",
    "Wednesday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Wednesday']\n",
    "Thursday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Thursday']\n",
    "Friday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Friday']\n",
    "Saturday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Saturday']\n",
    "Sunday_NoStopsPerRoute_Malta = Malta_Stops_Per_Route_PerDay['Sunday']\n",
    "Monday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Monday']\n",
    "Tuesday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Tuesday']\n",
    "Wednesday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Wednesday']\n",
    "Thursday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Thursday']\n",
    "Friday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Friday']\n",
    "Saturday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Saturday']\n",
    "Sunday_NoStopsPerRoute_Gozo = Gozo_Stops_Per_Route_PerDay['Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93fca8-8b98-4c73-9d60-005be1f824da",
   "metadata": {
    "id": "9b93fca8-8b98-4c73-9d60-005be1f824da",
    "outputId": "c9216d5d-5247-4b8c-9996-099b4bc8215d"
   },
   "outputs": [],
   "source": [
    "# Step 4.2.1 - Combine Data, related to Malta, in One DataFrame with the following\n",
    "    # 1. Column - Day of the week\n",
    "    # 2. Rows - Route Number\n",
    "    # 3. Entries in DataFrame - Number of Bus Stops traverrsed by each Route\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Malta_RoutePresencePerDay__and_BusStopsVisited'\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited = pd.concat([Monday_NoStopsPerRoute_Malta, Tuesday_NoStopsPerRoute_Malta, Wednesday_NoStopsPerRoute_Malta,\n",
    "                                                           Thursday_NoStopsPerRoute_Malta, Friday_NoStopsPerRoute_Malta, Saturday_NoStopsPerRoute_Malta,\n",
    "                                                           Sunday_NoStopsPerRoute_Malta], axis=1)\n",
    "# Replace 'N/A' with NaN\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited = Malta_RoutePresencePerDay__and_BusStopsVisited.astype('Int64')\n",
    "# Rename Columns\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited.columns = List_Dates\n",
    "# Display DataFrame\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b657608-8a3d-4281-b1de-6f096e80cd78",
   "metadata": {
    "id": "1b657608-8a3d-4281-b1de-6f096e80cd78",
    "outputId": "19ff184e-3bbb-4f55-af1a-d0ea67d973b1"
   },
   "outputs": [],
   "source": [
    "# Step 4.2.2 - Combine Data, related to Gozo, in One DataFrame with the following\n",
    "    # 1. Column - Day of the week\n",
    "    # 2. Rows - Route Number\n",
    "    # 3. Entries in DataFrame - Number of Bus Stops traverrsed by each Route\n",
    "\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Gozo_RoutePresencePerDay__and_BusStopsVisited'\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited = pd.concat([Monday_NoStopsPerRoute_Gozo, Tuesday_NoStopsPerRoute_Gozo, Wednesday_NoStopsPerRoute_Gozo,\n",
    "                                                           Thursday_NoStopsPerRoute_Gozo, Friday_NoStopsPerRoute_Gozo, Saturday_NoStopsPerRoute_Gozo,\n",
    "                                                           Sunday_NoStopsPerRoute_Gozo], axis=1)\n",
    "# Replace 'N/A' with NaN\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited = Gozo_RoutePresencePerDay__and_BusStopsVisited.astype('Int64')\n",
    "# Rename Columns\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited.columns = List_Dates\n",
    "# Display DataFrame\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d812ed7-b477-49ca-80c2-5b7de278e66f",
   "metadata": {
    "id": "8d812ed7-b477-49ca-80c2-5b7de278e66f"
   },
   "outputs": [],
   "source": [
    "# Step 4.3 - Obtain table indicating number of times route runs throughout a day, also taking into account day of the week\n",
    "# (To simplify problem, for any non-circular stops we will consider only the maximum frequency between directions)\n",
    "# [Frequency is given per working day]\n",
    "# N.B: It is expected that circular routes will run more frequently compared to routes going in one direction\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store result of number of stops of each route per day\n",
    "Malta_Frequency_Of_Route_PerDay = {}\n",
    "Gozo_Frequency_Of_Route_PerDay = {}\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in Malta_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    Grouped = i_copy.groupby('Route Number')\n",
    "    # Find the maximum size for each Route Number\n",
    "    Malta_Frequency_Of_Route = Grouped['Time_Count'].max()\n",
    "    Malta_Frequency_Of_Route_PerDay[List_Dates[j]] = Malta_Frequency_Of_Route\n",
    "    j += 1\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in Gozo_Route_DataFrames_List:\n",
    "    i_copy = i.copy()\n",
    "    Grouped = i_copy.groupby('Route Number')\n",
    "    # Find the maximum size for each Route Number\n",
    "    Gozo_Frequency_Of_Route = Grouped['Time_Count'].max()\n",
    "    Gozo_Frequency_Of_Route_PerDay[List_Dates[k]] = Gozo_Frequency_Of_Route\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# Naming Dataframes\n",
    "Monday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Monday']\n",
    "Tuesday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Tuesday']\n",
    "Wednesday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Wednesday']\n",
    "Thursday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Thursday']\n",
    "Friday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Friday']\n",
    "Saturday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Saturday']\n",
    "Sunday_FrequencyofRoute_Malta = Malta_Frequency_Of_Route_PerDay['Sunday']\n",
    "Monday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Monday']\n",
    "Tuesday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Tuesday']\n",
    "Wednesday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Wednesday']\n",
    "Thursday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Thursday']\n",
    "Friday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Friday']\n",
    "Saturday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Saturday']\n",
    "Sunday_FrequencyofRoute_Gozo = Gozo_Frequency_Of_Route_PerDay['Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbd53f-0ef7-4989-89b3-35b76c55606d",
   "metadata": {
    "id": "8fbbd53f-0ef7-4989-89b3-35b76c55606d",
    "outputId": "66e73d27-4496-4555-a893-b0cc70243e9c"
   },
   "outputs": [],
   "source": [
    "# Step 4.3.1 - Combine Data, related to Malta, in One DataFrame with the following\n",
    "    # 1. Column - Day of the week\n",
    "    # 2. Rows - Route Number\n",
    "    # 3. Entries in DataFrame - The Frequency per day of each Route\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Malta_FrequencyPerDay'\n",
    "Malta_FrequencyPerDay = pd.concat([Monday_FrequencyofRoute_Malta, Tuesday_FrequencyofRoute_Malta, Wednesday_FrequencyofRoute_Malta,\n",
    "                                                           Thursday_FrequencyofRoute_Malta, Friday_FrequencyofRoute_Malta, Saturday_FrequencyofRoute_Malta,\n",
    "                                                           Sunday_FrequencyofRoute_Malta], axis=1)\n",
    "# Replace 'N/A' with NaN\n",
    "Malta_FrequencyPerDay.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Malta_FrequencyPerDay = Malta_FrequencyPerDay.astype('Int64')\n",
    "# Rename Columns\n",
    "Malta_FrequencyPerDay.columns = List_Dates\n",
    "# Display DataFrame\n",
    "Malta_FrequencyPerDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4835f1-2f9f-4776-966f-cb74cfc1db75",
   "metadata": {
    "id": "ce4835f1-2f9f-4776-966f-cb74cfc1db75",
    "outputId": "85260d17-b1d3-4fc8-a261-c59920e5aa87"
   },
   "outputs": [],
   "source": [
    "# Step 4.3.2 - Combine Data, related to Gozo, in One DataFrame with the following\n",
    "    # 1. Column - Day of the week\n",
    "    # 2. Rows - Route Number\n",
    "    # 3. Entries in DataFrame - The Frequency per day of each Route\n",
    "\n",
    "# Combine Data in one DataFrame entitled 'Gozo_FrequencyPerDay'\n",
    "Gozo_FrequencyPerDay = pd.concat([Monday_FrequencyofRoute_Gozo, Tuesday_FrequencyofRoute_Gozo, Wednesday_FrequencyofRoute_Gozo,\n",
    "                                                           Thursday_FrequencyofRoute_Gozo, Friday_FrequencyofRoute_Gozo, Saturday_FrequencyofRoute_Gozo,\n",
    "                                                           Sunday_FrequencyofRoute_Gozo], axis=1)\n",
    "# Replace 'N/A' with NaN\n",
    "Gozo_FrequencyPerDay.replace('N/A', pd.NA, inplace=True)\n",
    "# Convert to Integers\n",
    "Gozo_FrequencyPerDay = Gozo_FrequencyPerDay.astype('Int64')\n",
    "# Rename Columns\n",
    "Gozo_FrequencyPerDay.columns = List_Dates\n",
    "# Display DataFrame\n",
    "Gozo_FrequencyPerDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27ff61-3098-482e-bb11-fa24f0bd2d9d",
   "metadata": {
    "id": "9f27ff61-3098-482e-bb11-fa24f0bd2d9d",
    "outputId": "d254533d-1dd2-4087-cce0-e8dde23a6e40"
   },
   "outputs": [],
   "source": [
    "# Step 4.4 - Splitting Bus Stops, related to Malta, into three separate\n",
    "#  1. 'Normal_and_BusTerminals_DataFrame_Malta' - Bus Stops used as both Normal Stops and Bus Terminals\n",
    "#  2. 'BusTerminals_Only_DataFrame_Malta' - Bus Stops used as Bus Terminals Only\n",
    "#  3. 'NormalStops_Only_DataFrame_Malta' - Bus Stops used as Normal Stops Only\n",
    "# All DataFrame outputs are saved in the path specieid\n",
    "\n",
    "\n",
    "Malta_Route_DataFrames_List = [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta]\n",
    "Gozo_Route_DataFrames_List = [Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "Day_Names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# Save Path Home\n",
    "#save_path = \"C://Users//Owner//ICT5012 - Disseration//Untitled Folder//\"\n",
    "# Save Path Work\n",
    "save_path = \"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//\"\n",
    "\n",
    "for i, day in zip(Malta_Route_DataFrames_List, Day_Names):\n",
    "\n",
    "    print(day)\n",
    "\n",
    "    Reset_Condition_SepDay = (\n",
    "        i['Route Number'].shift(-1) != i['Route Number']) | \\\n",
    "        (i['Route Direction'].shift(-1) != i['Route Direction'])\n",
    "\n",
    "    # Initialise all entries in 'Bus_Terminal' as 0\n",
    "    i['Bus_Terminal'] = 0\n",
    "    # If Reset_Conditions defined above fails, then Bus Stop considered in 'Bus_Stop_ID' is a Bus Terminal\n",
    "    i.loc[Reset_Condition_SepDay, 'Bus_Terminal'] = 1\n",
    "    OG_BUS_Terminal_COLUMN = i['Bus_Terminal'].copy()\n",
    "    # Iterate through the original column\n",
    "    for j in range(len(OG_BUS_Terminal_COLUMN) - 1):\n",
    "        if OG_BUS_Terminal_COLUMN[j] == 1:\n",
    "            i.loc[j + 1, 'Bus_Terminal'] = 1\n",
    "    # Initialising First Row as Bus Terminal\n",
    "    i.loc[0, 'Bus_Terminal'] = 1\n",
    "\n",
    "    Bus_Terminals_DataFrame = i[i['Bus_Terminal'] == 1]\n",
    "\n",
    "    # Contain List of traversed Bus_Stop_ID ('bus_stop_ids' - All Bus Stops identified as terminal stops)\n",
    "    bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Bus_Terminals_DataFrame)):\n",
    "        bus_stop_id = Bus_Terminals_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id not in bus_stop_ids:\n",
    "            bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "    # Obtain only entries which correspond to a Bus Terminals.\n",
    "    # Duplicates will be present since the same Bus Terminals may be utilised for multiple 'Route Numebr' and 'Route Direction'\n",
    "    Normal_Bus_DataFrame = i[i['Bus_Terminal'] == 0]\n",
    "\n",
    "    # Contain List of traversed Bus_Stop_ID ('Normal_bus_stop_ids' - All Bus Stops identified as normal stops)\n",
    "    Normal_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Normal_Bus_DataFrame)):\n",
    "        Normal_bus_stop_id = Normal_Bus_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Normal_bus_stop_id not in Normal_bus_stop_ids:\n",
    "            Normal_bus_stop_ids.append(Normal_bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "\n",
    "    # Bus Stops used in terminals/terminals used as Bus Stops\n",
    "    # Find items in common between the two lists produced above 'bus_stop_ids' and 'Normal_bus_stop_ids'\n",
    "    #Normal_and_BusTerminals_ids = [item for item in Normal_bus_stop_ids if item in bus_stop_ids]\n",
    "    Normal_and_BusTerminals_ids = list(set(bus_stop_ids) & set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    Normal_and_BusTerminals_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    compare_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        bus_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id in Normal_and_BusTerminals_ids and bus_stop_id not in compare_bus_stop_ids:\n",
    "            compare_bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            Normal_and_BusTerminals_DataFrame_Malta = pd.concat([Normal_and_BusTerminals_DataFrame_Malta, i.iloc[[c]]],\n",
    "                                                                ignore_index=True)\n",
    "\n",
    "    file_name = f\"AllNormalBusStopsUsedAsTerminalsMalta_{day}.csv\"\n",
    "    Normal_and_BusTerminals_DataFrame_Malta.to_csv(save_path + file_name, index=False)\n",
    "\n",
    "    # Obtaining Stops which are only used as Terminals\n",
    "    BusTerminals_Only_ids = list(set(bus_stop_ids) - set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    BusTerminals_Only_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Terminal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Terminal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Terminal_stop_id in BusTerminals_Only_ids and Only_Terminal_stop_id not in Only_Terminal_stop_ids:\n",
    "            Only_Terminal_stop_ids.append(Only_Terminal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            BusTerminals_Only_DataFrame_Malta = pd.concat([BusTerminals_Only_DataFrame_Malta, i.iloc[[c]]],\n",
    "                                                          ignore_index=True)\n",
    "\n",
    "    file_name = f\"BusTerminalsOnlyMalta_{day}.csv\"\n",
    "    BusTerminals_Only_DataFrame_Malta.to_csv(save_path + file_name, index=False)\n",
    "\n",
    "    # Obtaining Stops which are only used as Normal Stops\n",
    "    NormalStops_Only_ids = list(set(Normal_bus_stop_ids) - set(bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    NormalStops_Only_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Normal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Normal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Normal_stop_id in NormalStops_Only_ids and Only_Normal_stop_id not in Only_Normal_stop_ids:\n",
    "            Only_Normal_stop_ids.append(Only_Normal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            NormalStops_Only_DataFrame_Malta = pd.concat([NormalStops_Only_DataFrame_Malta, i.iloc[[c]]],\n",
    "                                                         ignore_index=True)\n",
    "\n",
    "    file_name = f\"NormalStopsOnlyMalta_{day}.csv\"\n",
    "    NormalStops_Only_DataFrame_Malta.to_csv(save_path + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a2c41",
   "metadata": {
    "id": "6f4a2c41",
    "outputId": "e178f123-cf40-4b65-a48d-319a8a20d4f6"
   },
   "outputs": [],
   "source": [
    "# Step 4.4.2 - Splitting Bus Stops, related to Gozo, into three separate DataFrames\n",
    "#  1. 'Normal_and_BusTerminals_DataFrame_Malta' - Bus Stops used as both Normal Stops and Bus Terminals\n",
    "#  2. 'BusTerminals_Only_DataFrame_Malta' - Bus Stops used as Bus Terminals Only\n",
    "#  3. 'NormalStops_Only_DataFrame_Malta' - Bus Stops used as Normal Stops Only\n",
    "# All DataFrame outputs are saved in the path specied in 'save_path'\n",
    "\n",
    "Malta_Route_DataFrames_List = [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta]\n",
    "Gozo_Route_DataFrames_List = [Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "Day_Names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# Save Path Home\n",
    "#save_path = \"C://Users//Owner//ICT5012 - Disseration//Untitled Folder//\"\n",
    "# Save Path Work\n",
    "save_path = \"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//\"\n",
    "\n",
    "\n",
    "for i, day in zip(Gozo_Route_DataFrames_List, Day_Names):\n",
    "\n",
    "    print(day)\n",
    "\n",
    "    Reset_Condition_SepDay = (\n",
    "        i['Route Number'].shift(-1) != i['Route Number']) | \\\n",
    "        (i['Route Direction'].shift(-1) != i['Route Direction'])\n",
    "\n",
    "    # Initialise all entries in 'Bus_Terminal' as 0\n",
    "    i['Bus_Terminal'] = 0\n",
    "    # If Reset_Conditions defined above fails, then Bus Stop considered in 'Bus_Stop_ID' is a Bus Terminal\n",
    "    i.loc[Reset_Condition_SepDay, 'Bus_Terminal'] = 1\n",
    "    OG_BUS_Terminal_COLUMN = i['Bus_Terminal'].copy()\n",
    "    # Iterate through the original column\n",
    "    for j in range(len(OG_BUS_Terminal_COLUMN) - 1):\n",
    "        if OG_BUS_Terminal_COLUMN[j] == 1:\n",
    "            i.loc[j + 1, 'Bus_Terminal'] = 1\n",
    "    # Initialising First Row as Bus Terminal\n",
    "    i.loc[0, 'Bus_Terminal'] = 1\n",
    "\n",
    "    Bus_Terminals_DataFrame = i[i['Bus_Terminal'] == 1]\n",
    "\n",
    "    # Contain List of traversed Bus_Stop_ID ('bus_stop_ids' - All Bus Stops identified as terminal stops)\n",
    "    bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Bus_Terminals_DataFrame)):\n",
    "        bus_stop_id = Bus_Terminals_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id not in bus_stop_ids:\n",
    "            bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "    # Obtain only entries which correspond to a Bus Terminals.\n",
    "    # Duplicates will be present since the same Bus Terminals may be utilised for multiple 'Route Numebr' and 'Route Direction'\n",
    "    Normal_Bus_DataFrame = i[i['Bus_Terminal'] == 0]\n",
    "\n",
    "    # Contain List of traversed Bus_Stop_ID ('Normal_bus_stop_ids' - All Bus Stops identified as normal stops)\n",
    "    Normal_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(Normal_Bus_DataFrame)):\n",
    "        Normal_bus_stop_id = Normal_Bus_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Normal_bus_stop_id not in Normal_bus_stop_ids:\n",
    "            Normal_bus_stop_ids.append(Normal_bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "\n",
    "    # Bus Stops used in terminals/terminals used as Bus Stops\n",
    "    # Find items in common between the two lists produced above 'bus_stop_ids' and 'Normal_bus_stop_ids'\n",
    "    #Normal_and_BusTerminals_ids = [item for item in Normal_bus_stop_ids if item in bus_stop_ids]\n",
    "    Normal_and_BusTerminals_ids = list(set(bus_stop_ids) & set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    Normal_and_BusTerminals_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    compare_bus_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        bus_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if bus_stop_id in Normal_and_BusTerminals_ids and bus_stop_id not in compare_bus_stop_ids:\n",
    "            compare_bus_stop_ids.append(bus_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            Normal_and_BusTerminals_DataFrame_Gozo = pd.concat([Normal_and_BusTerminals_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                                                                ignore_index=True)\n",
    "\n",
    "    file_name = f\"AllNormalBusStopsUsedAsTerminalsGozo_{day}.csv\"\n",
    "    Normal_and_BusTerminals_DataFrame_Gozo.to_csv(save_path + file_name, index=False)\n",
    "\n",
    "    # Obtaining Stops which are only used as Terminals\n",
    "    BusTerminals_Only_ids = list(set(bus_stop_ids) - set(Normal_bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    BusTerminals_Only_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Terminal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Terminal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Terminal_stop_id in BusTerminals_Only_ids and Only_Terminal_stop_id not in Only_Terminal_stop_ids:\n",
    "            Only_Terminal_stop_ids.append(Only_Terminal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            BusTerminals_Only_DataFrame_Gozo = pd.concat([BusTerminals_Only_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                                                          ignore_index=True)\n",
    "\n",
    "    file_name = f\"BusTerminalsOnlyGozo_{day}.csv\"\n",
    "    BusTerminals_Only_DataFrame_Gozo.to_csv(save_path + file_name, index=False)\n",
    "\n",
    "    # Obtaining Stops which are only used as Normal Stops\n",
    "    NormalStops_Only_ids = list(set(Normal_bus_stop_ids) - set(bus_stop_ids))\n",
    "\n",
    "    # Define empty DataFrame to Store all Bus Stops used as Normal Bus Stops and Terminals in Malta and Gozo\n",
    "    NormalStops_Only_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "\n",
    "    # Store Bus Stops to avoid duplicates\n",
    "    Only_Normal_stop_ids = []\n",
    "\n",
    "    # Consider only Distinct Bus Terminals\n",
    "    for c in range(len(i)):\n",
    "        Only_Normal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "\n",
    "        if Only_Normal_stop_id in NormalStops_Only_ids and Only_Normal_stop_id not in Only_Normal_stop_ids:\n",
    "            Only_Normal_stop_ids.append(Only_Normal_stop_id)  # Add to list of seen IDs\n",
    "\n",
    "            # Check the island and append the row\n",
    "            NormalStops_Only_DataFrame_Gozo = pd.concat([NormalStops_Only_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                                                         ignore_index=True)\n",
    "\n",
    "    file_name = f\"NormalStopsOnlyGozo_{day}.csv\"\n",
    "    NormalStops_Only_DataFrame_Gozo.to_csv(save_path + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2c348-ee06-4f8a-9d16-e1871ea4c4f0",
   "metadata": {
    "id": "83e2c348-ee06-4f8a-9d16-e1871ea4c4f0"
   },
   "outputs": [],
   "source": [
    "# Step 4.4.3 - Loading all datasets created (for Malta)\n",
    "Malta_NormalStops_Monday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Monday.csv\")\n",
    "Malta_NormalStops_Tuesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Tuesday.csv\")\n",
    "Malta_NormalStops_Wednesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Wednesday.csv\")\n",
    "Malta_NormalStops_Thursday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Thursday.csv\")\n",
    "Malta_NormalStops_Friday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Friday.csv\")\n",
    "Malta_NormalStops_Saturday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Saturday.csv\")\n",
    "Malta_NormalStops_Sunday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyMalta_Sunday.csv\")\n",
    "\n",
    "Malta_TerminalStops_Monday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Monday.csv\")\n",
    "Malta_TerminalStops_Tuesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Tuesday.csv\")\n",
    "Malta_TerminalStops_Wednesday =pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Wednesday.csv\")\n",
    "Malta_TerminalStops_Thursday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Thursday.csv\")\n",
    "Malta_TerminalStops_Friday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Friday.csv\")\n",
    "Malta_TerminalStops_Saturday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Saturday.csv\")\n",
    "Malta_TerminalStops_Sunday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyMalta_Sunday.csv\")\n",
    "\n",
    "Malta_NormalandTerminalStops_Monday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Monday.csv\")\n",
    "Malta_NormalandTerminalStops_Tuesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Tuesday.csv\")\n",
    "Malta_NormalandTerminalStops_Wednesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Wednesday.csv\")\n",
    "Malta_NormalandTerminalStops_Thursday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Thursday.csv\")\n",
    "Malta_NormalandTerminalStops_Friday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Friday.csv\")\n",
    "Malta_NormalandTerminalStops_Saturday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Saturday.csv\")\n",
    "Malta_NormalandTerminalStops_Sunday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsMalta_Sunday.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a47c2-d619-4610-a127-b5bb6f84ac44",
   "metadata": {
    "id": "a97a47c2-d619-4610-a127-b5bb6f84ac44"
   },
   "outputs": [],
   "source": [
    "# Step 4.4.4 - Loading all datasets created (for Gozo)\n",
    "Gozo_NormalStops_Monday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Monday.csv\")\n",
    "Gozo_NormalStops_Tuesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Tuesday.csv\")\n",
    "Gozo_NormalStops_Wednesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Wednesday.csv\")\n",
    "Gozo_NormalStops_Thursday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Thursday.csv\")\n",
    "Gozo_NormalStops_Friday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Friday.csv\")\n",
    "Gozo_NormalStops_Saturday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Saturday.csv\")\n",
    "Gozo_NormalStops_Sunday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//NormalStopsOnlyGozo_Sunday.csv\")\n",
    "\n",
    "Gozo_TerminalStops_Monday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Monday.csv\")\n",
    "Gozo_TerminalStops_Tuesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Tuesday.csv\")\n",
    "Gozo_TerminalStops_Wednesday =pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Wednesday.csv\")\n",
    "Gozo_TerminalStops_Thursday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Thursday.csv\")\n",
    "Gozo_TerminalStops_Friday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Friday.csv\")\n",
    "Gozo_TerminalStops_Saturday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Saturday.csv\")\n",
    "Gozo_TerminalStops_Sunday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//BusTerminalsOnlyGozo_Sunday.csv\")\n",
    "\n",
    "Gozo_NormalandTerminalStops_Monday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Monday.csv\")\n",
    "Gozo_NormalandTerminalStops_Tuesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Tuesday.csv\")\n",
    "Gozo_NormalandTerminalStops_Wednesday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Wednesday.csv\")\n",
    "Gozo_NormalandTerminalStops_Thursday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Thursday.csv\")\n",
    "Gozo_NormalandTerminalStops_Friday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Friday.csv\")\n",
    "Gozo_NormalandTerminalStops_Saturday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Saturday.csv\")\n",
    "Gozo_NormalandTerminalStops_Sunday = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Outputs of Terminals_NormalStops//AllNormalBusStopsUsedAsTerminalsGozo_Sunday.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a3767-c29f-470d-8e8a-f661bfe72c9d",
   "metadata": {
    "id": "032a3767-c29f-470d-8e8a-f661bfe72c9d",
    "outputId": "ba0f1350-4507-41fd-c8bf-12e52604cd01"
   },
   "outputs": [],
   "source": [
    "# Step 4.4.5 - Creating Pandas Dataframes to show data, for both Malta and Gozo, in table form\n",
    "\n",
    "List_Original_DataFrames =  [Monday_Routes_Malta, Tuesday_Routes_Malta, Wednesday_Routes_Malta, Thursday_Routes_Malta, Friday_Routes_Malta, Saturday_Routes_Malta, Sunday_Routes_Malta,\n",
    "                            Monday_Routes_Gozo, Tuesday_Routes_Gozo, Wednesday_Routes_Gozo, Thursday_Routes_Gozo, Friday_Routes_Gozo, Saturday_Routes_Gozo, Sunday_Routes_Gozo]\n",
    "\n",
    "List_NormalStopsOnly_DataFrames = [Malta_NormalStops_Monday, Malta_NormalStops_Tuesday, Malta_NormalStops_Wednesday, Malta_NormalStops_Thursday, Malta_NormalStops_Friday, Malta_NormalStops_Saturday,\n",
    "                                   Malta_NormalStops_Sunday, Gozo_NormalStops_Monday, Gozo_NormalStops_Tuesday, Gozo_NormalStops_Wednesday, Gozo_NormalStops_Thursday, Gozo_NormalStops_Friday, Gozo_NormalStops_Saturday,\n",
    "                                   Gozo_NormalStops_Sunday]\n",
    "\n",
    "List_TerminalStopsOnly_DataFrames = [Malta_TerminalStops_Monday, Malta_TerminalStops_Tuesday, Malta_TerminalStops_Wednesday, Malta_TerminalStops_Thursday,\n",
    "                                    Malta_TerminalStops_Friday, Malta_TerminalStops_Saturday, Malta_TerminalStops_Sunday, Gozo_TerminalStops_Monday, Gozo_TerminalStops_Tuesday, Gozo_TerminalStops_Wednesday, Gozo_TerminalStops_Thursday,\n",
    "                                    Gozo_TerminalStops_Friday, Gozo_TerminalStops_Saturday, Gozo_TerminalStops_Sunday]\n",
    "\n",
    "List_NormalandTerminalStops_DataFrames = [Malta_NormalandTerminalStops_Monday, Malta_NormalandTerminalStops_Tuesday, Malta_NormalandTerminalStops_Wednesday, Malta_NormalandTerminalStops_Thursday,\n",
    "                                          Malta_NormalandTerminalStops_Friday, Malta_NormalandTerminalStops_Saturday, Malta_NormalandTerminalStops_Sunday, Gozo_NormalandTerminalStops_Monday, Gozo_NormalandTerminalStops_Tuesday, Gozo_NormalandTerminalStops_Wednesday, Gozo_NormalandTerminalStops_Thursday,\n",
    "                                          Gozo_NormalandTerminalStops_Friday, Gozo_NormalandTerminalStops_Saturday, Gozo_NormalandTerminalStops_Sunday]\n",
    "\n",
    "Column_List = ['Malta_Monday', 'Malta_Tuesday', 'Malta_Wednesday', 'Malta_Thursday', 'Malta_Friday',\n",
    "               'Malta_Saturday', 'Malta_Sunday', 'Gozo_Monday', 'Gozo_Tuesday', 'Gozo_Wednesday', 'Gozo_Thursday', 'Gozo_Friday',\n",
    "               'Gozo_Saturday', 'Gozo_Sunday']\n",
    "\n",
    "Total_Nodes = []\n",
    "for c in List_Original_DataFrames:\n",
    "    Total_Nodes.append(c['Bus_Stop_ID'].nunique())\n",
    "\n",
    "Total_NormalStopsOnly = []\n",
    "for c in List_NormalStopsOnly_DataFrames:\n",
    "    Total_NormalStopsOnly.append(c['Bus_Stop_ID'].nunique())\n",
    "\n",
    "Total_TerminalStopsOnly = []\n",
    "for c in List_TerminalStopsOnly_DataFrames:\n",
    "    Total_TerminalStopsOnly.append(c['Bus_Stop_ID'].nunique())\n",
    "\n",
    "Total_NormalandTerminalStops = []\n",
    "for c in List_NormalandTerminalStops_DataFrames:\n",
    "    Total_NormalandTerminalStops.append(c['Bus_Stop_ID'].nunique())\n",
    "\n",
    "NodeInfo_SplitByDay = pd.DataFrame([Total_Nodes, Total_NormalStopsOnly, Total_TerminalStopsOnly, Total_NormalandTerminalStops],\n",
    "                                   index=['Total Number of unique Nodes', 'Total Number of Unique Normal Stops', 'Total Number of Unique Bus Terminals',\n",
    "                                          'Total Number of Unique Stops used as both Regular Stops and Terminals'], columns= Column_List)\n",
    "# Display DataFrame\n",
    "NodeInfo_SplitByDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e475d-e4c5-4a82-8faf-23dec31d7bd3",
   "metadata": {
    "id": "ef3e475d-e4c5-4a82-8faf-23dec31d7bd3"
   },
   "outputs": [],
   "source": [
    "# Saving a copy of all DataFrames Created\n",
    "Malta_RoutePresencePerDay__and_BusStopsVisited.to_csv('C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Malta_RoutePresencePerDay__and_BusStopsVisited.csv')\n",
    "Gozo_RoutePresencePerDay__and_BusStopsVisited.to_csv('C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Gozo_RoutePresencePerDay__and_BusStopsVisited.csv')\n",
    "Malta_FrequencyPerDay.to_csv('C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Malta_FrequencyPerDay.csv')\n",
    "Gozo_FrequencyPerDay.to_csv('C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Gozo_FrequencyPerDay.csv')\n",
    "NodeInfo_SplitByDay.to_csv('C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//NodeInfo_SplitByDay.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b43aa-89a5-45ec-9a8d-92b21e298c9b",
   "metadata": {
    "id": "bd5b43aa-89a5-45ec-9a8d-92b21e298c9b"
   },
   "source": [
    "### Step 5 - Obtaining Information on the travel time beween each Origin and destination Bus Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f74cd",
   "metadata": {
    "id": "509f74cd"
   },
   "outputs": [],
   "source": [
    "# Step 5.1 - Load data from 'Distinct_Edges_MALTA_IncTravelTimes' (renamed to 'Malta_DistinctEdges_IncTravelTimes') and\n",
    "# 'Distinct_Edges_GOZO_IncTravelTimes' (renamed to 'Gozo_DistinctEdges_IncTravelTimes')\n",
    "#Malta_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes.csv\")\n",
    "#Gozo_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes.csv\")\n",
    "\n",
    "# At Work\n",
    "Malta_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Files Used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes = pd.read_csv(\"C://Users//attardan.CBM//Data Visualisation//Files Used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b62c8",
   "metadata": {
    "id": "018b62c8",
    "outputId": "87d0fc5c-4fb3-4837-f47b-461516b4c6a4"
   },
   "outputs": [],
   "source": [
    "len(Malta_DistinctEdges_IncTravelTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1fd04",
   "metadata": {
    "id": "c3d1fd04",
    "outputId": "396d9d93-a13b-4387-a877-ed9ffb879597"
   },
   "outputs": [],
   "source": [
    "len(Gozo_DistinctEdges_IncTravelTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e0771-31ee-491c-9915-cac63c9277f8",
   "metadata": {
    "id": "790e0771-31ee-491c-9915-cac63c9277f8"
   },
   "outputs": [],
   "source": [
    "# Step 5.2 - Data Cleaning (Take shortest path if available ex. Stop 3 to Stop 819 is 56 seconds long on the otherhand Stop 819 to Stop 3\n",
    "# is 1019 seconds long (The former is correct))\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Malta_DistinctEdges_IncTravelTimes['Standardized_Route'] = Malta_DistinctEdges_IncTravelTimes['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Malta_DistinctEdges_IncTravelTimes_Min = Malta_DistinctEdges_IncTravelTimes.loc[Malta_DistinctEdges_IncTravelTimes.groupby('Standardized_Route')['Travel_Time'].idxmin()]\n",
    "# Drop the helper column if not needed\n",
    "Malta_DistinctEdges_IncTravelTimes_Min = Malta_DistinctEdges_IncTravelTimes_Min.drop(columns=['Standardized_Route'])\n",
    "\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Gozo_DistinctEdges_IncTravelTimes['Standardized_Route'] = Gozo_DistinctEdges_IncTravelTimes['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Gozo_DistinctEdges_IncTravelTimes_Min = Gozo_DistinctEdges_IncTravelTimes.loc[Gozo_DistinctEdges_IncTravelTimes.groupby('Standardized_Route')['Travel_Time'].idxmin()]\n",
    "# Drop the helper column if not needed\n",
    "Gozo_DistinctEdges_IncTravelTimes_Min = Gozo_DistinctEdges_IncTravelTimes_Min.drop(columns=['Standardized_Route'])\n",
    "\n",
    "# Saving DataFrames\n",
    "Malta_DistinctEdges_IncTravelTimes_Min.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes_WrongPathFix.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes_Min.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes_WrongPathFix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd4918-94e8-4966-8357-9401220a144d",
   "metadata": {
    "id": "acfd4918-94e8-4966-8357-9401220a144d",
    "outputId": "e8140efc-4b70-45f7-fe8a-986bb80e3cdd"
   },
   "outputs": [],
   "source": [
    "# Step 5.3 - Obtaining Information related to Malta (Time)\n",
    "\n",
    "# Find edge with maximum travel time\n",
    "Malta_DistinctEdges_IncTravelTimes_Min[Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'] == Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'].max()]\n",
    "# Find average travelling time throughout all edges\n",
    "Average_TravelTime = Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'].mean()\n",
    "# Find median travelling time throughout all edges\n",
    "Median_TravelTime = Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'].median()\n",
    "# Obtain box plot of Travel Time\n",
    "\n",
    "# Removing Errors by Changing Data Type to numeric\n",
    "Travel_TimeData = pd.to_numeric(Malta_DistinctEdges_IncTravelTimes_Min['Travel_Time'], errors='coerce').dropna()\n",
    "\n",
    "\n",
    "# Obtaining further statistics\n",
    "minimum = np.min(Travel_TimeData)\n",
    "Q1 = np.percentile(Travel_TimeData, 25)\n",
    "median = np.median(Travel_TimeData)\n",
    "Q3 = np.percentile(Travel_TimeData, 75)\n",
    "maximum = np.max(Travel_TimeData)\n",
    "# Compute interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "# Compute whiskers (last values before outliers)\n",
    "lower_whisker = np.min(Travel_TimeData[Travel_TimeData >= (Q1 - 1.5 * IQR)].astype(float))\n",
    "upper_whisker = np.max(Travel_TimeData[Travel_TimeData <= (Q3 + 1.5 * IQR)].astype(float))\n",
    "\n",
    "# Defining figure size\n",
    "Figure = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(Travel_TimeData, vert = True, patch_artist = True)\n",
    "\n",
    "# Add title, y-axis and x-axis\n",
    "plt.xlabel(\"Edge Travel Time Data\", fontsize = 12)\n",
    "plt.ylabel(\"Travel Time (seconds)\", fontsize = 12)\n",
    "plt.title(\"Box Plot of Edge In-Vehicle Travel Time in Malta\", fontsize = 14)\n",
    "\n",
    "\n",
    "plt.annotate(f\"Min/Lower Whisker: {minimum:.2f}\",\n",
    "             xy=(1, minimum),\n",
    "             xytext=(1.1, minimum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Q1: {Q1:.2f}\",\n",
    "             xy=(1, Q1),\n",
    "             xytext=(1.1, Q1 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Median: {median:.2f}\",\n",
    "             xy=(1, median),\n",
    "             xytext=(1.1, median + 2),\n",
    "             fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.annotate(f\"Q3: {Q3:.2f}\",\n",
    "             xy=(1, Q3),\n",
    "             xytext=(1.1, Q3 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Max: {maximum:.2f}\",\n",
    "             xy=(1, maximum),\n",
    "             xytext=(1.1, maximum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Upper Whisker: {upper_whisker:.2f}\",\n",
    "             xy=(1, upper_whisker),\n",
    "             xytext=(1.1, upper_whisker + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5f0bf-b8ab-4d20-94cd-e5046592c6ff",
   "metadata": {
    "id": "a0c5f0bf-b8ab-4d20-94cd-e5046592c6ff",
    "outputId": "98e647b9-8f0b-42e0-af38-a18da7b9f208"
   },
   "outputs": [],
   "source": [
    "# Step 5.4 - Obtaining Information related to Gozo (Time)\n",
    "\n",
    "# Find edge with maximum travel time\n",
    "Gozo_DistinctEdges_IncTravelTimes_Min[Gozo_DistinctEdges_IncTravelTimes_Min['Travel_Time'] == Gozo_DistinctEdges_IncTravelTimes_Min['Travel_Time'].max()]\n",
    "# Find average travelling time throughout all edges\n",
    "Average_TravelTime = Gozo_DistinctEdges_IncTravelTimes_Min['Travel_Time'].mean()\n",
    "# Find median travelling time throughout all edges\n",
    "Median_TravelTime = Gozo_DistinctEdges_IncTravelTimes_Min['Travel_Time'].median()\n",
    "\n",
    "# Obtain box plot of Travel Time\n",
    "# Example data (replace this with your actual DataFrame column)\n",
    "Travel_TimeData = pd.to_numeric(Gozo_DistinctEdges_IncTravelTimes_Min['Travel_Time'], errors='coerce').dropna()\n",
    "\n",
    "# Obtaining further statistics\n",
    "minimum = np.min(Travel_TimeData)\n",
    "Q1 = np.percentile(Travel_TimeData, 25)\n",
    "median = np.median(Travel_TimeData)\n",
    "Q3 = np.percentile(Travel_TimeData, 75)\n",
    "maximum = np.max(Travel_TimeData)\n",
    "# Compute interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "# Compute whiskers (last values before outliers)\n",
    "lower_whisker = np.min(Travel_TimeData[Travel_TimeData >= (Q1 - 1.5 * IQR)].astype(float))\n",
    "upper_whisker = np.max(Travel_TimeData[Travel_TimeData <= (Q3 + 1.5 * IQR)].astype(float))\n",
    "\n",
    "# Defining figure size\n",
    "Figure = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(Travel_TimeData, vert = True, patch_artist = True)\n",
    "\n",
    "# Add title, y-axis and x-axis\n",
    "plt.xlabel(\"Edge Travel Time Data\", fontsize = 12)\n",
    "plt.ylabel(\"Travel Time (seconds)\", fontsize = 12)\n",
    "plt.title(\"Box Plot of Edge In-Vehicle Travel Time in Gozo\", fontsize = 14)\n",
    "\n",
    "#Annotate Values to Box Plot\n",
    "plt.annotate(f\"Min/Lower Whisker: {minimum:.2f}\",\n",
    "             xy=(1, minimum),\n",
    "             xytext=(1.1, minimum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Q1: {Q1:.2f}\",\n",
    "             xy=(1, Q1),\n",
    "             xytext=(1.1, Q1 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Median: {median:.2f}\",\n",
    "             xy=(1, median),\n",
    "             xytext=(1.1, median + 2),\n",
    "             fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.annotate(f\"Q3: {Q3:.2f}\",\n",
    "             xy=(1, Q3),\n",
    "             xytext=(1.1, Q3 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Max: {maximum:.2f}\",\n",
    "             xy=(1, maximum),\n",
    "             xytext=(1.1, maximum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Upper Whisker: {upper_whisker:.2f}\",\n",
    "             xy=(1, upper_whisker),\n",
    "             xytext=(1.1, upper_whisker + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa82bb5",
   "metadata": {
    "id": "8aa82bb5"
   },
   "outputs": [],
   "source": [
    "# Step 5.5 - Data Cleaning (Take shortest path if available ex. Stop 3 to Stop 819 is 56 seconds long on the otherhand Stop 819 to Stop 3\n",
    "# is 1019 seconds long (The former is correct))\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Malta_DistinctEdges_IncTravelTimes['Standardized_Route'] = Malta_DistinctEdges_IncTravelTimes['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Malta_DistinctEdges_IncTravelTimes_MinLength = Malta_DistinctEdges_IncTravelTimes.loc[Malta_DistinctEdges_IncTravelTimes.groupby('Standardized_Route')['Length_In_Metres'].idxmin()]\n",
    "# Drop the helper column if not needed\n",
    "Malta_DistinctEdges_IncTravelTimes_MinLength = Malta_DistinctEdges_IncTravelTimes_MinLength.drop(columns=['Standardized_Route'])\n",
    "\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Gozo_DistinctEdges_IncTravelTimes['Standardized_Route'] = Gozo_DistinctEdges_IncTravelTimes['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Gozo_DistinctEdges_IncTravelTimes_MinLength = Gozo_DistinctEdges_IncTravelTimes.loc[Gozo_DistinctEdges_IncTravelTimes.groupby('Standardized_Route')['Length_In_Metres'].idxmin()]\n",
    "# Drop the helper column if not needed\n",
    "Gozo_DistinctEdges_IncTravelTimes_MinLength = Gozo_DistinctEdges_IncTravelTimes_MinLength.drop(columns=['Standardized_Route'])\n",
    "\n",
    "# Saving DataFrames\n",
    "Malta_DistinctEdges_IncTravelTimes_MinLength.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes_WrongPathFixLength.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes_MinLength.to_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes_WrongPathFixLength.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c442684-2357-46db-a760-f3c03e7f138c",
   "metadata": {
    "id": "0c442684-2357-46db-a760-f3c03e7f138c",
    "outputId": "31facbf7-97f1-4bc0-9870-3344b34bc212"
   },
   "outputs": [],
   "source": [
    "# Step 5.6 - Obtaining Information related to Malta (Length)\n",
    "\n",
    "# Find edge with maximum travel time\n",
    "Malta_DistinctEdges_IncTravelTimes_MinLength[Malta_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'] == Malta_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'].max()]\n",
    "# Find average travelling time throughout all edges\n",
    "Average_Length = Malta_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'].mean()\n",
    "# Find median travelling time throughout all edges\n",
    "Median_Length = Malta_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'].median()\n",
    "# Obtain box plot of Travel Time\n",
    "\n",
    "# Removing Errors by Changing Data Type to numeric\n",
    "Length_Data = pd.to_numeric(Malta_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'], errors='coerce').dropna()\n",
    "\n",
    "\n",
    "# Obtaining further statistics\n",
    "minimum = np.min(Length_Data)\n",
    "Q1 = np.percentile(Length_Data, 25)\n",
    "median = np.median(Length_Data)\n",
    "Q3 = np.percentile(Length_Data, 75)\n",
    "maximum = np.max(Length_Data)\n",
    "# Compute interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "# Compute whiskers (last values before outliers)\n",
    "lower_whisker = np.min(Length_Data[Length_Data >= (Q1 - 1.5 * IQR)].astype(float))\n",
    "upper_whisker = np.max(Length_Data[Length_Data <= (Q3 + 1.5 * IQR)].astype(float))\n",
    "\n",
    "# Defining figure size\n",
    "Figure = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(Length_Data, vert = True, patch_artist = True)\n",
    "\n",
    "# Add title, y-axis and x-axis\n",
    "plt.xlabel(\"Edge Length Data\", fontsize = 12)\n",
    "plt.ylabel(\"Length (metres)\", fontsize = 12)\n",
    "plt.title(\"Box Plot of Edge Length in Malta\", fontsize = 14)\n",
    "\n",
    "\n",
    "plt.annotate(f\"Min/Lower Whisker: {minimum:.2f}\",\n",
    "             xy=(1, minimum),\n",
    "             xytext=(1.1, minimum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Q1: {Q1:.2f}\",\n",
    "             xy=(1, Q1),\n",
    "             xytext=(1.1, Q1 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Median: {median:.2f}\",\n",
    "             xy=(1, median),\n",
    "             xytext=(1.1, median + 2),\n",
    "             fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.annotate(f\"Q3: {Q3:.2f}\",\n",
    "             xy=(1, Q3),\n",
    "             xytext=(1.1, Q3 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Max: {maximum:.2f}\",\n",
    "             xy=(1, maximum),\n",
    "             xytext=(1.1, maximum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Upper Whisker: {upper_whisker:.2f}\",\n",
    "             xy=(1, upper_whisker),\n",
    "             xytext=(1.1, upper_whisker + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805481e0",
   "metadata": {
    "id": "805481e0",
    "outputId": "a9b5b024-f05f-48ef-e7e4-5ae71c967a0c"
   },
   "outputs": [],
   "source": [
    "# Step 5.6 - Obtaining Information related to Gozo (Length)\n",
    "\n",
    "# Find edge with maximum travel time\n",
    "Gozo_DistinctEdges_IncTravelTimes_MinLength[Gozo_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'] == Gozo_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'].max()]\n",
    "# Find average travelling time throughout all edges\n",
    "Average_Length = Gozo_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'].mean()\n",
    "# Find median travelling time throughout all edges\n",
    "Median_Length = Gozo_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'].median()\n",
    "# Obtain box plot of Travel Time\n",
    "\n",
    "# Removing Errors by Changing Data Type to numeric\n",
    "Length_Data = pd.to_numeric(Gozo_DistinctEdges_IncTravelTimes_MinLength['Length_In_Metres'], errors='coerce').dropna()\n",
    "\n",
    "\n",
    "# Obtaining further statistics\n",
    "minimum = np.min(Length_Data)\n",
    "Q1 = np.percentile(Length_Data, 25)\n",
    "median = np.median(Length_Data)\n",
    "Q3 = np.percentile(Length_Data, 75)\n",
    "maximum = np.max(Length_Data)\n",
    "# Compute interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "# Compute whiskers (last values before outliers)\n",
    "lower_whisker = np.min(Length_Data[Length_Data >= (Q1 - 1.5 * IQR)].astype(float))\n",
    "upper_whisker = np.max(Length_Data[Length_Data <= (Q3 + 1.5 * IQR)].astype(float))\n",
    "\n",
    "# Defining figure size\n",
    "Figure = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(Length_Data, vert = True, patch_artist = True)\n",
    "\n",
    "# Add title, y-axis and x-axis\n",
    "plt.xlabel(\"Edge Length Data\", fontsize = 12)\n",
    "plt.ylabel(\"Length (metres)\", fontsize = 12)\n",
    "plt.title(\"Box Plot of Edge Length in Gozo\", fontsize = 14)\n",
    "\n",
    "\n",
    "plt.annotate(f\"Min/Lower Whisker: {minimum:.2f}\",\n",
    "             xy=(1, minimum),\n",
    "             xytext=(1.1, minimum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Q1: {Q1:.2f}\",\n",
    "             xy=(1, Q1),\n",
    "             xytext=(1.1, Q1 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Median: {median:.2f}\",\n",
    "             xy=(1, median),\n",
    "             xytext=(1.1, median + 2),\n",
    "             fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.annotate(f\"Q3: {Q3:.2f}\",\n",
    "             xy=(1, Q3),\n",
    "             xytext=(1.1, Q3 + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Max: {maximum:.2f}\",\n",
    "             xy=(1, maximum),\n",
    "             xytext=(1.1, maximum + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "plt.annotate(f\"Upper Whisker: {upper_whisker:.2f}\",\n",
    "             xy=(1, upper_whisker),\n",
    "             xytext=(1.1, upper_whisker + 2),\n",
    "             fontsize=8)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d7887",
   "metadata": {
    "id": "006d7887"
   },
   "source": [
    "### Step 6 - Analysing Most Popular Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b829f7-e305-47c3-a362-429784990922",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Routes_Copy = pd.concat([Monday_Routes_Malta, Monday_Routes_Gozo], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6cfb4",
   "metadata": {
    "id": "83f6cfb4",
    "outputId": "463d0ae0-74b3-4979-dd5d-760414edc297"
   },
   "outputs": [],
   "source": [
    "# Keeping Only essential data from 'All_Routes_Copy' DataFrame\n",
    "Trip_Generation_DataFrame = All_Routes_Copy[['Stops','City Name', 'Bus_Stop_ID', 'Longitude_Final', 'Latitude_Final', 'Stop Island']]\n",
    "Trip_Generation_DataFrame.loc[:, \"Index\"] = range(1, len(Trip_Generation_DataFrame) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151b80",
   "metadata": {
    "id": "c5151b80",
    "outputId": "d1178138-3b40-4713-b7aa-f951139b9460"
   },
   "outputs": [],
   "source": [
    "# Obtaining Unique City Names to check population figures\n",
    "Unique_CityNames = Trip_Generation_DataFrame['City Name'].unique()\n",
    "print(Unique_CityNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c1733",
   "metadata": {
    "id": "4f6c1733"
   },
   "source": [
    "# Checking if City Name Exists in NSO Census Data\n",
    "\n",
    "- **Hal Luqa** - Yes (7,249)\n",
    "- **San Vincenz** - No (Long-term care facility in Luqa, 7,249)\n",
    "- **Il-Marsa** - Yes (5,468)\n",
    "- **L-Imsida** - Yes (13,587)\n",
    "- **Mater Dei** - No (Refers to Hospital in Msida, 13,587)\n",
    "- **Is-Swieqi** - Yes (13,044)\n",
    "- **Pembroke** - Yes (3,545)\n",
    "- **Bahar ic-Caghaq** - No (Part of Naxxar according to Postal Code, 16,912)\n",
    "- **Il-Qawra** - No (Part of San Pawl Il-Baar according to Postal Code, 32,042)\n",
    "- **San Pawl il-Bahar** - Yes (32,042)\n",
    "- **Ix-Xemxija** - No (Part of San Pawl Il-Baar according to Postal Code, 32,042)\n",
    "- **Il-Mellieha** - Yes (12,738)\n",
    "- **Il-Marfa** - No (Part of Mellieha according to Postal Code, 12,738)\n",
    "- **Ic-Cirkewwa** - No (Part of Mellieha according to Postal Code, 12,738)\n",
    "- **San Vincenz/Luqa** - No (Long-term care facility in Luqa, 7,249)\n",
    "- **Paola** - No (Part of Rahal Gdid according to NSO map, 9,339)\n",
    "- **Il-Gudja** - Yes (3,229)\n",
    "- **Hal Far** - No (Part of Birzebuga according to Postal Code, 11,844)\n",
    "- **Birzebbuga** - Yes (11,844)\n",
    "- **Il-Qajjenza** - No (Part of Birzebuga according to Postal Code, 11,844)\n",
    "- **Marsaskala** - Yes (16,804)\n",
    "- **Marsaxlokk** - Yes (3,988)\n",
    "- **Bir id-Deheb** - No (Part of Zejtun according to Postal Code, 12,409)\n",
    "- **Iz-Zejtun** - Yes (12,409)\n",
    "- **Santa Lucija, Malta** - Yes (2,617)\n",
    "- **Is-Swatar** - No (Part of Birkirkara according to Postal Code, 25,807)\n",
    "- **San Giljan** - Yes (11,653)\n",
    "- **Tas-Sliema** - Yes (19,655)\n",
    "- **Il-Gzira** - Yes (10,331)\n",
    "- **Santa Venera** - Yes (8,834)\n",
    "- **Birkirkara** - Yes (25,807)\n",
    "- **Hal Balzan** - Yes (4,774)\n",
    "- **H'Attard** - Yes (12,268)\n",
    "- **Ta' Qali** - No (Part of H'Attard according to Postal Code, 12,268)\n",
    "- **Ir-Rabat, Malta** - Yes (11,936)\n",
    "- **L-Imtarfa** - Yes (2,566)\n",
    "- **Il-Mosta** - Yes (23,482)\n",
    "- **Bugibba** - No (Part of San Pawl Il-Baar according to Postal Code, 32,042)\n",
    "- **Il-Belt Valletta** - Yes (5,157)\n",
    "- **Floriana** - Yes (1,985)\n",
    "- **Il-Hamrun** - Yes (10,514)\n",
    "- **Hal Farrug** - No (Part of Luqa according to Postal Code, 7,249)\n",
    "- **Il-Fgura** - Yes (13,066)\n",
    "- **Bormla** - Yes (4,654)\n",
    "- **L-Isla** - Yes (2,304)\n",
    "- **Il-Birgu** - Yes (2,261)\n",
    "- **Il-Kalkara** - Yes (3,105)\n",
    "- **Ix-Xghajra** - Yes (2,192)\n",
    "- **Ir-Rinella** - No (Part of Kalkara according to Postal Code, 3,105)\n",
    "- **Tal-P-et** - Yes (5,892)\n",
    "- **Ta' Xbiex** - Yes (2,092)\n",
    "- **Paceville** - No (Part of San Giljan according to Postal Code, 11,653)\n",
    "- **Il-Madliena** - No (Part of Swieqi, 13,044)\n",
    "- **Il-Kappara** - No (Part of San Gwann according to Postal Code, 14,244)\n",
    "- **Ta' Giorni** - No (Part of San Gwann according to Postal Code, 14,244)\n",
    "- **San Gwann** - Yes (14,244)\n",
    "- **L-Iklin** - Yes (3,399)\n",
    "- **In-Naxxar** - Yes (16,912)\n",
    "- **Burmarrad** - No (Part of San Pawl Il-Baar according to Postal Code, 32,042)\n",
    "- **Hal Lija** - Yes (3,162)\n",
    "- **Fleur-de-Lys** - No (Part of Birkirkara according to Postal Code, 25,807)\n",
    "- **Iz-Zebbiegh** - No (Part of Mgarr according to Postal Code, 4,840)\n",
    "- **L-Imgarr, Malta** - Yes (4,840)\n",
    "- **Ghajn Tuffieha** - No (Part of Mgarr according to Postal Code, 4,840)\n",
    "- **Il-Manikata** - No (Part of Mellieha according to Postal Code, 12,738)\n",
    "- **Hal Gharghur** - Yes (3,741)\n",
    "- **Gwardamangia** - No (Part of Pi-ta according to Postal Code, 5,892)\n",
    "- **Had-Dingli** - Yes (3,865)\n",
    "- **Il-Buskett** - No (Part of Had-Dingli according to Postal Code, 3,865)\n",
    "- **Hal Qormi** - Yes (18,099)\n",
    "- **Haz-Zebbug** - Yes (13,785)\n",
    "- **Is-Siggiewi** - Yes (9,318)\n",
    "- **Hal Kirkop** - Yes (2,527)\n",
    "- **Hal Safi** - Yes (2,641)\n",
    "- **Iz-Zurrieq** - Yes (12,295)\n",
    "- **L-Imqabba** - Yes (3,525)\n",
    "- **Il-Qrendi** - Yes (3,148)\n",
    "- **Hal Tarxien** - Yes (9,464)\n",
    "- **Bulebel** - No (Part of Zejtun according to Postal Code, 12,409)\n",
    "- **Hal Ghaxaq** - Yes (5,538)\n",
    "- **Haz-Zabbar** - Yes (17,148)\n",
    "- **Il-Bidnija** - No (Part of San Pawl Il-Baar according to Postal Code, 32,042)\n",
    "- **Ir-Rabat, Ghawdex** - Yes (7,242)\n",
    "- **Ix-Xewkija** - Yes (3,555)\n",
    "- **Ghajnsielem** - Yes (3,523)\n",
    "- **L-Imgarr, Ghawdex** - No (Part of Ghajnsielem according to NSO map, 3,523)\n",
    "- **In-Nadur** - Yes (4,548)\n",
    "- **Il-Qala** - Yes (2,300)\n",
    "- **Ta' Sannat** - Yes (2,186)\n",
    "- **Il-Munxar** - Yes (1,707)\n",
    "- **Il-Fontana, Ghawdex** - Yes (1,042)\n",
    "- **Ix-Xaghra** - Yes (5,161)\n",
    "- **L-Ghasri** - Yes (518)\n",
    "- **Iz-Zebbug, Gozo** - Yes (3,303)\n",
    "- **L-Gharb** - Yes (1,549)\n",
    "- **San Lawrenz** - Yes (772)\n",
    "- **Ta' Kercem** - Yes (1,881)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020966d-4dc6-4a74-a9f5-aaaaead23fa2",
   "metadata": {
    "id": "5020966d-4dc6-4a74-a9f5-aaaaead23fa2"
   },
   "source": [
    "## Step 7 - Obtaining the required txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89877955-5a1f-4e50-822b-8a154c2cb25b",
   "metadata": {},
   "source": [
    "### Step 7.1 - Loading All Necessary Files and Splitting Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "281da99b-900b-472f-81be-ac6fd635a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.1 - Calling/Loading necessary files\n",
    "# 1) 'Monday_Routes_Malta'\n",
    "# 2) 'Monday_Routes_Gozo'\n",
    "# 2) 'Distinct_Edges_MALTA_IncTravelTimes' (renamed to 'Malta_DistinctEdges_IncTravelTimes')\n",
    "# 3) 'Distinct_Edges_GOZO_IncTravelTimes' (renamed to 'Gozo_DistinctEdges_IncTravelTimes')\n",
    "\n",
    "Monday_Routes_Malta\n",
    "Monday_Routes_Gozo\n",
    "#Morning\n",
    "Malta_DistinctEdges_IncTravelTimes_Morning = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes_Morning.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes_Morning = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes_Morning.csv\")\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Morning = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Malta_IncTravelTimes_Morning.csv\")\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Morning = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Gozo_IncTravelTimes_Morning.csv\")\n",
    "\n",
    "\n",
    "#Evening\n",
    "Malta_DistinctEdges_IncTravelTimes_Evening = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_MALTA_IncTravelTimes_Evening.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes_Evening = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//Distinct_Edges_GOZO_IncTravelTimes_Evening.csv\")\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Evening = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Malta_IncTravelTimes_Evening.csv\")\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Evening = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//New_Distinct_Edges_Gozo_IncTravelTimes_Evening.csv\")\n",
    "\n",
    "# Add 1 second to the Travel_Time column where the value is zero\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Morning.loc[New_Distinct_Edges_Malta_IncTravelTimes_Morning['Travel_Time'] == 0, 'Travel_Time'] += 1\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Evening.loc[New_Distinct_Edges_Malta_IncTravelTimes_Evening['Travel_Time'] == 0, 'Travel_Time'] += 1\n",
    "\n",
    "\n",
    "# Change Travel Times to Minutes\n",
    "Malta_DistinctEdges_IncTravelTimes_Morning['Travel_Time'] = Malta_DistinctEdges_IncTravelTimes_Morning['Travel_Time']/60\n",
    "Gozo_DistinctEdges_IncTravelTimes_Morning['Travel_Time'] = Gozo_DistinctEdges_IncTravelTimes_Morning['Travel_Time']/60\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Morning['Travel_Time'] = New_Distinct_Edges_Malta_IncTravelTimes_Morning['Travel_Time']/60\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Travel_Time'] = New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Travel_Time']/60\n",
    "\n",
    "Malta_DistinctEdges_IncTravelTimes_Evening['Travel_Time'] = Malta_DistinctEdges_IncTravelTimes_Evening['Travel_Time']/60\n",
    "Gozo_DistinctEdges_IncTravelTimes_Evening['Travel_Time'] = Gozo_DistinctEdges_IncTravelTimes_Evening['Travel_Time']/60\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Evening['Travel_Time'] = New_Distinct_Edges_Malta_IncTravelTimes_Evening['Travel_Time']/60\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Travel_Time'] = New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Travel_Time']/60\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701f00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Monday_Routes_Malta into separate route sections according to Malta Public Transport Website\n",
    "\n",
    "South_Eastern_Routes = ['X4', '71', '72', '73', '74', '80', '82', '84', '85', '88', '91', '92', '93']\n",
    "Northern_Harbour_Routes = ['13A', '14', '15', '16', '21', '22', '58', '58A', '24', '25', '32', '35', '63', '64', '110', '121', '225']\n",
    "Southern_Harbour_Routes = ['1', '2', '3', '4', '83', '90', '94', '120', '124', '130', '133', '150']\n",
    "Western_Routes = ['50', '51', '52', '53', '54', '56', '61', '62', '186', '202', '109', '109A']\n",
    "Northern_Routes = ['X1A', '13', '31', '41', '42', '43', '44', '45', '46', '47', '48', '101', '103', '203', '212', '221', '222', '223', '238', '260', '250', 'X300']\n",
    "Mater_Dei_North_Routes = ['106', '181', '182', '209', '233', '280']\n",
    "Mater_Dei_South_Routes = ['117', '122', '135', '204', '206', '210', '213', '218', '226', '300']\n",
    "Airport_Routes = ['X1', '119', 'X2', 'X3', '201']\n",
    "\n",
    "# Defining a Separate DataFrame for each specifiv Route Set\n",
    "Monday_Routes_Malta_South_Eastern_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(South_Eastern_Routes)]\n",
    "Monday_Routes_Malta_Northern_Harbour_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Northern_Harbour_Routes)]\n",
    "Monday_Routes_Malta_Southern_Harbour_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Southern_Harbour_Routes)]\n",
    "Monday_Routes_Malta_Western_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Western_Routes)]\n",
    "Monday_Routes_Malta_Northern_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Northern_Routes)]\n",
    "Monday_Routes_Malta_Mater_Dei_North_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Mater_Dei_North_Routes)]\n",
    "Monday_Routes_Malta_Mater_Dei_South_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Mater_Dei_South_Routes)]\n",
    "Monday_Routes_Malta_Mater_Dei_Airport_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Airport_Routes)]\n",
    "\n",
    "\n",
    "# Create a List of TUples: (name, dataframe)\n",
    "Monday_Routes_Malta_List = [\n",
    "    ('South_eastern_routes', Monday_Routes_Malta_South_Eastern_Routes),\n",
    "    ('Northern_harbour_routes', Monday_Routes_Malta_Northern_Harbour_Routes),\n",
    "    ('Southern_harbour_routes', Monday_Routes_Malta_Southern_Harbour_Routes),\n",
    "    ('Western_routes', Monday_Routes_Malta_Western_Routes),\n",
    "    ('Northern_routes', Monday_Routes_Malta_Northern_Routes),\n",
    "    ('Mater_dei_north_routes', Monday_Routes_Malta_Mater_Dei_North_Routes),\n",
    "    ('Mater_dei_south_routes', Monday_Routes_Malta_Mater_Dei_South_Routes),\n",
    "    ('Airport_routes', Monday_Routes_Malta_Mater_Dei_Airport_Routes)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e38d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Routes Malta - Skip Cell\n",
    "Monday_Routes_Malta_South_Eastern_Routes.to_csv('South_Eastern_Routes.csv')\n",
    "Monday_Routes_Malta_Northern_Harbour_Routes.to_csv('Northern_Harbour_Routes.csv')\n",
    "Monday_Routes_Malta_Southern_Harbour_Routes.to_csv('Southern_Harbour_Routes.csv')\n",
    "Monday_Routes_Malta_Western_Routes.to_csv('Western_Routes.csv')\n",
    "Monday_Routes_Malta_Northern_Routes.to_csv('Northern_Routes.csv')\n",
    "Monday_Routes_Malta_Mater_Dei_North_Routes.to_csv('Mater_Dei_North_Routes.csv')\n",
    "Monday_Routes_Malta_Mater_Dei_South_Routes.to_csv('Mater_Dei_South_Routes.csv')\n",
    "Monday_Routes_Malta_Mater_Dei_Airport_Routes.to_csv('Airport_Routes.csv')\n",
    "# Saving Routes Gozo\n",
    "Monday_Routes_Gozo.to_csv('Gozo_Routes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf99475-a047-4726-ab38-0232825a9638",
   "metadata": {
    "id": "cdf99475-a047-4726-ab38-0232825a9638"
   },
   "outputs": [],
   "source": [
    "# Data Cleaning (Take shortest path if available ex. Stop 3 to Stop 819 is 56 seconds long on the otherhand Stop 819 to Stop 3\n",
    "# is 1019 seconds long (The former is correct))\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Malta_DistinctEdges_IncTravelTimes_Morning['Standardized_Route'] = Malta_DistinctEdges_IncTravelTimes_Morning['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Malta_DistinctEdges_IncTravelTimes_Morning['Travel_Time'] = Malta_DistinctEdges_IncTravelTimes_Morning.groupby('Standardized_Route')['Travel_Time'].transform('min')\n",
    "# Drop the helper column if not needed\n",
    "Malta_DistinctEdges_IncTravelTimes_Morning_Min = Malta_DistinctEdges_IncTravelTimes_Morning.drop(columns=['Standardized_Route'])\n",
    "\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Gozo_DistinctEdges_IncTravelTimes_Morning['Standardized_Route'] = Gozo_DistinctEdges_IncTravelTimes_Morning['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Gozo_DistinctEdges_IncTravelTimes_Morning['Travel_Time'] = Gozo_DistinctEdges_IncTravelTimes_Morning.groupby('Standardized_Route')['Travel_Time'].transform('min')\n",
    "# Drop the helper column if not needed\n",
    "Gozo_DistinctEdges_IncTravelTimes_Morning_Min = Gozo_DistinctEdges_IncTravelTimes_Morning.drop(columns=['Standardized_Route'])\n",
    "\n",
    "\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Malta_DistinctEdges_IncTravelTimes_Evening['Standardized_Route'] = Malta_DistinctEdges_IncTravelTimes_Evening['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Malta_DistinctEdges_IncTravelTimes_Evening['Travel_Time'] = Malta_DistinctEdges_IncTravelTimes_Evening.groupby('Standardized_Route')['Travel_Time'].transform('min')\n",
    "# Drop the helper column if not needed\n",
    "Malta_DistinctEdges_IncTravelTimes_Evening_Min = Malta_DistinctEdges_IncTravelTimes_Evening.drop(columns=['Standardized_Route'])\n",
    "\n",
    "\n",
    "# Standardize route names to be order-independent\n",
    "Gozo_DistinctEdges_IncTravelTimes_Evening['Standardized_Route'] = Gozo_DistinctEdges_IncTravelTimes_Evening['Bus_Stop_Next_Bus_Stop'].apply(lambda x: '_to_'.join(sorted(x.split('_to_'))))\n",
    "# Keep the row with the minimum travel time for each standardized route\n",
    "Gozo_DistinctEdges_IncTravelTimes_Evening['Travel_Time'] = Gozo_DistinctEdges_IncTravelTimes_Evening.groupby('Standardized_Route')['Travel_Time'].transform('min')\n",
    "# Drop the helper column if not needed\n",
    "Gozo_DistinctEdges_IncTravelTimes_Evening_Min = Gozo_DistinctEdges_IncTravelTimes_Evening.drop(columns=['Standardized_Route'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f52bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Malta_DistinctEdges_IncTravelTimes_Morning_Min.to_csv(\"Malta_DistinctEdges_IncTravelTimes_Morning_Min.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes_Morning_Min.to_csv(\"Gozo_DistinctEdges_IncTravelTimes_Morning_Min.csv\")\n",
    "Malta_DistinctEdges_IncTravelTimes_Evening_Min.to_csv(\"Malta_DistinctEdges_IncTravelTimes_Evening_Min.csv\")\n",
    "Gozo_DistinctEdges_IncTravelTimes_Evening_Min.to_csv(\"Gozo_DistinctEdges_IncTravelTimes_Evening_Min.csv\")\n",
    "\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Morning.to_csv(\"New_Distinct_Edges_Malta_IncTravelTimes_Morning.csv\")\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Morning.to_csv(\"New_Distinct_Edges_Gozo_IncTravelTimes_Morning.csv\")\n",
    "New_Distinct_Edges_Malta_IncTravelTimes_Evening.to_csv(\"New_Distinct_Edges_Malta_IncTravelTimes_Evening.csv\")\n",
    "New_Distinct_Edges_Gozo_IncTravelTimes_Evening.to_csv(\"New_Distinct_Edges_Gozo_IncTravelTimes_Evening.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf337af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21532\\2489717394.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Trip_Generation_DataFrame.loc[:, \"Index\"] = range(1, len(Trip_Generation_DataFrame) + 1)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21532\\2489717394.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Trip_Generation_DataFrame['City Name - Stop Island'] =  Trip_Generation_DataFrame['City Name'] + '.' + Trip_Generation_DataFrame['Stop Island']\n"
     ]
    }
   ],
   "source": [
    "# Preliminaries for creating Passenger-Demand Matrix\n",
    "All_Routes_Copy = pd.concat([Monday_Routes_Malta, Monday_Routes_Gozo], ignore_index=True)\n",
    "\n",
    "# Keeping Only essential data from 'All_Routes_Copy' DataFrame\n",
    "Trip_Generation_DataFrame = All_Routes_Copy[['Stops','City Name', 'Bus_Stop_ID', 'Longitude_Final', 'Latitude_Final', 'Stop Island']]\n",
    "Trip_Generation_DataFrame.loc[:, \"Index\"] = range(1, len(Trip_Generation_DataFrame) + 1)\n",
    "\n",
    "\n",
    "# Step 1 - Loading Census data\n",
    "CENSUS_DATA = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//CENSUS_DATA.xlsx\")\n",
    "\n",
    "# Step 2 - Append 'Proper Name', 'Stop Island' and 'Population' columns from 'CENSUS_DATA' DataFrame to 'Trip_Generation_DataFrame' DataFrame\n",
    "# Rename DataFrame as 'Stop_Info'\n",
    "# Create Column 'City Name - Stop Island' in 'Trip_Generation_DataFrame'\n",
    "Trip_Generation_DataFrame['City Name - Stop Island'] =  Trip_Generation_DataFrame['City Name'] + '.' + Trip_Generation_DataFrame['Stop Island']\n",
    "# Create column 'City Name - Stop Island' in 'CENSUS_DATA'\n",
    "CENSUS_DATA['City Name - Stop Island'] = CENSUS_DATA['Name in Sheet'] + '.' + CENSUS_DATA['Stop Island']\n",
    "# Utilise newly created column to concatenate 'Trip_Generation_DataFrame' and 'CENSUS_DATA'\n",
    "Stop_Info = pd.merge(Trip_Generation_DataFrame[['Stops', 'Bus_Stop_ID', 'Longitude_Final', 'Latitude_Final', 'City Name - Stop Island', \"Index\"]], CENSUS_DATA[['City Name - Stop Island', 'Stop Island', 'Proper Name', 'Population']], on=\"City Name - Stop Island\", how=\"inner\",  sort=False)\n",
    "Stop_Info = Stop_Info.sort_values(\"Index\").drop(columns=[\"Index\"])\n",
    "\n",
    "# Step 3 - Setting estimates for individuals making use of bus in Malta and Gozo at 8 AM\n",
    "# Morning Model\n",
    "# Trip Origin will be from Home\n",
    "# Trip Destination will be to Work\n",
    "\n",
    "# Time to Consider - 8 AM\n",
    "# Total Number of trips by bus (Whole day) - 34,679\n",
    "# Total Number of trips by bus (Whole day - Malta) - 32390.186\n",
    "# Total Number of trips by bus (Whole day - Gozo) - 2288.814\n",
    "# Proportion of trips occuring at 8 AM - 82,000/638,456 (12.843484907%)\n",
    "Bus_Travel_Morning_Malta = 1000000*(82000/638456)\n",
    "Bus_Travel_Morning_Gozo = 100000*(82000/638456)\n",
    "\n",
    "\n",
    "# Step 4 - Calculate Number of Individuals leaving each stop\n",
    "# 'Unique_Stops' Dataframe - Remove duplicate 'Bus_Stop_ID' entries from 'Stop_Info' DataFrame\n",
    "Unique_Stops = Stop_Info.drop_duplicates(subset=['Bus_Stop_ID'])\n",
    "# Count Number of distinct stops in each city (cities denoted by 'Proper Name' column)\n",
    "BusStopPerCity = Unique_Stops.groupby('Proper Name')['Bus_Stop_ID'].count().reset_index()\n",
    "# 'Unique_City' Dataframe - Remove duplicate 'Proper Name' entries from 'Stop_Info' DataFrame\n",
    "Unique_City = Stop_Info.drop_duplicates(subset=['Proper Name'])\n",
    "# 'BusStopPerCity' DataFrame - Append 'Population' and 'Stop Island' columns to BusStopPerCity\n",
    "BusStopPerCity = pd.merge(BusStopPerCity, Unique_City[['Proper Name','Population', 'Stop Island']], on=\"Proper Name\", how=\"inner\",  sort=False)\n",
    "# Calculate Total Population per Island\n",
    "total_population_per_island = BusStopPerCity.groupby('Stop Island')['Population'].sum().rename('Total_population_in_Island')\n",
    "# Merge Total Population per Island to BusStopPerCity DataFrame\n",
    "BusStopPerCity = BusStopPerCity.merge(total_population_per_island, on='Stop Island')\n",
    "# Calculate Population Proportion in each city\n",
    "BusStopPerCity['Pop_Proportion'] = BusStopPerCity['Population'] / BusStopPerCity['Total_population_in_Island']\n",
    "# Calculate 'POP_LEAVING_Per_City' by multiplying Population proportion in city and total people travelling using bus\n",
    "BusStopPerCity['POP_LEAVING_Per_City'] = np.where(\n",
    "    BusStopPerCity['Stop Island'] == 'MALTA STOP',\n",
    "    np.ceil(BusStopPerCity['Pop_Proportion'] * Bus_Travel_Morning_Malta),\n",
    "    np.ceil(BusStopPerCity['Pop_Proportion'] * Bus_Travel_Morning_Gozo)\n",
    ")\n",
    "# Calculate 'POP_LEAVING_Per_Stop' by dividing POP_LEAVING_Per_City by number of stops in city\n",
    "BusStopPerCity['POP_Leaving_Per_Stop'] = np.ceil(BusStopPerCity['POP_LEAVING_Per_City']/BusStopPerCity['Bus_Stop_ID'])\n",
    "\n",
    "# Step 5 - Calculate Number of Individuals arriving at each stop\n",
    "#Get total stops per island\n",
    "total_times_stops_appears = Stop_Info.groupby('Bus_Stop_ID').size().reset_index(name='total_times_stops_appears')\n",
    "#Merge with original 'Stop_Info' DataFrame\n",
    "Stop_Info_WOccofStop = Stop_Info.merge(total_times_stops_appears, on='Bus_Stop_ID', how = 'left')\n",
    "#Consider only one instance of each distinc 'Bus_Stop_ID'\n",
    "Unique_Stops_Updated = Stop_Info_WOccofStop.drop_duplicates(subset=['Bus_Stop_ID'])\n",
    "# Get total stops per island\n",
    "total_stops_in_island = Unique_Stops_Updated.groupby('Stop Island')['total_times_stops_appears'].sum().rename('Total_stops_in_Island')\n",
    "# Merge with original DataFrame\n",
    "Unique_Stops_Updated = Unique_Stops_Updated.merge(total_stops_in_island, on='Stop Island')\n",
    "# Calculate proportion of stops per city\n",
    "Unique_Stops_Updated['Stop_Proportion'] = Unique_Stops_Updated['total_times_stops_appears'] / Unique_Stops_Updated['Total_stops_in_Island']\n",
    "# Calculate 'POP_COMING' by multiplying Population proportion in city and total people travelling using bus\n",
    "Unique_Stops_Updated['POP_COMING'] = np.where(\n",
    "    Unique_Stops_Updated['Stop Island'] == 'MALTA STOP',\n",
    "    np.ceil(Unique_Stops_Updated['Stop_Proportion'] * Bus_Travel_Morning_Malta),\n",
    "    np.ceil(Unique_Stops_Updated['Stop_Proportion'] * Bus_Travel_Morning_Gozo)\n",
    ")\n",
    "\n",
    "# Obtain Final_Dataset representing Individuals exiting and entering each stop\n",
    "Final_Dataset = pd.merge(Unique_Stops_Updated, BusStopPerCity[['Proper Name','POP_Leaving_Per_Stop']], on=\"Proper Name\", how=\"inner\",  sort=False)\n",
    "\n",
    "\n",
    "# Summarise Data Set\n",
    "Morning_Dataset = Final_Dataset[['Stops', 'Bus_Stop_ID', 'Proper Name', 'Longitude_Final', 'Latitude_Final', 'Stop Island', 'POP_COMING', 'POP_Leaving_Per_Stop']]\n",
    "\n",
    "# Sort DataFrame\n",
    "Morning_Dataset_Sorted = Morning_Dataset.sort_values(by=\"Bus_Stop_ID\", key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int))\n",
    "\n",
    "Morning_Dataset_Sorted_Malta = Morning_Dataset_Sorted[Morning_Dataset_Sorted[\"Stop Island\"] == \"MALTA STOP\"]\n",
    "Morning_Dataset_Sorted_Gozo = Morning_Dataset_Sorted[Morning_Dataset_Sorted[\"Stop Island\"] == \"GOZO STOP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa0f2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21532\\330565371.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Trip_Generation_DataFrame.loc[:, \"Index\"] = range(1, len(Trip_Generation_DataFrame) + 1)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21532\\330565371.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Trip_Generation_DataFrame['City Name - Stop Island'] =  Trip_Generation_DataFrame['City Name'] + '.' + Trip_Generation_DataFrame['Stop Island']\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21532\\330565371.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Evening_Dataset['POP_COMING'], Evening_Dataset['POP_Leaving_Per_Stop'] = Evening_Dataset['POP_Leaving_Per_Stop'], Evening_Dataset['POP_COMING']\n"
     ]
    }
   ],
   "source": [
    "# Preliminaries for creating Passenger-Demand Matrix\n",
    "All_Routes_Copy = pd.concat([Monday_Routes_Malta, Monday_Routes_Gozo], ignore_index=True)\n",
    "\n",
    "# Keeping Only essential data from 'All_Routes_Copy' DataFrame\n",
    "Trip_Generation_DataFrame = All_Routes_Copy[['Stops','City Name', 'Bus_Stop_ID', 'Longitude_Final', 'Latitude_Final', 'Stop Island']]\n",
    "Trip_Generation_DataFrame.loc[:, \"Index\"] = range(1, len(Trip_Generation_DataFrame) + 1)\n",
    "\n",
    "\n",
    "# Step 1 - Loading Census data\n",
    "CENSUS_DATA = pd.read_excel(\"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Files used for Data Visualisation//CENSUS_DATA.xlsx\")\n",
    "\n",
    "# Step 2 - Append 'Proper Name', 'Stop Island' and 'Population' columns from 'CENSUS_DATA' DataFrame to 'Trip_Generation_DataFrame' DataFrame\n",
    "# Rename DataFrame as 'Stop_Info'\n",
    "# Create Column 'City Name - Stop Island' in 'Trip_Generation_DataFrame'\n",
    "Trip_Generation_DataFrame['City Name - Stop Island'] =  Trip_Generation_DataFrame['City Name'] + '.' + Trip_Generation_DataFrame['Stop Island']\n",
    "# Create column 'City Name - Stop Island' in 'CENSUS_DATA'\n",
    "CENSUS_DATA['City Name - Stop Island'] = CENSUS_DATA['Name in Sheet'] + '.' + CENSUS_DATA['Stop Island']\n",
    "# Utilise newly created column to concatenate 'Trip_Generation_DataFrame' and 'CENSUS_DATA'\n",
    "Stop_Info = pd.merge(Trip_Generation_DataFrame[['Stops', 'Bus_Stop_ID', 'Longitude_Final', 'Latitude_Final', 'City Name - Stop Island', \"Index\"]], CENSUS_DATA[['City Name - Stop Island', 'Stop Island', 'Proper Name', 'Population']], on=\"City Name - Stop Island\", how=\"inner\",  sort=False)\n",
    "Stop_Info = Stop_Info.sort_values(\"Index\").drop(columns=[\"Index\"])\n",
    "\n",
    "# Step 3 - Setting estimates for individuals making use of bus in Malta and Gozo at 5 PM\n",
    "\n",
    "# Evening Model\n",
    "# Trip origin will be from work\n",
    "# Trip destination will be to home\n",
    "\n",
    "# Time to Consider - 5 PM\n",
    "# Total Number of trips by bus (Whole day) - 34,679\n",
    "# Total Number of trips by bus (Whole day - Malta) - 32390.186\n",
    "# Total Number of trips by bus (Whole day - Gozo) - 2288.814\n",
    "# Proportion of trips occuring at 5 PM - 45,000/638,456 (7.04825391256%)\n",
    "Bus_Travel_Evening_Malta = 1000000*(45000/638456)\n",
    "Bus_Travel_Evening_Gozo = 100000*(45000/638456)\n",
    "\n",
    "\n",
    "\n",
    "# Step 4 - Calculate Number of Individuals leaving each stop\n",
    "# 'Unique_Stops' Dataframe - Remove duplicate 'Bus_Stop_ID' entries from 'Stop_Info' DataFrame\n",
    "Unique_Stops = Stop_Info.drop_duplicates(subset=['Bus_Stop_ID'])\n",
    "# Count Number of distinct stops in each city (cities denoted by 'Proper Name' column)\n",
    "BusStopPerCity = Unique_Stops.groupby('Proper Name')['Bus_Stop_ID'].count().reset_index()\n",
    "# 'Unique_City' Dataframe - Remove duplicate 'Proper Name' entries from 'Stop_Info' DataFrame\n",
    "Unique_City = Stop_Info.drop_duplicates(subset=['Proper Name'])\n",
    "# 'BusStopPerCity' DataFrame - Append 'Population' and 'Stop Island' columns to BusStopPerCity\n",
    "BusStopPerCity = pd.merge(BusStopPerCity, Unique_City[['Proper Name','Population', 'Stop Island']], on=\"Proper Name\", how=\"inner\",  sort=False)\n",
    "# Calculate Total Population per Island\n",
    "total_population_per_island = BusStopPerCity.groupby('Stop Island')['Population'].sum().rename('Total_population_in_Island')\n",
    "# Merge Total Population per Island to BusStopPerCity DataFrame\n",
    "BusStopPerCity = BusStopPerCity.merge(total_population_per_island, on='Stop Island')\n",
    "# Calculate Population Proportion in each city\n",
    "BusStopPerCity['Pop_Proportion'] = BusStopPerCity['Population'] / BusStopPerCity['Total_population_in_Island']\n",
    "# Calculate 'POP_LEAVING_Per_City' by multiplying Population proportion in city and total people travelling using bus\n",
    "BusStopPerCity['POP_LEAVING_Per_City'] = np.where(\n",
    "    BusStopPerCity['Stop Island'] == 'MALTA STOP',\n",
    "    np.ceil(BusStopPerCity['Pop_Proportion'] * Bus_Travel_Evening_Malta),\n",
    "    np.ceil(BusStopPerCity['Pop_Proportion'] * Bus_Travel_Evening_Gozo)\n",
    ")\n",
    "# Calculate 'POP_LEAVING_Per_Stop' by dividing POP_LEAVING_Per_City by number of stops in city\n",
    "BusStopPerCity['POP_Leaving_Per_Stop'] = np.ceil(BusStopPerCity['POP_LEAVING_Per_City']/BusStopPerCity['Bus_Stop_ID'])\n",
    "\n",
    "# Step 5 - Calculate Number of Individuals arriving at each stop\n",
    "#Get total stops per island\n",
    "total_times_stops_appears = Stop_Info.groupby('Bus_Stop_ID').size().reset_index(name='total_times_stops_appears')\n",
    "#Merge with original 'Stop_Info' DataFrame\n",
    "Stop_Info_WOccofStop = Stop_Info.merge(total_times_stops_appears, on='Bus_Stop_ID', how = 'left')\n",
    "#Consider only one instance of each distinc 'Bus_Stop_ID'\n",
    "Unique_Stops_Updated = Stop_Info_WOccofStop.drop_duplicates(subset=['Bus_Stop_ID'])\n",
    "# Get total stops per island\n",
    "total_stops_in_island = Unique_Stops_Updated.groupby('Stop Island')['total_times_stops_appears'].sum().rename('Total_stops_in_Island')\n",
    "# Merge with original DataFrame\n",
    "Unique_Stops_Updated = Unique_Stops_Updated.merge(total_stops_in_island, on='Stop Island')\n",
    "# Calculate proportion of stops per city\n",
    "Unique_Stops_Updated['Stop_Proportion'] = Unique_Stops_Updated['total_times_stops_appears'] / Unique_Stops_Updated['Total_stops_in_Island']\n",
    "# Calculate 'POP_COMING' by multiplying Population proportion in city and total people travelling using bus\n",
    "Unique_Stops_Updated['POP_COMING'] = np.where(\n",
    "    Unique_Stops_Updated['Stop Island'] == 'MALTA STOP',\n",
    "    np.ceil(Unique_Stops_Updated['Stop_Proportion'] * Bus_Travel_Evening_Malta),\n",
    "    np.ceil(Unique_Stops_Updated['Stop_Proportion'] * Bus_Travel_Evening_Gozo)\n",
    ")\n",
    "\n",
    "# Obtain Final_Dataset representing Individuals exiting and entering each stop\n",
    "Final_Dataset = pd.merge(Unique_Stops_Updated, BusStopPerCity[['Proper Name','POP_Leaving_Per_Stop']], on=\"Proper Name\", how=\"inner\",  sort=False)\n",
    "\n",
    "\n",
    "# Summarise Data Set\n",
    "Evening_Dataset = Final_Dataset[['Stops', 'Bus_Stop_ID', 'Proper Name', 'Longitude_Final', 'Latitude_Final', 'Stop Island', 'POP_COMING', 'POP_Leaving_Per_Stop']]\n",
    "Evening_Dataset['POP_COMING'], Evening_Dataset['POP_Leaving_Per_Stop'] = Evening_Dataset['POP_Leaving_Per_Stop'], Evening_Dataset['POP_COMING']\n",
    "\n",
    "# Sort DataFrame\n",
    "Evening_Dataset_Sorted = Evening_Dataset.sort_values(by=\"Bus_Stop_ID\", key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int))\n",
    "\n",
    "Evening_Dataset_Sorted_Malta = Evening_Dataset_Sorted[Evening_Dataset_Sorted[\"Stop Island\"] == \"MALTA STOP\"]\n",
    "Evening_Dataset_Sorted_Gozo = Evening_Dataset_Sorted[Evening_Dataset_Sorted[\"Stop Island\"] == \"GOZO STOP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76aabbe-82b5-4f30-9561-ad2ff6e257ec",
   "metadata": {},
   "source": [
    "### Step 7.2 - Morning Model (7AM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb375afc",
   "metadata": {},
   "source": [
    "#### Step 7.2.1 - Obtaining Text Files for Malta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Coords text file\n",
    "for name, df in Monday_Routes_Malta_List:\n",
    "    # 1 - Obtain List of Unique Stops in Malta\n",
    "    unique_stops = df.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "    # 2 - Sort Stops in Descending Order\n",
    "    unique_stops_sorted  = unique_stops.sort_values(by='Bus_Stop_ID', key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int))\n",
    "    # 3 - Limit 'Latitude_Final' and 'Longitude_Final' columns to 7 Decimal Places\n",
    "    unique_stops_sorted[['Latitude_Final', 'Longitude_Final']] = unique_stops_sorted[['Latitude_Final', 'Longitude_Final']].round(7)\n",
    "    # 4 - Obtain 'MaltaCoords.txt' file\n",
    "    File_Name = f\"{name}Coords.txt\"\n",
    "    Columns_Required = ['Latitude_Final', 'Longitude_Final']\n",
    "    Number_of_Rows = len(unique_stops_sorted)\n",
    "    \n",
    "    with open(File_Name, 'w') as File:\n",
    "        # Write row count at top of csv file\n",
    "        File.write(f\"{Number_of_Rows}\\n\")\n",
    "        unique_stops_sorted[Columns_Required].to_csv(File, sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6a841fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix for South_eastern_routes populated successfully.\n",
      "Matrix for Northern_harbour_routes populated successfully.\n",
      "Matrix for Southern_harbour_routes populated successfully.\n",
      "Matrix for Western_routes populated successfully.\n",
      "Matrix for Northern_routes populated successfully.\n",
      "Matrix for Mater_dei_north_routes populated successfully.\n",
      "Matrix for Mater_dei_south_routes populated successfully.\n",
      "Matrix for Airport_routes populated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Obtain Travel Time Text File\n",
    "for route_name, df in Monday_Routes_Malta_List:\n",
    "    # 1 - Obtain list of unique stops for this route\n",
    "    unique_stops = df.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "    unique_stops_sorted = unique_stops.sort_values(\n",
    "        by='Bus_Stop_ID',\n",
    "        key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int)\n",
    "    )\n",
    "    \n",
    "    # Create Bus Stops list\n",
    "    bus_stops_list = unique_stops_sorted['Bus_Stop_ID'].unique()\n",
    "    # Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "    travel_time_matrix = pd.DataFrame(index=bus_stops_list, columns=bus_stops_list)\n",
    "    \n",
    "    # Set index for faster lookup in malta_edges\n",
    "    malta_edges = Malta_DistinctEdges_IncTravelTimes_Morning_Min.copy()\n",
    "    malta_edges.set_index(['Bus_Stop_ID', 'Next_Bus_Stop_ID'], inplace=True)\n",
    "    \n",
    "    # Initialize the matrix with np.inf (as a default)\n",
    "    travel_time_matrix[:] = np.inf\n",
    "\n",
    "    # Set diagonal entries to zero\n",
    "    np.fill_diagonal(travel_time_matrix.values, 0)\n",
    "\n",
    "    # Loop through each bus_stop combination specified in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        bus_stop_pair = row['Bus_Stop_Next_Bus_Stop']\n",
    "        if pd.notna(bus_stop_pair):  # Ensure the value is not NaN\n",
    "            # Convert to string and split\n",
    "            stop_0, stop_1 = str(bus_stop_pair).split('_to_')\n",
    "        \n",
    "            if stop_0 == stop_1:\n",
    "                travel_time_matrix.at[stop_0, stop_1] = 0\n",
    "            elif (stop_0, stop_1) in malta_edges.index:\n",
    "                travel_time_matrix.at[stop_0, stop_1] = malta_edges.at[(stop_0, stop_1), 'Travel_Time']\n",
    "\n",
    "    \n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Airport_routes':\n",
    "        AR1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_23') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_24')]\n",
    "        travel_time_AR1 = AR1['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_23', 'Stop_24'] = travel_time_AR1[0]\n",
    "        AR2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_0') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_29')]\n",
    "        travel_time_AR2 = AR2['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_0', 'Stop_29'] = travel_time_AR2[0]\n",
    "        AR3 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_29') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_34')]\n",
    "        travel_time_AR3 = AR3['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_29', 'Stop_34'] = travel_time_AR3[0]   \n",
    "        AR4 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_29') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_0')]\n",
    "        travel_time_AR4 = AR4['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_29', 'Stop_0'] = travel_time_AR4[0]\n",
    "        AR5 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_144') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_167')]\n",
    "        travel_time_AR5 = AR5['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_144', 'Stop_167'] = travel_time_AR5[0]\n",
    "        AR6 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_9') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_112')]\n",
    "        travel_time_AR6 = AR6['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_9', 'Stop_112'] = travel_time_AR6[0]\n",
    "        AR7 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_82') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_83')]\n",
    "        travel_time_AR7 = AR7['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_82', 'Stop_83'] = travel_time_AR7[0]\n",
    "        AR8 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_158')]\n",
    "        travel_time_AR8 = AR8['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_157', 'Stop_158'] = travel_time_AR8[0]\n",
    "\n",
    "    if route_name == 'Mater_dei_north_routes':\n",
    "        MDN1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_7') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_8')]\n",
    "        travel_time_MDN1 = MDN1['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_7', 'Stop_8'] = travel_time_MDN1  # Ensure the indices are correct as per your matrix setup\n",
    "        MDN2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_456')]\n",
    "        travel_time_MDN2 = MDN2['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_456'] = travel_time_MDN2  # Ensure the indices are correct as per your matrix setup\n",
    "\n",
    "    if route_name == 'Mater_dei_south_routes':\n",
    "        MDS1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_7') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_27')]\n",
    "        travel_time_MDS1 = MDS1['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_7', 'Stop_27'] = travel_time_MDS1\n",
    "        MDS2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_223')]\n",
    "        travel_time_MDS2 = MDS2['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_223'] = travel_time_MDS2\n",
    "        MDS3 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_82') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_83')]\n",
    "        travel_time_MDS3 = MDS3['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_82', 'Stop_83'] = travel_time_MDS3\n",
    "        MDS4 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_7') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_8')]\n",
    "        travel_time_MDS4 = MDS4['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_7', 'Stop_8'] = travel_time_MDS4\n",
    "\n",
    "    if route_name == 'Northern_harbour_routes':\n",
    "        NH1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_347')]\n",
    "        travel_time_NH1 = NH1['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_347'] = travel_time_NH1\n",
    "        NH2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_349') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_329')]\n",
    "        travel_time_NH2 = NH2['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_349', 'Stop_329'] = travel_time_NH2\n",
    "        NH3 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_355')]\n",
    "        travel_time_NH3 = NH3['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_355'] = travel_time_NH3\n",
    "        NH4 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_232') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_233')]\n",
    "        travel_time_NH4 = NH4['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_232', 'Stop_233'] = travel_time_NH4\n",
    "        NH5 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_171')]\n",
    "        travel_time_NH5 = NH5['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_171'] = travel_time_NH5\n",
    "        NH6 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_412')]\n",
    "        travel_time_NH6 = NH6['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_412'] = travel_time_NH6\n",
    "        NH7 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_575')]\n",
    "        travel_time_NH7 = NH7['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_575'] = travel_time_NH7\n",
    "        NH8 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_752')]\n",
    "        travel_time_NH8 = NH8['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_752'] = travel_time_NH8\n",
    "        NH9 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_244') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_232')]\n",
    "        travel_time_NH9 = NH9['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_244', 'Stop_232'] = travel_time_NH9\n",
    "        NH10 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_114') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_112')]\n",
    "        travel_time_NH10 = NH10['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_114', 'Stop_112'] = travel_time_NH10\n",
    "        NH11 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_327')]\n",
    "        travel_time_NH11 = NH11['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_327'] = travel_time_NH11\n",
    "        \n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Northern_routes':\n",
    "        N1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_327')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_327'] = N1['Travel_Time'].values[0]\n",
    "        N2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_456')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_456'] = N2['Travel_Time'].values[0]\n",
    "        N3 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_424')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_424'] = N3['Travel_Time'].values[0]\n",
    "        N4 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_23') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_24')]\n",
    "        travel_time_matrix.at['Stop_23', 'Stop_24'] = N4['Travel_Time'].values[0]\n",
    "        N5 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_471')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_471'] = N5['Travel_Time'].values[0]\n",
    "        N6 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_506')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_506'] = N6['Travel_Time'].values[0]\n",
    "        N7 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_509')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_509'] = N7['Travel_Time'].values[0]\n",
    "        N8 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_528') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_525')]\n",
    "        travel_time_matrix.at['Stop_528', 'Stop_525'] = N8['Travel_Time'].values[0]\n",
    "        N9 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_540')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_540'] = N9['Travel_Time'].values[0]\n",
    "        N10 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_349') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_329')]\n",
    "        travel_time_matrix.at['Stop_349', 'Stop_329'] = N10['Travel_Time'].values[0]\n",
    "        N11 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_195')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_195'] = N11['Travel_Time'].values[0]\n",
    "        N12 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_232') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_384')]\n",
    "        travel_time_matrix.at['Stop_232', 'Stop_384'] = N12['Travel_Time'].values[0]\n",
    "        N13 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_244') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_232')]\n",
    "        travel_time_matrix.at['Stop_244', 'Stop_232'] = N13['Travel_Time'].values[0]\n",
    "        N14 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_1120')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_1120'] = N14['Travel_Time'].values[0]\n",
    "        N15 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_1122')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_1122'] = N15['Travel_Time'].values[0]\n",
    "\n",
    "\n",
    "    # Adding Required Connections\n",
    "    if route_name == 'South_eastern_routes':\n",
    "        SE1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_772')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_772'] = SE1['Travel_Time'].values[0]\n",
    "        SE2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_805')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_805'] = SE2['Travel_Time'].values[0]\n",
    "        SE3 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_44') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_43')]\n",
    "        travel_time_matrix.at['Stop_44', 'Stop_43'] = SE3['Travel_Time'].values[0]\n",
    "        SE4 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_853')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_853'] = SE4['Travel_Time'].values[0]\n",
    "        SE5 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_878')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_878'] = SE5['Travel_Time'].values[0]\n",
    "        SE6 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_927') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_928')]\n",
    "        travel_time_matrix.at['Stop_927', 'Stop_928'] = SE6['Travel_Time'].values[0]\n",
    "        SE7 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_895')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_895'] = SE7['Travel_Time'].values[0]\n",
    "        SE8 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_245')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_245'] = SE8['Travel_Time'].values[0]\n",
    "        SE9 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_933')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_933'] = SE9['Travel_Time'].values[0]\n",
    "        SE10 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_171')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_171'] = SE10['Travel_Time'].values[0]\n",
    "        SE11 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_57') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_190')]\n",
    "        travel_time_matrix.at['Stop_57', 'Stop_190'] = SE11['Travel_Time'].values[0]\n",
    "        SE12 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_914')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_914'] = SE12['Travel_Time'].values[0]\n",
    "\n",
    "        \n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Southern_harbour_routes':\n",
    "        SH1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_280')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_280'] = SH1['Travel_Time'].values[0]\n",
    "        SH2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_319')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_319'] = SH2['Travel_Time'].values[0]\n",
    "        SH3 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_895')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_895'] = SH3['Travel_Time'].values[0]\n",
    "        SH4 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_932')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_932'] = SH4['Travel_Time'].values[0]\n",
    "        SH5 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_349') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_329')]\n",
    "        travel_time_matrix.at['Stop_349', 'Stop_329'] = SH5['Travel_Time'].values[0]\n",
    "        SH6 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_271') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_949')]\n",
    "        travel_time_matrix.at['Stop_271', 'Stop_949'] = SH6['Travel_Time'].values[0]\n",
    "        SH7 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_223')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_223'] = SH7['Travel_Time'].values[0]\n",
    "\n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Western_routes':\n",
    "        W1 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_575')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_575'] = W1['Travel_Time'].values[0]\n",
    "        W2 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_590')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_590'] = W2['Travel_Time'].values[0]\n",
    "        W3 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_633') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_634')]\n",
    "        travel_time_matrix.at['Stop_633', 'Stop_634'] = W3['Travel_Time'].values[0]\n",
    "        W4 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_581') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_587')]\n",
    "        travel_time_matrix.at['Stop_581', 'Stop_587'] = W4['Travel_Time'].values[0]\n",
    "        W5 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_642')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_642'] = W5['Travel_Time'].values[0]\n",
    "        W6 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_689')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_689'] = W6['Travel_Time'].values[0]\n",
    "        W7 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_727')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_727'] = W7['Travel_Time'].values[0]\n",
    "        W8 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_158')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_158'] = W8['Travel_Time'].values[0]\n",
    "        W9 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_144') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_167')]\n",
    "        travel_time_matrix.at['Stop_144', 'Stop_167'] = W9['Travel_Time'].values[0]\n",
    "        W10 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_384') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_232')]\n",
    "        travel_time_matrix.at['Stop_384', 'Stop_232'] = W10['Travel_Time'].values[0]\n",
    "        W11 = New_Distinct_Edges_Malta_IncTravelTimes_Morning[(New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop From'] == 'Stop_581') & (New_Distinct_Edges_Malta_IncTravelTimes_Morning['Stop To'] == 'Stop_167')]\n",
    "        travel_time_matrix.at['Stop_581', 'Stop_167'] = W11['Travel_Time'].values[0]\n",
    "        \n",
    "        \n",
    "    print(f\"Matrix for {route_name} populated successfully.\")\n",
    "    \n",
    "    # Replace infinite values with the string 'Inf'\n",
    "    travel_time_matrix.replace({np.inf: 'Inf'}, inplace=True)\n",
    "    \n",
    "    # Save to txt file in append mode\n",
    "    file_name = f\"{route_name}TravelTimes.txt\"\n",
    "    travel_time_matrix.to_csv(file_name, sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eae95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate Distance Matrix (In KM using Haversine distance)\n",
    "\n",
    "# Earth's radius in kilometers\n",
    "R = 6371\n",
    "\n",
    "# Function to compute Haversine distance\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])  # Convert to radians\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c  # Distance in kilometers\n",
    "\n",
    "# Extract unique Bus_Stop_IDs\n",
    "bus_stops = Morning_Dataset_Sorted_Malta['Bus_Stop_ID'].unique()\n",
    "\n",
    "# Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "distance_matrix_malta = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert latitude and longitude to NumPy arrays for fast lookup\n",
    "latitudes = Morning_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['Latitude_Final']\n",
    "longitudes = Morning_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['Longitude_Final']\n",
    "\n",
    "# Compute the Haversine distance for each pair\n",
    "for i in bus_stops:\n",
    "    print(i)\n",
    "    for j in bus_stops:\n",
    "        distance_matrix_malta.at[i, j] = haversine(latitudes[i], longitudes[i], latitudes[j], longitudes[j])\n",
    "\n",
    "# Convert to numeric\n",
    "distance_matrix_malta = distance_matrix_malta.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc4ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta = -0.5\n",
    "bus_stops = Morning_Dataset_Sorted_Malta['Bus_Stop_ID'].unique()  # Get unique bus stops\n",
    "\n",
    "# Initialize DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "nij_df = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert distance_matrix to NumPy array for speed\n",
    "distance_matrix_np = distance_matrix_malta.loc[bus_stops, bus_stops].to_numpy()\n",
    "\n",
    "# Replace 0 distances with np.inf (to avoid division errors)\n",
    "distance_matrix_np[distance_matrix_np == 0] = np.inf\n",
    "\n",
    "# Precompute d_ij^beta\n",
    "d_matrix_beta = distance_matrix_np ** beta  # Apply power directly\n",
    "\n",
    "# Extract relevant columns as NumPy arrays for fast access\n",
    "pop_leaving = Morning_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['POP_Leaving_Per_Stop'].to_dict()\n",
    "pop_coming = Morning_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['POP_COMING'].to_dict()\n",
    "\n",
    "for i_idx, i in enumerate(bus_stops):  # Loop through focus stops\n",
    "    print(i)\n",
    "    gi = pop_leaving[i]  # Get g_i\n",
    "\n",
    "    # Compute denominator in vectorized form\n",
    "    a2 = np.array([pop_coming[m] for m in bus_stops])\n",
    "    sum_denominator = np.sum(a2 * d_matrix_beta[i_idx, :])  # Vectorized sum\n",
    "\n",
    "    # Compute nij values\n",
    "    a = np.array([pop_coming[j] for j in bus_stops])\n",
    "    d = d_matrix_beta[i_idx, :]  # Get row i from precomputed d^beta\n",
    "    nij_df.iloc[i_idx, :] = (gi * a * d) / sum_denominator  # Vectorized division\n",
    "\n",
    "# Convert to numeric type for calculations\n",
    "nij_df_malta = nij_df.apply(pd.to_numeric)\n",
    "\n",
    "nij_df_Malta_ROUNDED = nij_df_malta.round(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume Monday_Routes_Malta_List is defined as a list of tuples: (route_name, dataframe)\n",
    "for route_name, df in Monday_Routes_Malta_List:\n",
    "    # 1 - Obtain list of unique stops for this route\n",
    "    unique_stops = df.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "    unique_stops_sorted = unique_stops.sort_values(\n",
    "        by='Bus_Stop_ID',\n",
    "        key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int)\n",
    "    )\n",
    "    # Create Bus Stops list\n",
    "    bus_stops_list = unique_stops_sorted['Bus_Stop_ID'].unique()\n",
    "    nij_df_Malta_ROUNDED_df = nij_df_Malta_ROUNDED.loc[bus_stops_list, bus_stops_list]\n",
    "    \n",
    "    # Save to txt file in append mode\n",
    "    file_name = f\"{route_name}Demand.txt\"\n",
    "    nij_df_Malta_ROUNDED_df.to_csv(file_name, sep='\\t', index=False, header=False)\n",
    "    \n",
    "    print(f\"Demand Matrix for {route_name} Saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624e2156-65f7-41e1-8bec-bddbd8d40c3e",
   "metadata": {},
   "source": [
    "#### Step 7.2.2 - Obtaining Text Files for Gozo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d70ee2-ad67-4dbd-9eda-36beb1431016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Coords text file\n",
    "\n",
    "# 1 - Obtain List of Unique Stops in Malta\n",
    "Unique_Stops_Monday_Routes_Gozo = Monday_Routes_Gozo.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "# 2 - Sort Stops in Descending Order\n",
    "Unique_Stops_Monday_Routes_Gozo_Sorted = Unique_Stops_Monday_Routes_Gozo.sort_values(by='Bus_Stop_ID', key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int))\n",
    "# 3 - Limit 'Latitude_Final' and 'Longitude_Final' columns to 7 Decimal Places\n",
    "Unique_Stops_Monday_Routes_Gozo_Sorted[['Latitude_Final', 'Longitude_Final']] = Unique_Stops_Monday_Routes_Gozo_Sorted[['Latitude_Final', 'Longitude_Final']].round(7)\n",
    "\n",
    "# 4 - Obtain 'GozoCoords.txt' file\n",
    "File_Name = 'GozoCoords.txt'\n",
    "Columns_Required = ['Latitude_Final', 'Longitude_Final']\n",
    "Number_of_Rows = len(Unique_Stops_Monday_Routes_Gozo_Sorted)\n",
    "\n",
    "with open(File_Name, 'w') as File:\n",
    "    # Write row count at top of csv file\n",
    "    File.write(f\"{Number_of_Rows}\\n\")\n",
    "    Unique_Stops_Monday_Routes_Gozo_Sorted[Columns_Required].to_csv(File, sep=' ', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521a4ee-ddcc-43b3-ad41-c2501a39313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Travel Time Matrix\n",
    "\n",
    "Bus_Stops_List = Unique_Stops_Monday_Routes_Gozo_Sorted['Bus_Stop_ID'].unique()\n",
    "\n",
    "# Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo = pd.DataFrame(index=Bus_Stops_List, columns=Bus_Stops_List)\n",
    "\n",
    "# Set 'Bus_Stop_ID' and 'Next_Bus_Stop_ID' as index for faster lookup\n",
    "Gozo_DistinctEdges_IncTravelTimes_Copy =  Gozo_DistinctEdges_IncTravelTimes_Morning_Min.copy()\n",
    "Gozo_DistinctEdges_IncTravelTimes_Copy.set_index(['Bus_Stop_ID', 'Next_Bus_Stop_ID'], inplace=True)\n",
    "\n",
    "# Initialize the matrix with np.inf (as a default)\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo[:] = np.inf\n",
    "\n",
    "# Set diagonal entries to zero\n",
    "np.fill_diagonal(Travel_Time_Matrix_Monday_Routes_Gozo.values, 0)\n",
    "\n",
    "# Loop through each pair of bus stops in the list\n",
    "for index, row in Monday_Routes_Gozo.iterrows():\n",
    "    bus_stop_pair = row['Bus_Stop_Next_Bus_Stop']\n",
    "    if pd.notna(bus_stop_pair):  # Ensure the value is not NaN\n",
    "        # Convert to string and split\n",
    "        stop_0, stop_1 = str(bus_stop_pair).split('_to_')\n",
    "        if stop_0 == stop_1:\n",
    "            Travel_Time_Matrix_Monday_Routes_Gozo[stop_0, stop_1] = 0\n",
    "        elif (stop_0, stop_1) in Gozo_DistinctEdges_IncTravelTimes_Copy.index:\n",
    "            Travel_Time_Matrix_Monday_Routes_Gozo.at[stop_0, stop_1] = Gozo_DistinctEdges_IncTravelTimes_Copy.at[(stop_0, stop_1), 'Travel_Time']\n",
    "\n",
    "            \n",
    "G1 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1159') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1138')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1159', 'Stop_1138'] = G1['Travel_Time'].values[0]            \n",
    "G2 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1161') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1160')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1161', 'Stop_1160'] = G2['Travel_Time'].values[0]            \n",
    "G3 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1159') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1185')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1159', 'Stop_1185'] = G3['Travel_Time'].values[0]            \n",
    "G4 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1161') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1220')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1161', 'Stop_1220'] = G4['Travel_Time'].values[0]            \n",
    "G5 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1275') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1185')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1275', 'Stop_1185'] = G5['Travel_Time'].values[0]            \n",
    "G6 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1275') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1160')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1275', 'Stop_1160'] = G6['Travel_Time'].values[0]            \n",
    "G7 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1302') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1160')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1302', 'Stop_1160'] = G7['Travel_Time'].values[0]            \n",
    "G8 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1275') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1138')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1275', 'Stop_1138'] = G8['Travel_Time'].values[0]            \n",
    "G9 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1341') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1329')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1341', 'Stop_1329'] = G9['Travel_Time'].values[0]            \n",
    "G10 = New_Distinct_Edges_Gozo_IncTravelTimes_Morning[(New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop From'] == 'Stop_1161') & (New_Distinct_Edges_Gozo_IncTravelTimes_Morning['Stop To'] == 'Stop_1329')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1161', 'Stop_1329'] = G10['Travel_Time'].values[0]                        \n",
    "            \n",
    "            \n",
    "print(f\"Matrix for Gozo populated successfully.\")\n",
    "\n",
    "# Replace infinite values with the string 'Inf'\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.replace({np.inf: 'Inf'}, inplace=True)\n",
    "\n",
    "# Save to txt file in append mode\n",
    "File_Name = 'GozoTravelTimes.txt'\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.to_csv(File_Name, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57de1b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate Distance Matrix (In KM using Haversine distance)\n",
    "\n",
    "# Earth's radius in kilometers\n",
    "R = 6371\n",
    "\n",
    "# Function to compute Haversine distance\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])  # Convert to radians\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c  # Distance in kilometers\n",
    "\n",
    "# Extract unique Bus_Stop_IDs\n",
    "bus_stops = Morning_Dataset_Sorted_Gozo['Bus_Stop_ID'].unique()\n",
    "\n",
    "# Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "distance_matrix_gozo = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert latitude and longitude to NumPy arrays for fast lookup\n",
    "latitudes = Morning_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['Latitude_Final']\n",
    "longitudes = Morning_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['Longitude_Final']\n",
    "\n",
    "# Compute the Haversine distance for each pair\n",
    "for i in bus_stops:\n",
    "    print(i)\n",
    "    for j in bus_stops:\n",
    "        distance_matrix_gozo.at[i, j] = haversine(latitudes[i], longitudes[i], latitudes[j], longitudes[j])\n",
    "\n",
    "# Convert to numeric\n",
    "distance_matrix_gozo = distance_matrix_gozo.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c914d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "beta = -0.5\n",
    "bus_stops = Morning_Dataset_Sorted_Gozo['Bus_Stop_ID'].unique()  # Get unique bus stops\n",
    "\n",
    "# Initialize DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "nij_df = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert distance_matrix to NumPy array for speed\n",
    "distance_matrix_np = distance_matrix_gozo.loc[bus_stops, bus_stops].to_numpy()\n",
    "\n",
    "# Replace 0 distances with np.inf (to avoid division errors)\n",
    "distance_matrix_np[distance_matrix_np == 0] = np.inf\n",
    "\n",
    "# Precompute d_ij^beta\n",
    "d_matrix_beta = distance_matrix_np ** beta  # Apply power directly\n",
    "\n",
    "# Extract relevant columns as NumPy arrays for fast access\n",
    "pop_leaving = Morning_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['POP_Leaving_Per_Stop'].to_dict()\n",
    "pop_coming = Morning_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['POP_COMING'].to_dict()\n",
    "\n",
    "for i_idx, i in enumerate(bus_stops):  # Loop through focus stops\n",
    "    print(i)\n",
    "    gi = pop_leaving[i]  # Get g_i\n",
    "\n",
    "    # Compute denominator in vectorized form\n",
    "    a2 = np.array([pop_coming[m] for m in bus_stops])\n",
    "    sum_denominator = np.sum(a2 * d_matrix_beta[i_idx, :])  # Vectorized sum\n",
    "\n",
    "    # Compute nij values\n",
    "    a = np.array([pop_coming[j] for j in bus_stops])\n",
    "    d = d_matrix_beta[i_idx, :]  # Get row i from precomputed d^beta\n",
    "    nij_df.iloc[i_idx, :] = (gi * a * d) / sum_denominator  # Vectorized division\n",
    "\n",
    "# Convert to numeric type for calculations\n",
    "nij_df_gozo = nij_df.apply(pd.to_numeric)\n",
    "\n",
    "nij_df_Gozo_ROUNDED = nij_df_gozo.round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdfebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save txt file\n",
    "File_Name = 'GozoDemand.txt'\n",
    "nij_df_Gozo_ROUNDED.to_csv(File_Name, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba2b5c-718a-4ff1-9596-d103b8d06970",
   "metadata": {},
   "source": [
    "### Step 7.3 - Evening Model (4PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1c004",
   "metadata": {},
   "source": [
    "#### Step 7.3.1 - Obtaining Text Files for Malta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b9d2f-beb5-47d8-b7ec-db4a14ec963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Coords text file\n",
    "for name, df in Monday_Routes_Malta_List:\n",
    "    # 1 - Obtain List of Unique Stops in Malta\n",
    "    unique_stops = df.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "    # 2 - Sort Stops in Descending Order\n",
    "    unique_stops_sorted  = unique_stops.sort_values(by='Bus_Stop_ID', key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int))\n",
    "    # 3 - Limit 'Latitude_Final' and 'Longitude_Final' columns to 7 Decimal Places\n",
    "    unique_stops_sorted[['Latitude_Final', 'Longitude_Final']] = unique_stops_sorted[['Latitude_Final', 'Longitude_Final']].round(7)\n",
    "    # 4 - Obtain 'MaltaCoords.txt' file\n",
    "    File_Name = f\"{name}Coords.txt\"\n",
    "    Columns_Required = ['Latitude_Final', 'Longitude_Final']\n",
    "    Number_of_Rows = len(unique_stops_sorted)\n",
    "    \n",
    "    with open(File_Name, 'w') as File:\n",
    "        # Write row count at top of csv file\n",
    "        File.write(f\"{Number_of_Rows}\\n\")\n",
    "        unique_stops_sorted[Columns_Required].to_csv(File, sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "531097b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix for South_eastern_routes populated successfully.\n",
      "Matrix for Northern_harbour_routes populated successfully.\n",
      "Matrix for Southern_harbour_routes populated successfully.\n",
      "Matrix for Western_routes populated successfully.\n",
      "Matrix for Northern_routes populated successfully.\n",
      "Matrix for Mater_dei_north_routes populated successfully.\n",
      "Matrix for Mater_dei_south_routes populated successfully.\n",
      "Matrix for Airport_routes populated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Obtain Travel Time Text File\n",
    "for route_name, df in Monday_Routes_Malta_List:\n",
    "    # 1 - Obtain list of unique stops for this route\n",
    "    unique_stops = df.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "    unique_stops_sorted = unique_stops.sort_values(\n",
    "        by='Bus_Stop_ID',\n",
    "        key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int)\n",
    "    )\n",
    "    \n",
    "    # Create Bus Stops list\n",
    "    bus_stops_list = unique_stops_sorted['Bus_Stop_ID'].unique()\n",
    "    # Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "    travel_time_matrix = pd.DataFrame(index=bus_stops_list, columns=bus_stops_list)\n",
    "    \n",
    "    # Set index for faster lookup in malta_edges\n",
    "    malta_edges = Malta_DistinctEdges_IncTravelTimes_Evening_Min.copy()\n",
    "    malta_edges.set_index(['Bus_Stop_ID', 'Next_Bus_Stop_ID'], inplace=True)\n",
    "    \n",
    "    # Initialize the matrix with np.inf (as a default)\n",
    "    travel_time_matrix[:] = np.inf\n",
    "\n",
    "    # Set diagonal entries to zero\n",
    "    np.fill_diagonal(travel_time_matrix.values, 0)\n",
    "\n",
    "    # Loop through each bus_stop combination specified in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        bus_stop_pair = row['Bus_Stop_Next_Bus_Stop']\n",
    "        if pd.notna(bus_stop_pair):  # Ensure the value is not NaN\n",
    "            # Convert to string and split\n",
    "            stop_0, stop_1 = str(bus_stop_pair).split('_to_')\n",
    "        \n",
    "            if stop_0 == stop_1:\n",
    "                travel_time_matrix.at[stop_0, stop_1] = 0\n",
    "            elif (stop_0, stop_1) in malta_edges.index:\n",
    "                travel_time_matrix.at[stop_0, stop_1] = malta_edges.at[(stop_0, stop_1), 'Travel_Time']\n",
    "\n",
    "    \n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Airport_routes':\n",
    "        AR1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_23') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_24')]\n",
    "        travel_time_AR1 = AR1['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_23', 'Stop_24'] = travel_time_AR1[0]\n",
    "        AR2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_0') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_29')]\n",
    "        travel_time_AR2 = AR2['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_0', 'Stop_29'] = travel_time_AR2[0]\n",
    "        AR3 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_29') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_34')]\n",
    "        travel_time_AR3 = AR3['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_29', 'Stop_34'] = travel_time_AR3[0]   \n",
    "        AR4 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_29') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_0')]\n",
    "        travel_time_AR4 = AR4['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_29', 'Stop_0'] = travel_time_AR4[0]\n",
    "        AR5 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_144') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_167')]\n",
    "        travel_time_AR5 = AR5['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_144', 'Stop_167'] = travel_time_AR5[0]\n",
    "        AR6 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_9') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_112')]\n",
    "        travel_time_AR6 = AR6['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_9', 'Stop_112'] = travel_time_AR6[0]\n",
    "        AR7 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_82') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_83')]\n",
    "        travel_time_AR7 = AR7['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_82', 'Stop_83'] = travel_time_AR7[0]\n",
    "        AR8 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_158')]\n",
    "        travel_time_AR8 = AR8['Travel_Time'].values \n",
    "        travel_time_matrix.at['Stop_157', 'Stop_158'] = travel_time_AR8[0]\n",
    "\n",
    "    if route_name == 'Mater_dei_north_routes':\n",
    "        MDN1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_7') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_8')]\n",
    "        travel_time_MDN1 = MDN1['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_7', 'Stop_8'] = travel_time_MDN1  # Ensure the indices are correct as per your matrix setup\n",
    "        MDN2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_456')]\n",
    "        travel_time_MDN2 = MDN2['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_456'] = travel_time_MDN2  # Ensure the indices are correct as per your matrix setup\n",
    "\n",
    "    if route_name == 'Mater_dei_south_routes':\n",
    "        MDS1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_7') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_27')]\n",
    "        travel_time_MDS1 = MDS1['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_7', 'Stop_27'] = travel_time_MDS1\n",
    "        MDS2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_223')]\n",
    "        travel_time_MDS2 = MDS2['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_223'] = travel_time_MDS2\n",
    "        MDS3 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_82') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_83')]\n",
    "        travel_time_MDS3 = MDS3['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_82', 'Stop_83'] = travel_time_MDS3\n",
    "        MDS4 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_7') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_8')]\n",
    "        travel_time_MDS4 = MDS4['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_7', 'Stop_8'] = travel_time_MDS4\n",
    "\n",
    "    if route_name == 'Northern_harbour_routes':\n",
    "        NH1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_347')]\n",
    "        travel_time_NH1 = NH1['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_347'] = travel_time_NH1\n",
    "        NH2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_349') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_329')]\n",
    "        travel_time_NH2 = NH2['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_349', 'Stop_329'] = travel_time_NH2\n",
    "        NH3 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_355')]\n",
    "        travel_time_NH3 = NH3['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_355'] = travel_time_NH3\n",
    "        NH4 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_232') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_233')]\n",
    "        travel_time_NH4 = NH4['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_232', 'Stop_233'] = travel_time_NH4\n",
    "        NH5 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_171')]\n",
    "        travel_time_NH5 = NH5['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_171'] = travel_time_NH5\n",
    "        NH6 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_412')]\n",
    "        travel_time_NH6 = NH6['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_412'] = travel_time_NH6\n",
    "        NH7 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_575')]\n",
    "        travel_time_NH7 = NH7['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_575'] = travel_time_NH7\n",
    "        NH8 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_752')]\n",
    "        travel_time_NH8 = NH8['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_752'] = travel_time_NH8\n",
    "        NH9 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_244') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_232')]\n",
    "        travel_time_NH9 = NH9['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_244', 'Stop_232'] = travel_time_NH9\n",
    "        NH10 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_114') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_112')]\n",
    "        travel_time_NH10 = NH10['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_114', 'Stop_112'] = travel_time_NH10\n",
    "        NH11 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_327')]\n",
    "        travel_time_NH11 = NH11['Travel_Time'].values[0]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_327'] = travel_time_NH11\n",
    "        \n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Northern_routes':\n",
    "        N1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_327')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_327'] = N1['Travel_Time'].values[0]\n",
    "        N2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_456')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_456'] = N2['Travel_Time'].values[0]\n",
    "        N3 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_424')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_424'] = N3['Travel_Time'].values[0]\n",
    "        N4 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_23') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_24')]\n",
    "        travel_time_matrix.at['Stop_23', 'Stop_24'] = N4['Travel_Time'].values[0]\n",
    "        N5 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_471')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_471'] = N5['Travel_Time'].values[0]\n",
    "        N6 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_506')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_506'] = N6['Travel_Time'].values[0]\n",
    "        N7 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_509')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_509'] = N7['Travel_Time'].values[0]\n",
    "        N8 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_528') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_525')]\n",
    "        travel_time_matrix.at['Stop_528', 'Stop_525'] = N8['Travel_Time'].values[0]\n",
    "        N9 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_540')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_540'] = N9['Travel_Time'].values[0]\n",
    "        N10 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_349') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_329')]\n",
    "        travel_time_matrix.at['Stop_349', 'Stop_329'] = N10['Travel_Time'].values[0]\n",
    "        N11 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_195')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_195'] = N11['Travel_Time'].values[0]\n",
    "        N12 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_232') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_384')]\n",
    "        travel_time_matrix.at['Stop_232', 'Stop_384'] = N12['Travel_Time'].values[0]\n",
    "        N13 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_244') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_232')]\n",
    "        travel_time_matrix.at['Stop_244', 'Stop_232'] = N13['Travel_Time'].values[0]\n",
    "        N14 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_1120')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_1120'] = N14['Travel_Time'].values[0]\n",
    "        N15 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_1122')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_1122'] = N15['Travel_Time'].values[0]\n",
    "\n",
    "\n",
    "    # Adding Required Connections\n",
    "    if route_name == 'South_eastern_routes':\n",
    "        SE1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_772')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_772'] = SE1['Travel_Time'].values[0]\n",
    "        SE2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_805')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_805'] = SE2['Travel_Time'].values[0]\n",
    "        SE3 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_44') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_43')]\n",
    "        travel_time_matrix.at['Stop_44', 'Stop_43'] = SE3['Travel_Time'].values[0]\n",
    "        SE4 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_853')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_853'] = SE4['Travel_Time'].values[0]\n",
    "        SE5 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_878')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_878'] = SE5['Travel_Time'].values[0]\n",
    "        SE6 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_927') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_928')]\n",
    "        travel_time_matrix.at['Stop_927', 'Stop_928'] = SE6['Travel_Time'].values[0]\n",
    "        SE7 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_895')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_895'] = SE7['Travel_Time'].values[0]\n",
    "        SE8 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_245')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_245'] = SE8['Travel_Time'].values[0]\n",
    "        SE9 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_933')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_933'] = SE9['Travel_Time'].values[0]\n",
    "        SE10 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_171')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_171'] = SE10['Travel_Time'].values[0]\n",
    "        SE11 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_57') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_190')]\n",
    "        travel_time_matrix.at['Stop_57', 'Stop_190'] = SE11['Travel_Time'].values[0]\n",
    "        SE12 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_914')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_914'] = SE12['Travel_Time'].values[0]\n",
    "\n",
    "        \n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Southern_harbour_routes':\n",
    "        SH1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_280')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_280'] = SH1['Travel_Time'].values[0]\n",
    "        SH2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_319')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_319'] = SH2['Travel_Time'].values[0]\n",
    "        SH3 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_895')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_895'] = SH3['Travel_Time'].values[0]\n",
    "        SH4 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_932')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_932'] = SH4['Travel_Time'].values[0]\n",
    "        SH5 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_349') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_329')]\n",
    "        travel_time_matrix.at['Stop_349', 'Stop_329'] = SH5['Travel_Time'].values[0]\n",
    "        SH6 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_271') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_949')]\n",
    "        travel_time_matrix.at['Stop_271', 'Stop_949'] = SH6['Travel_Time'].values[0]\n",
    "        SH7 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_223')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_223'] = SH7['Travel_Time'].values[0]\n",
    "\n",
    "    # Adding Required Connections\n",
    "    if route_name == 'Western_routes':\n",
    "        W1 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_575')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_575'] = W1['Travel_Time'].values[0]\n",
    "        W2 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_590')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_590'] = W2['Travel_Time'].values[0]\n",
    "        W3 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_633') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_634')]\n",
    "        travel_time_matrix.at['Stop_633', 'Stop_634'] = W3['Travel_Time'].values[0]\n",
    "        W4 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_581') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_587')]\n",
    "        travel_time_matrix.at['Stop_581', 'Stop_587'] = W4['Travel_Time'].values[0]\n",
    "        W5 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_642')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_642'] = W5['Travel_Time'].values[0]\n",
    "        W6 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_689')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_689'] = W6['Travel_Time'].values[0]\n",
    "        W7 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_190') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_727')]\n",
    "        travel_time_matrix.at['Stop_190', 'Stop_727'] = W7['Travel_Time'].values[0]\n",
    "        W8 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_157') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_158')]\n",
    "        travel_time_matrix.at['Stop_157', 'Stop_158'] = W8['Travel_Time'].values[0]\n",
    "        W9 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_144') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_167')]\n",
    "        travel_time_matrix.at['Stop_144', 'Stop_167'] = W9['Travel_Time'].values[0]\n",
    "        W10 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_384') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_232')]\n",
    "        travel_time_matrix.at['Stop_384', 'Stop_232'] = W10['Travel_Time'].values[0]\n",
    "        W11 = New_Distinct_Edges_Malta_IncTravelTimes_Evening[(New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop From'] == 'Stop_581') & (New_Distinct_Edges_Malta_IncTravelTimes_Evening['Stop To'] == 'Stop_167')]\n",
    "        travel_time_matrix.at['Stop_581', 'Stop_167'] = W11['Travel_Time'].values[0]\n",
    "        \n",
    "        \n",
    "    print(f\"Matrix for {route_name} populated successfully.\")\n",
    "    \n",
    "    # Replace infinite values with the string 'Inf'\n",
    "    travel_time_matrix.replace({np.inf: 'Inf'}, inplace=True)\n",
    "    \n",
    "    # Save to txt file in append mode\n",
    "    file_name = f\"{route_name}TravelTimes.txt\"\n",
    "    travel_time_matrix.to_csv(file_name, sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d047340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Distance Matrix (In KM using Haversine distance)\n",
    "\n",
    "# Earth's radius in kilometers\n",
    "R = 6371\n",
    "\n",
    "# Function to compute Haversine distance\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])  # Convert to radians\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c  # Distance in kilometers\n",
    "\n",
    "# Extract unique Bus_Stop_IDs\n",
    "bus_stops = Evening_Dataset_Sorted_Malta['Bus_Stop_ID'].unique()\n",
    "\n",
    "# Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "distance_matrix_malta = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert latitude and longitude to NumPy arrays for fast lookup\n",
    "latitudes = Evening_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['Latitude_Final']\n",
    "longitudes = Evening_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['Longitude_Final']\n",
    "\n",
    "# Compute the Haversine distance for each pair\n",
    "for i in bus_stops:\n",
    "    print(i)\n",
    "    for j in bus_stops:\n",
    "        distance_matrix_malta.at[i, j] = haversine(latitudes[i], longitudes[i], latitudes[j], longitudes[j])\n",
    "\n",
    "# Convert to numeric\n",
    "distance_matrix_malta = distance_matrix_malta.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72152687",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = -0.5\n",
    "bus_stops = Evening_Dataset_Sorted_Malta['Bus_Stop_ID'].unique()  # Get unique bus stops\n",
    "\n",
    "# Initialize DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "nij_df = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert distance_matrix to NumPy array for speed\n",
    "distance_matrix_np = distance_matrix_malta.loc[bus_stops, bus_stops].to_numpy()\n",
    "\n",
    "# Replace 0 distances with np.inf (to avoid division errors)\n",
    "distance_matrix_np[distance_matrix_np == 0] = np.inf\n",
    "\n",
    "# Precompute d_ij^beta\n",
    "d_matrix_beta = distance_matrix_np ** beta  # Apply power directly\n",
    "\n",
    "# Extract relevant columns as NumPy arrays for fast access\n",
    "pop_leaving = Evening_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['POP_Leaving_Per_Stop'].to_dict()\n",
    "pop_coming = Evening_Dataset_Sorted_Malta.set_index('Bus_Stop_ID')['POP_COMING'].to_dict()\n",
    "\n",
    "for i_idx, i in enumerate(bus_stops):  # Loop through focus stops\n",
    "    print(i)\n",
    "    gi = pop_leaving[i]  # Get g_i\n",
    "\n",
    "    # Compute denominator in vectorized form\n",
    "    a2 = np.array([pop_coming[m] for m in bus_stops])\n",
    "    sum_denominator = np.sum(a2 * d_matrix_beta[i_idx, :])  # Vectorized sum\n",
    "\n",
    "    # Compute nij values\n",
    "    a = np.array([pop_coming[j] for j in bus_stops])\n",
    "    d = d_matrix_beta[i_idx, :]  # Get row i from precomputed d^beta\n",
    "    nij_df.iloc[i_idx, :] = (gi * a * d) / sum_denominator  # Vectorized division\n",
    "\n",
    "# Convert to numeric type for calculations\n",
    "nij_df_malta = nij_df.apply(pd.to_numeric)\n",
    "\n",
    "nij_df_Malta_ROUNDED = nij_df_malta.round(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume Monday_Routes_Malta_List is defined as a list of tuples: (route_name, dataframe)\n",
    "for route_name, df in Monday_Routes_Malta_List:\n",
    "    # 1 - Obtain list of unique stops for this route\n",
    "    unique_stops = df.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "    unique_stops_sorted = unique_stops.sort_values(\n",
    "        by='Bus_Stop_ID',\n",
    "        key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int)\n",
    "    )\n",
    "    # Create Bus Stops list\n",
    "    bus_stops_list = unique_stops_sorted['Bus_Stop_ID'].unique()\n",
    "    nij_df_Malta_ROUNDED_df = nij_df_Malta_ROUNDED.loc[bus_stops_list, bus_stops_list]\n",
    "    \n",
    "    # Save to txt file in append mode\n",
    "    file_name = f\"{route_name}Demand.txt\"\n",
    "    nij_df_Malta_ROUNDED_df.to_csv(file_name, sep='\\t', index=False, header=False)\n",
    "    \n",
    "    print(f\"Demand Matrix for {route_name} Saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72b4b2",
   "metadata": {},
   "source": [
    "#### Step 7.3.2 - Obtaining Text Files for Gozo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Coords text file\n",
    "\n",
    "# 1 - Obtain List of Unique Stops in Malta\n",
    "Unique_Stops_Monday_Routes_Gozo = Monday_Routes_Gozo.drop_duplicates(subset=['Bus_Stop_ID'], keep='first')\n",
    "# 2 - Sort Stops in Descending Order\n",
    "Unique_Stops_Monday_Routes_Gozo_Sorted = Unique_Stops_Monday_Routes_Gozo.sort_values(by='Bus_Stop_ID', key=lambda x: x.str.extract(r'(\\d+)')[0].astype(int))\n",
    "# 3 - Limit 'Latitude_Final' and 'Longitude_Final' columns to 7 Decimal Places\n",
    "Unique_Stops_Monday_Routes_Gozo_Sorted[['Latitude_Final', 'Longitude_Final']] = Unique_Stops_Monday_Routes_Gozo_Sorted[['Latitude_Final', 'Longitude_Final']].round(7)\n",
    "\n",
    "# 4 - Obtain 'GozoCoords.txt' file\n",
    "File_Name = 'GozoCoords.txt'\n",
    "Columns_Required = ['Latitude_Final', 'Longitude_Final']\n",
    "Number_of_Rows = len(Unique_Stops_Monday_Routes_Gozo_Sorted)\n",
    "\n",
    "with open(File_Name, 'w') as File:\n",
    "    # Write row count at top of csv file\n",
    "    File.write(f\"{Number_of_Rows}\\n\")\n",
    "    Unique_Stops_Monday_Routes_Gozo_Sorted[Columns_Required].to_csv(File, sep=' ', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4278cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Travel Time Matrix\n",
    "\n",
    "Bus_Stops_List = Unique_Stops_Monday_Routes_Gozo_Sorted['Bus_Stop_ID'].unique()\n",
    "\n",
    "# Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo = pd.DataFrame(index=Bus_Stops_List, columns=Bus_Stops_List)\n",
    "\n",
    "# Set 'Bus_Stop_ID' and 'Next_Bus_Stop_ID' as index for faster lookup\n",
    "Gozo_DistinctEdges_IncTravelTimes_Copy =  Gozo_DistinctEdges_IncTravelTimes_Evening_Min.copy()\n",
    "Gozo_DistinctEdges_IncTravelTimes_Copy.set_index(['Bus_Stop_ID', 'Next_Bus_Stop_ID'], inplace=True)\n",
    "\n",
    "# Initialize the matrix with np.inf (as a default)\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo[:] = np.inf\n",
    "\n",
    "# Set diagonal entries to zero\n",
    "np.fill_diagonal(Travel_Time_Matrix_Monday_Routes_Gozo.values, 0)\n",
    "\n",
    "# Loop through each pair of bus stops in the list\n",
    "for index, row in Monday_Routes_Gozo.iterrows():\n",
    "    bus_stop_pair = row['Bus_Stop_Next_Bus_Stop']\n",
    "    if pd.notna(bus_stop_pair):  # Ensure the value is not NaN\n",
    "        # Convert to string and split\n",
    "        stop_0, stop_1 = str(bus_stop_pair).split('_to_')\n",
    "        if stop_0 == stop_1:\n",
    "            Travel_Time_Matrix_Monday_Routes_Gozo[stop_0, stop_1] = 0\n",
    "        elif (stop_0, stop_1) in Gozo_DistinctEdges_IncTravelTimes_Copy.index:\n",
    "            Travel_Time_Matrix_Monday_Routes_Gozo.at[stop_0, stop_1] = Gozo_DistinctEdges_IncTravelTimes_Copy.at[(stop_0, stop_1), 'Travel_Time']\n",
    "\n",
    "            \n",
    "G1 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1159') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1138')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1159', 'Stop_1138'] = G1['Travel_Time'].values[0]            \n",
    "G2 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1161') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1160')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1161', 'Stop_1160'] = G2['Travel_Time'].values[0]            \n",
    "G3 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1159') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1185')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1159', 'Stop_1185'] = G3['Travel_Time'].values[0]            \n",
    "G4 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1161') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1220')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1161', 'Stop_1220'] = G4['Travel_Time'].values[0]            \n",
    "G5 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1275') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1185')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1275', 'Stop_1185'] = G5['Travel_Time'].values[0]            \n",
    "G6 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1275') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1160')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1275', 'Stop_1160'] = G6['Travel_Time'].values[0]            \n",
    "G7 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1302') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1160')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1302', 'Stop_1160'] = G7['Travel_Time'].values[0]            \n",
    "G8 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1275') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1138')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1275', 'Stop_1138'] = G8['Travel_Time'].values[0]            \n",
    "G9 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1341') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1329')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1341', 'Stop_1329'] = G9['Travel_Time'].values[0]            \n",
    "G10 = New_Distinct_Edges_Gozo_IncTravelTimes_Evening[(New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop From'] == 'Stop_1161') & (New_Distinct_Edges_Gozo_IncTravelTimes_Evening['Stop To'] == 'Stop_1329')]\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.at['Stop_1161', 'Stop_1329'] = G10['Travel_Time'].values[0]                        \n",
    "            \n",
    "            \n",
    "print(f\"Matrix for Gozo populated successfully.\")\n",
    "\n",
    "# Replace infinite values with the string 'Inf'\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.replace({np.inf: 'Inf'}, inplace=True)\n",
    "\n",
    "# Save to txt file in append mode\n",
    "File_Name = 'GozoTravelTimes.txt'\n",
    "Travel_Time_Matrix_Monday_Routes_Gozo.to_csv(File_Name, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Distance Matrix (In KM using Haversine distance)\n",
    "\n",
    "# Earth's radius in kilometers\n",
    "R = 6371\n",
    "\n",
    "# Function to compute Haversine distance\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])  # Convert to radians\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c  # Distance in kilometers\n",
    "\n",
    "# Extract unique Bus_Stop_IDs\n",
    "bus_stops = Evening_Dataset_Sorted_Gozo['Bus_Stop_ID'].unique()\n",
    "\n",
    "# Create an empty DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "distance_matrix_gozo = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert latitude and longitude to NumPy arrays for fast lookup\n",
    "latitudes = Evening_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['Latitude_Final']\n",
    "longitudes = Evening_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['Longitude_Final']\n",
    "\n",
    "# Compute the Haversine distance for each pair\n",
    "for i in bus_stops:\n",
    "    print(i)\n",
    "    for j in bus_stops:\n",
    "        distance_matrix_gozo.at[i, j] = haversine(latitudes[i], longitudes[i], latitudes[j], longitudes[j])\n",
    "\n",
    "# Convert to numeric\n",
    "distance_matrix_gozo = distance_matrix_gozo.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "beta = -0.5\n",
    "bus_stops = Evening_Dataset_Sorted_Gozo['Bus_Stop_ID'].unique()  # Get unique bus stops\n",
    "\n",
    "# Initialize DataFrame with Bus_Stop_IDs as both rows and columns\n",
    "nij_df = pd.DataFrame(index=bus_stops, columns=bus_stops)\n",
    "\n",
    "# Convert distance_matrix to NumPy array for speed\n",
    "distance_matrix_np = distance_matrix_gozo.loc[bus_stops, bus_stops].to_numpy()\n",
    "\n",
    "# Replace 0 distances with np.inf (to avoid division errors)\n",
    "distance_matrix_np[distance_matrix_np == 0] = np.inf\n",
    "\n",
    "# Precompute d_ij^beta\n",
    "d_matrix_beta = distance_matrix_np ** beta  # Apply power directly\n",
    "\n",
    "# Extract relevant columns as NumPy arrays for fast access\n",
    "pop_leaving = Evening_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['POP_Leaving_Per_Stop'].to_dict()\n",
    "pop_coming = Evening_Dataset_Sorted_Gozo.set_index('Bus_Stop_ID')['POP_COMING'].to_dict()\n",
    "\n",
    "for i_idx, i in enumerate(bus_stops):  # Loop through focus stops\n",
    "    print(i)\n",
    "    gi = pop_leaving[i]  # Get g_i\n",
    "\n",
    "    # Compute denominator in vectorized form\n",
    "    a2 = np.array([pop_coming[m] for m in bus_stops])\n",
    "    sum_denominator = np.sum(a2 * d_matrix_beta[i_idx, :])  # Vectorized sum\n",
    "\n",
    "    # Compute nij values\n",
    "    a = np.array([pop_coming[j] for j in bus_stops])\n",
    "    d = d_matrix_beta[i_idx, :]  # Get row i from precomputed d^beta\n",
    "    nij_df.iloc[i_idx, :] = (gi * a * d) / sum_denominator  # Vectorized division\n",
    "\n",
    "# Convert to numeric type for calculations\n",
    "nij_df_gozo = nij_df.apply(pd.to_numeric)\n",
    "\n",
    "nij_df_Gozo_ROUNDED = nij_df_gozo.round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save txt file\n",
    "File_Name = 'GozoDemand.txt'\n",
    "nij_df_Gozo_ROUNDED.to_csv(File_Name, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc3fab",
   "metadata": {},
   "source": [
    "### Step 8 - Analysing Route, in Malta and Gozo, according to Route Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31a1c6",
   "metadata": {},
   "source": [
    "### Step 8.1 - Malta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa406b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Separate DataFrame for each specifiv Route Set\n",
    "Monday_Routes_Malta_South_Eastern_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(South_Eastern_Routes)]\n",
    "Monday_Routes_Malta_Northern_Harbour_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Northern_Harbour_Routes)]\n",
    "Monday_Routes_Malta_Southern_Harbour_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Southern_Harbour_Routes)]\n",
    "Monday_Routes_Malta_Western_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Western_Routes)]\n",
    "Monday_Routes_Malta_Northern_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Northern_Routes)]\n",
    "Monday_Routes_Malta_Mater_Dei_North_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Mater_Dei_North_Routes)]\n",
    "Monday_Routes_Malta_Mater_Dei_South_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Mater_Dei_South_Routes)]\n",
    "Monday_Routes_Malta_Mater_Dei_Airport_Routes = Monday_Routes_Malta[Monday_Routes_Malta['Route Number'].isin(Airport_Routes)]\n",
    "\n",
    "\n",
    "# Create a List of TUples: (name, dataframe)\n",
    "Monday_Routes_Malta_List = [\n",
    "    ('South_Eastern_Routes', Monday_Routes_Malta_South_Eastern_Routes),\n",
    "    ('Northern_Harbour_Routes', Monday_Routes_Malta_Northern_Harbour_Routes),\n",
    "    ('Southern_Harbour_Routes', Monday_Routes_Malta_Southern_Harbour_Routes),\n",
    "    ('Western_Routes', Monday_Routes_Malta_Western_Routes),\n",
    "    ('Northern_Routes', Monday_Routes_Malta_Northern_Routes),\n",
    "    ('Mater_Dei_North_Routes', Monday_Routes_Malta_Mater_Dei_North_Routes),\n",
    "    ('Mater_Dei_South_Routes', Monday_Routes_Malta_Mater_Dei_South_Routes),\n",
    "    ('Airport_Routes', Monday_Routes_Malta_Mater_Dei_Airport_Routes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5146e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1 - Obtain Number of routes covered by each Route_Group\n",
    "\n",
    "# Create a list of route group names from Monday_Routes_Malta_List\n",
    "Route_Group = [name for name, _ in Monday_Routes_Malta_List]\n",
    "\n",
    "# Compute number of unique routes per route group, adding one extra if the group is 'Route41_49'\n",
    "malta_routes = []\n",
    "for name, df in Monday_Routes_Malta_List:\n",
    "    unique_count = len(df[['Route Number', 'Route Direction', 'Time_Count']].drop_duplicates())\n",
    "    if name == 'Northern_Routes':\n",
    "        unique_count += 1  # Add an extra route for Route41_49\n",
    "    malta_routes.append(unique_count)\n",
    "\n",
    "# Create the summary DataFrame\n",
    "route_data = pd.DataFrame({\n",
    "    \"Route Group\": Route_Group,\n",
    "    \"Number of Routes\": malta_routes\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(route_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.2 - Obtain table indicating number of bus stops traversed by each route,\n",
    "# also taking into account day of the week (for non-circular stops, we consider only\n",
    "# the maximum number of stops in any one direction)\n",
    "\n",
    "# Initialize a list to collect summary data for each route DataFrame\n",
    "summary_results = []\n",
    "\n",
    "# Process each tuple (name, DataFrame) in Monday_Routes_Malta_List\n",
    "for name, df in Monday_Routes_Malta_List:\n",
    "    # Work on a copy of the DataFrame\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Create a unique route identifier by concatenating relevant columns.\n",
    "    df_copy['Route_ID'] = (df_copy['Route Number'] + '-' +\n",
    "                           df_copy['Route Direction'] + '-' +\n",
    "                           df_copy['Time_Count'].astype(str))\n",
    "    \n",
    "    # Group by the unique route identifier and count the number of bus stops per route instance.\n",
    "    route_stop_counts = df_copy.groupby('Route_ID').size()\n",
    "    \n",
    "    # Determine the minimum and maximum number of bus stops seen in any one route instance.\n",
    "    min_stops = route_stop_counts.min()\n",
    "    max_stops = route_stop_counts.max()\n",
    "    \n",
    "    # If the route group is 'Route41_49', divide the maximum stops value by 2 and convert to int\n",
    "    if name == \"Northern_Routes\":\n",
    "        max_stops = int(max_stops / 2)\n",
    "    \n",
    "    # Append the results for this DataFrame to the summary list.\n",
    "    summary_results.append({\n",
    "        'DataFrame_Name': name,\n",
    "        'Min_Bus_Stops': min_stops,\n",
    "        'Max_Bus_Stops': max_stops\n",
    "    })\n",
    "\n",
    "# Convert the summary results to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure save_path ends with a separator\n",
    "save_path = \"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Python Scripts//Terminal_NormalStops_Identification//\"\n",
    "\n",
    "for name, i in Monday_Routes_Malta_List:\n",
    "    print(name)\n",
    "    \n",
    "    # Reset index and work on a copy to avoid SettingWithCopyWarning\n",
    "    i = i.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Create Reset_Condition for identifying changes in route attributes\n",
    "    Reset_Condition = (\n",
    "        (i['Route Number'].shift(-1) != i['Route Number']) |\n",
    "        (i['Route Direction'].shift(-1) != i['Route Direction']) |\n",
    "        (i['Time_Count'].shift(-1) != i['Time_Count'])\n",
    "    )\n",
    "    \n",
    "    # Initialise all entries in 'Bus_Terminal' as 0\n",
    "    i.loc[:, 'Bus_Terminal'] = 0\n",
    "    # If Reset_Condition is True then mark as Bus Terminal\n",
    "    i.loc[Reset_Condition, 'Bus_Terminal'] = 1\n",
    "    \n",
    "    OG_BUS_Terminal_COLUMN = i['Bus_Terminal'].copy()\n",
    "    # Iterate through the original Bus_Terminal column\n",
    "    for j in range(len(OG_BUS_Terminal_COLUMN) - 1):\n",
    "        if OG_BUS_Terminal_COLUMN[j] == 1:\n",
    "            i.loc[j + 1, 'Bus_Terminal'] = 1\n",
    "    # Initialise first row as Bus Terminal\n",
    "    i.loc[0, 'Bus_Terminal'] = 1\n",
    "    \n",
    "    # Identify Bus Terminal stops\n",
    "    Bus_Terminals_DataFrame = i[i['Bus_Terminal'] == 1]\n",
    "    \n",
    "    # Collect unique Bus_Stop_IDs for Bus Terminals\n",
    "    bus_stop_ids = []\n",
    "    for c in range(len(Bus_Terminals_DataFrame)):\n",
    "        bus_stop_id = Bus_Terminals_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "        if bus_stop_id not in bus_stop_ids:\n",
    "            bus_stop_ids.append(bus_stop_id)\n",
    "    \n",
    "    # DataFrame for Normal Bus Stops (non-terminals)\n",
    "    Normal_Bus_DataFrame = i[i['Bus_Terminal'] == 0]\n",
    "    \n",
    "    # Collect unique Bus_Stop_IDs for Normal stops\n",
    "    Normal_bus_stop_ids = []\n",
    "    for c in range(len(Normal_Bus_DataFrame)):\n",
    "        normal_bus_stop_id = Normal_Bus_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "        if normal_bus_stop_id not in Normal_bus_stop_ids:\n",
    "            Normal_bus_stop_ids.append(normal_bus_stop_id)\n",
    "    \n",
    "    # Bus Stops used as both Normal and Terminal stops\n",
    "    Normal_and_BusTerminals_ids = list(set(bus_stop_ids) & set(Normal_bus_stop_ids))\n",
    "    \n",
    "    # Define empty DataFrame to store Bus Stops used as both Normal and Terminal\n",
    "    Normal_and_BusTerminals_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "    compare_bus_stop_ids = []\n",
    "    for c in range(len(i)):\n",
    "        bus_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "        if bus_stop_id in Normal_and_BusTerminals_ids and bus_stop_id not in compare_bus_stop_ids:\n",
    "            compare_bus_stop_ids.append(bus_stop_id)\n",
    "            Normal_and_BusTerminals_DataFrame_Malta = pd.concat(\n",
    "                [Normal_and_BusTerminals_DataFrame_Malta, i.iloc[[c]]],\n",
    "                ignore_index=True\n",
    "            )\n",
    "    \n",
    "    file_name = f\"AllNormalBusStopsUsedAsTerminals_{name}.csv\"\n",
    "    Normal_and_BusTerminals_DataFrame_Malta.to_csv(os.path.join(save_path, file_name), index=False)\n",
    "    \n",
    "    # Bus Stops used only as Terminals\n",
    "    BusTerminals_Only_ids = list(set(bus_stop_ids) - set(Normal_bus_stop_ids))\n",
    "    BusTerminals_Only_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "    Only_Terminal_stop_ids = []\n",
    "    for c in range(len(i)):\n",
    "        Only_Terminal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "        if Only_Terminal_stop_id in BusTerminals_Only_ids and Only_Terminal_stop_id not in Only_Terminal_stop_ids:\n",
    "            Only_Terminal_stop_ids.append(Only_Terminal_stop_id)\n",
    "            BusTerminals_Only_DataFrame_Malta = pd.concat(\n",
    "                [BusTerminals_Only_DataFrame_Malta, i.iloc[[c]]],\n",
    "                ignore_index=True\n",
    "            )\n",
    "    \n",
    "    file_name = f\"BusTerminalsOnly_{name}.csv\"\n",
    "    BusTerminals_Only_DataFrame_Malta.to_csv(os.path.join(save_path, file_name), index=False)\n",
    "    \n",
    "    # Bus Stops used only as Normal stops\n",
    "    NormalStops_Only_ids = list(set(Normal_bus_stop_ids) - set(bus_stop_ids))\n",
    "    NormalStops_Only_DataFrame_Malta = pd.DataFrame(columns=i.columns)\n",
    "    Only_Normal_stop_ids = []\n",
    "    for c in range(len(i)):\n",
    "        Only_Normal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "        if Only_Normal_stop_id in NormalStops_Only_ids and Only_Normal_stop_id not in Only_Normal_stop_ids:\n",
    "            Only_Normal_stop_ids.append(Only_Normal_stop_id)\n",
    "            NormalStops_Only_DataFrame_Malta = pd.concat(\n",
    "                [NormalStops_Only_DataFrame_Malta, i.iloc[[c]]],\n",
    "                ignore_index=True\n",
    "            )\n",
    "    \n",
    "    file_name = f\"NormalStopsOnly_{name}.csv\"\n",
    "    NormalStops_Only_DataFrame_Malta.to_csv(os.path.join(save_path, file_name), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36833c0",
   "metadata": {},
   "source": [
    "### Step 8.2 - Gozo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "Monday_Routes_Gozo_List = [\n",
    "    ('Monday_Gozo_Routes', Monday_Routes_Gozo)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d369fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1 - Obtain Number of routes covered by each Route_Group\n",
    "\n",
    "# Create a list of route group names from Monday_Routes_Malta_List\n",
    "Route_Group = [name for name, _ in Monday_Routes_Gozo_List]\n",
    "\n",
    "# Compute number of unique routes per route group, adding one extra if the group is 'Route41_49'\n",
    "gozo_routes = []\n",
    "for name, df in Monday_Routes_Gozo_List:\n",
    "    unique_count = len(df[['Route Number', 'Route Direction', 'Time_Count']].drop_duplicates())\n",
    "    #if name == 'Northern_Routes':\n",
    "    #    unique_count += 1  # Add an extra route for Route41_49\n",
    "    gozo_routes.append(unique_count)\n",
    "\n",
    "# Create the summary DataFrame\n",
    "route_data = pd.DataFrame({\n",
    "    \"Route Group\": Route_Group,\n",
    "    \"Number of Routes\": gozo_routes\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(route_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.2 - Obtain table indicating number of bus stops traversed by each route,\n",
    "# also taking into account day of the week (for non-circular stops, we consider only\n",
    "# the maximum number of stops in any one direction)\n",
    "\n",
    "# Initialize a list to collect summary data for each route DataFrame\n",
    "summary_results = []\n",
    "\n",
    "# Process each tuple (name, DataFrame) in Monday_Routes_Malta_List\n",
    "for name, df in Monday_Routes_Gozo_List:\n",
    "    # Work on a copy of the DataFrame\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Create a unique route identifier by concatenating relevant columns.\n",
    "    df_copy['Route_ID'] = (df_copy['Route Number'] + '-' +\n",
    "                           df_copy['Route Direction'] + '-' +\n",
    "                           df_copy['Time_Count'].astype(str))\n",
    "    \n",
    "    # Group by the unique route identifier and count the number of bus stops per route instance.\n",
    "    route_stop_counts = df_copy.groupby('Route_ID').size()\n",
    "    \n",
    "    # Determine the minimum and maximum number of bus stops seen in any one route instance.\n",
    "    min_stops = route_stop_counts.min()\n",
    "    max_stops = route_stop_counts.max()\n",
    "    \n",
    "    # If the route group is 'Route41_49', divide the maximum stops value by 2 and convert to int\n",
    "    #if name == \"Northern_Routes\":\n",
    "    #   max_stops = int(max_stops / 2)\n",
    "    \n",
    "    # Append the results for this DataFrame to the summary list.\n",
    "    summary_results.append({\n",
    "        'DataFrame_Name': name,\n",
    "        'Min_Bus_Stops': min_stops,\n",
    "        'Max_Bus_Stops': max_stops\n",
    "    })\n",
    "\n",
    "# Convert the summary results to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187aa098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure save_path ends with a separator\n",
    "save_path = \"C://Users//Owner//ICT5012 - Disseration//Chapter 3 - Data Visualisation//Python Scripts//Terminal_NormalStops_Identification//\"\n",
    "\n",
    "for name, i in Monday_Routes_Gozo_List:\n",
    "    print(name)\n",
    "    \n",
    "    # Reset index and work on a copy to avoid SettingWithCopyWarning\n",
    "    i = i.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Create Reset_Condition for identifying changes in route attributes\n",
    "    Reset_Condition = (\n",
    "        (i['Route Number'].shift(-1) != i['Route Number']) |\n",
    "        (i['Route Direction'].shift(-1) != i['Route Direction']) |\n",
    "        (i['Time_Count'].shift(-1) != i['Time_Count'])\n",
    "    )\n",
    "    \n",
    "    # Initialise all entries in 'Bus_Terminal' as 0\n",
    "    i.loc[:, 'Bus_Terminal'] = 0\n",
    "    # If Reset_Condition is True then mark as Bus Terminal\n",
    "    i.loc[Reset_Condition, 'Bus_Terminal'] = 1\n",
    "    \n",
    "    OG_BUS_Terminal_COLUMN = i['Bus_Terminal'].copy()\n",
    "    # Iterate through the original Bus_Terminal column\n",
    "    for j in range(len(OG_BUS_Terminal_COLUMN) - 1):\n",
    "        if OG_BUS_Terminal_COLUMN[j] == 1:\n",
    "            i.loc[j + 1, 'Bus_Terminal'] = 1\n",
    "    # Initialise first row as Bus Terminal\n",
    "    i.loc[0, 'Bus_Terminal'] = 1\n",
    "    \n",
    "    # Identify Bus Terminal stops\n",
    "    Bus_Terminals_DataFrame = i[i['Bus_Terminal'] == 1]\n",
    "    \n",
    "    # Collect unique Bus_Stop_IDs for Bus Terminals\n",
    "    bus_stop_ids = []\n",
    "    for c in range(len(Bus_Terminals_DataFrame)):\n",
    "        bus_stop_id = Bus_Terminals_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "        if bus_stop_id not in bus_stop_ids:\n",
    "            bus_stop_ids.append(bus_stop_id)\n",
    "    \n",
    "    # DataFrame for Normal Bus Stops (non-terminals)\n",
    "    Normal_Bus_DataFrame = i[i['Bus_Terminal'] == 0]\n",
    "    \n",
    "    # Collect unique Bus_Stop_IDs for Normal stops\n",
    "    Normal_bus_stop_ids = []\n",
    "    for c in range(len(Normal_Bus_DataFrame)):\n",
    "        normal_bus_stop_id = Normal_Bus_DataFrame.iloc[c]['Bus_Stop_ID']\n",
    "        if normal_bus_stop_id not in Normal_bus_stop_ids:\n",
    "            Normal_bus_stop_ids.append(normal_bus_stop_id)\n",
    "    \n",
    "    # Bus Stops used as both Normal and Terminal stops\n",
    "    Normal_and_BusTerminals_ids = list(set(bus_stop_ids) & set(Normal_bus_stop_ids))\n",
    "    \n",
    "    # Define empty DataFrame to store Bus Stops used as both Normal and Terminal\n",
    "    Normal_and_BusTerminals_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "    compare_bus_stop_ids = []\n",
    "    for c in range(len(i)):\n",
    "        bus_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "        if bus_stop_id in Normal_and_BusTerminals_ids and bus_stop_id not in compare_bus_stop_ids:\n",
    "            compare_bus_stop_ids.append(bus_stop_id)\n",
    "            Normal_and_BusTerminals_DataFrame_Gozo = pd.concat(\n",
    "                [Normal_and_BusTerminals_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                ignore_index=True\n",
    "            )\n",
    "    \n",
    "    file_name = f\"AllNormalBusStopsUsedAsTerminals_{name}.csv\"\n",
    "    Normal_and_BusTerminals_DataFrame_Gozo.to_csv(os.path.join(save_path, file_name), index=False)\n",
    "    \n",
    "    # Bus Stops used only as Terminals\n",
    "    BusTerminals_Only_ids = list(set(bus_stop_ids) - set(Normal_bus_stop_ids))\n",
    "    BusTerminals_Only_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "    Only_Terminal_stop_ids = []\n",
    "    for c in range(len(i)):\n",
    "        Only_Terminal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "        if Only_Terminal_stop_id in BusTerminals_Only_ids and Only_Terminal_stop_id not in Only_Terminal_stop_ids:\n",
    "            Only_Terminal_stop_ids.append(Only_Terminal_stop_id)\n",
    "            BusTerminals_Only_DataFrame_Gozo = pd.concat(\n",
    "                [BusTerminals_Only_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                ignore_index=True\n",
    "            )\n",
    "    \n",
    "    file_name = f\"BusTerminalsOnly_{name}.csv\"\n",
    "    BusTerminals_Only_DataFrame_Gozo.to_csv(os.path.join(save_path, file_name), index=False)\n",
    "    \n",
    "    # Bus Stops used only as Normal stops\n",
    "    NormalStops_Only_ids = list(set(Normal_bus_stop_ids) - set(bus_stop_ids))\n",
    "    NormalStops_Only_DataFrame_Gozo = pd.DataFrame(columns=i.columns)\n",
    "    Only_Normal_stop_ids = []\n",
    "    for c in range(len(i)):\n",
    "        Only_Normal_stop_id = i.iloc[c]['Bus_Stop_ID']\n",
    "        if Only_Normal_stop_id in NormalStops_Only_ids and Only_Normal_stop_id not in Only_Normal_stop_ids:\n",
    "            Only_Normal_stop_ids.append(Only_Normal_stop_id)\n",
    "            NormalStops_Only_DataFrame_Gozo = pd.concat(\n",
    "                [NormalStops_Only_DataFrame_Gozo, i.iloc[[c]]],\n",
    "                ignore_index=True\n",
    "            )\n",
    "    \n",
    "    file_name = f\"NormalStopsOnly_{name}.csv\"\n",
    "    NormalStops_Only_DataFrame_Gozo.to_csv(os.path.join(save_path, file_name), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0321bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
