{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4948bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorboard\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daa6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/Owner/ICT5012 - Disseration/transit_learning-master_Newest')\n",
    "from torch_geometric.loader import DataLoader\n",
    "from simulation.citygraph_dataset import CityGraphData, \\\n",
    "    get_dataset_from_config, STOP_KEY\n",
    "from simulation.transit_time_estimator import RouteGenBatchState, get_cost_module_from_cfg\n",
    "import learning.utils as lrnu\n",
    "from torch_utils_2 import get_batch_tensor_from_routes, dump_routes\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2057d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Config, self).__init__(*args, **kwargs)\n",
    "        for key, value in self.items():\n",
    "            if isinstance(value, dict):\n",
    "                self[key] = Config(value)\n",
    "            elif isinstance(value, list):\n",
    "                # Convert dict elements in lists to Config objects\n",
    "                self[key] = [Config(item) if isinstance(item, dict) else item for item in value]\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "\n",
    "cfg = Config({\n",
    "    'ppo': {\n",
    "        'n_iterations': 200,\n",
    "        'val_period': 10,\n",
    "        'n_epochs': 1,\n",
    "        'minibatch_size': 10,\n",
    "        'horizon': 120,\n",
    "        'epsilon': 0.2,\n",
    "        'use_gae': False,\n",
    "        'gae_lambda': 0.95\n",
    "    },\n",
    "    'discount_rate': 0.95,\n",
    "    'diff_reward': True,\n",
    "    'baseline_lr': 0.0005,\n",
    "    'entropy_weight': 0,\n",
    "    'batch_size': 10,\n",
    "    'reward_scale': 1.0,\n",
    "    'lr': 0.0016134816080499328,\n",
    "    'decay': 0.0008404361781997002,\n",
    "    'optimizer': 'Adam',\n",
    "    'eval': {\n",
    "        'n_routes': 15,\n",
    "        'min_route_len': 11,\n",
    "        'max_route_len': 42\n",
    "    },\n",
    "    'dataset': {\n",
    "        'type': 'mumford',\n",
    "        'kwargs': {\n",
    "            'path': 'datasets/mumford_dataset/Instances',\n",
    "            'city': 'Gozo'\n",
    "        }\n",
    "    },\n",
    "    'experiment': {\n",
    "        'logdir': 'training_logs',\n",
    "        'anomaly': False,\n",
    "        'cpu': False,\n",
    "        'seed': 0,\n",
    "        'symmetric_routes': False\n",
    "    },\n",
    "    'defaults': [\n",
    "        '_self_',\n",
    "        {\n",
    "            'cost_function': {\n",
    "                'type': 'mine',\n",
    "                'kwargs': {\n",
    "                    'mean_stop_time_s': 0,\n",
    "                    'avg_transfer_wait_time_s': 300,\n",
    "                    'demand_time_weight': 0.5,\n",
    "                    'route_time_weight': 0.5,\n",
    "                    'constraint_violation_weight': 5.0,\n",
    "                    'variable_weights': False,\n",
    "                    'pp_fraction': 0.33,\n",
    "                    'op_fraction': 0.33\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234aac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Config, self).__init__(*args, **kwargs)\n",
    "        for key, value in self.items():\n",
    "            if isinstance(value, dict):\n",
    "                self[key] = Config(value)\n",
    "    __getattr__ = dict.get\n",
    "\n",
    "# Minimal experiment configuration\n",
    "exp_dc = Config({\n",
    "    'cost_function': {\n",
    "        'type': 'mine',  # Specify the cost function type as 'mine'\n",
    "        'kwargs': {}     # Any additional parameters can be added here\n",
    "    },\n",
    "    'symmetric_routes': True,    # or False, based on your requirement\n",
    "    'low_memory_mode': False\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb46c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    __getattr__ = dict.get\n",
    "\n",
    "Dataset_Info = Config({\n",
    "    'csv': True,\n",
    "    'n_routes': 15,\n",
    "    'min_route_len': 11,\n",
    "    'max_route_len': 42,\n",
    "    'type': 'mumford',\n",
    "    'path': 'C:/Users/Owner/ICT5012 - Disseration/transit_learning-master/CEC2013Supp/Instances',\n",
    "    'city': 'Gozo'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3cafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cfg = cfg.experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c80beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_cfg.get('cpu', False) or not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf0ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in cfg:\n",
    "    # setup the model\n",
    "    model = build_model_from_cfg(cfg['model'], exp_cfg)\n",
    "    if 'weights' in cfg.model:\n",
    "        model.load_state_dict(torch.load(cfg.model.weights,map_location=device))\n",
    "    elif weights_required and cfg.model.route_generator.type != 'RandomPathCombiningRouteGenerator': raise ValueError(\"model weights are required but not provided\")\n",
    "else:\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024aea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the cost function\n",
    "low_mem_mode = exp_cfg.get('low_memory_mode', False)\n",
    "cost_obj = get_cost_module_from_cfg(exp_dc.cost_function, low_mem_mode,\n",
    "                                    exp_cfg.symmetric_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bbab505",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_obj.to(device)\n",
    "if model is not None:\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a84b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = get_dataset_from_config(Dataset_Info)\n",
    "test_dl = DataLoader(test_ds, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68157dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = cfg.get('n_samples', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30b92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs = cfg.get('sample_batch_size', cfg.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0776995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(test_dl):\n",
    "    if device is not None and device.type != 'cpu':\n",
    "        data = data.cuda()\n",
    "    start_time = time.time()\n",
    "    state = RouteGenBatchState(data, cost_obj, cfg.eval.n_routes, \n",
    "                                   cfg.eval.min_route_len, \n",
    "                                   cfg.eval.max_route_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e699b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose your current tensor is:\n",
    "final_routes_tensor = torch.tensor([\n",
    "    [[12,  9,  6, 14,  8, -1, -1]],\n",
    "    [[ 0,  1,  2,  5, 14,  8, -1]],\n",
    "    [[ 0,  1,  2,  5,  7,  9, 12]],\n",
    "    [[ 6, 14,  5,  2,  1,  0, -1]],\n",
    "    [[12,  9,  6, 14,  8, -1, -1]],\n",
    "    [[12,  9,  7,  5,  2,  1,  0]],\n",
    "    [[ 0,  1,  2,  5,  7,  9, 12]],\n",
    "    [[12,  9,  6, -1, -1, -1, -1]],\n",
    "    [[ 0,  1,  2,  5, 14,  8, -1]],\n",
    "    [[12,  9,  7,  5,  2,  1,  0]],\n",
    "    [[ 0,  1,  2,  5,  7,  9, 12]],\n",
    "    [[12,  9,  6, 14,  8, -1, -1]]\n",
    "])\n",
    "# Current shape is [12, 1, 7].\n",
    "\n",
    "# First, remove the singleton dimension (the inner dimension):\n",
    "routes = final_routes_tensor.squeeze(1)  # Now shape: [12, 7]\n",
    "\n",
    "# Now, add a batch dimension of 1 at the front:\n",
    "final_routes_tensor_correct = routes.unsqueeze(0)  # Shape becomes [1, 12, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d790868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max route length: 38\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your list of route tensors (each is a 1D tensor)\n",
    "routes_list = [\n",
    "    torch.tensor([246, 112, 113, 114, 115, 23, 22, 1, 2, 3, 116, 117, 118, 119,\n",
    "                  120, 121, 122, 123, 126, 224, 40, 39, 38, 37, 36, 35, 48, 225,\n",
    "                  226, 52, 53, 58, 59]),\n",
    "    torch.tensor([194,195,196,197,198,199,200,201,202,183,182,189,190,144,\n",
    "                  145,146,147,148,149,150,151,143,142,152,203,191,1,2,3,4,5,6,30,31,32]),\n",
    "    torch.tensor([115,23,22,1,136,192,141,204,205,206,207,208,209,210,211,212,213,214]),\n",
    "    torch.tensor([3,4,5,18,19,20,21,0,1,136,137,138,153,154,155,156,157,158,159,160,161,162,163]),\n",
    "    torch.tensor([15,66,67,68,69,70,71,13,12,11,10,16,238,9,17,8,7,6,5,18,19,20,21,0,1,136,192,141,142,143,144,179,180,181,182,183]),\n",
    "    torch.tensor([46,23,24,25,26,27,28,29,32,33,34,35,36,37,38,39,40,229,126,127,124,223,134,135,119,118,117,116,20,21,0,1,136,137,138,139,140]),\n",
    "    torch.tensor([75,77,78,79,80,61,62,63,64,65,74,228,227,52,53,226,225,48,34,33,32,41,42,28,27,26,43,45,46,23,22,1,136,137,138,139,140,141]),\n",
    "    torch.tensor([135,119,118,117,116,20,21,0,1,136,164,22,23,83,84,85,86,87,88,89,90,91,92,93,94,95]),\n",
    "    torch.tensor([145,146,147,148,149,150,151,143,144,179,180,181,193,194,195,196,197,198,199,200,201,202,183]),\n",
    "    torch.tensor([100,98,102,96,103,104,105,106,107,108,109,110,111,112,113,114,115,23,22,1,2,3,116,117]),\n",
    "    torch.tensor([100,23,24,25,26,27,28,29,32,33,34,48,225,226,52,53,54,55,56,57]),\n",
    "    torch.tensor([81,80,59,60,77,78,79]),\n",
    "    torch.tensor([10,16,238,9,17,8,7,6,5,18,19,20,21,0,1,136,164,165,166,167,168,169,170,171,172,173,174,175,176,177]),\n",
    "    torch.tensor([195,196,197,198,199,200,201,202,183,182,189,190,144,143,142,152,203,191,1,2,3,4,5,6,7,8,9,10,11,12]),\n",
    "    torch.tensor([185,188,183,182,189,190,144,143,142,152,203,191,1,2,3,4,5,6,7,8,9,10,16,238,237,236,234,235])\n",
    "]\n",
    "\n",
    "# Determine the maximum route length among all routes.\n",
    "max_length = max(route.numel() for route in routes_list)\n",
    "print(\"Max route length:\", max_length)  # Expected: 38\n",
    "\n",
    "# Pad each route to the maximum length using -1 as the padding value.\n",
    "padded_routes = []\n",
    "for route in routes_list:\n",
    "    pad_length = max_length - route.numel()\n",
    "    if pad_length > 0:\n",
    "        padded_route = torch.cat([route, -1 * torch.ones(pad_length, dtype=route.dtype)])\n",
    "    else:\n",
    "        padded_route = route\n",
    "    padded_routes.append(padded_route)\n",
    "\n",
    "# Stack all padded routes into a tensor of shape [n_routes, max_length].\n",
    "routes_tensor = torch.stack(padded_routes)  # Shape: [15, 38]\n",
    "\n",
    "# If your state is for a single graph (batch size = 1), add a batch dimension.\n",
    "final_routes_tensor_correct = routes_tensor.unsqueeze(0)  # Final shape: [1, 15, 38]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00f29df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.add_new_routes(final_routes_tensor_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "672d4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_matrix = state.demand\n",
    "trip_times = state.transit_times\n",
    "nopath = ~state.has_path\n",
    "trip_times[nopath] = 0\n",
    "demand_time = demand_matrix * trip_times\n",
    "total_dmd_time = demand_time.sum(dim=(1, 2))\n",
    "demand_transfers = demand_matrix * state.n_transfers\n",
    "total_transfers = demand_transfers.sum(dim=(1, 2))\n",
    "unserved_demand = (demand_matrix * nopath).sum(dim=(1, 2))\n",
    "total_demand = demand_matrix.sum(dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1b1fce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9470.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "served_demand = total_demand - unserved_demand\n",
    "served_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d91fbced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2352386.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dmd_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20634f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e27fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "41794b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ffe88d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a .txt file into a pandas DataFrame\n",
    "Demand = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//transit_learning-master//CEC2013Supp//Instances//MandlDemand.txt\", delimiter=\"\\s+\", header=None)\n",
    "Travel_Time = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//transit_learning-master//CEC2013Supp//Instances//MandlTravelTimes.txt\", delimiter=\"\\s+\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d19aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Routes\n",
    "Routes = pd.read_csv(\"C://Users//Owner//ICT5012 - Disseration//transit_learning-master//LatestMandl.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "024d0824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Route 1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Route 2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Route 3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Route 4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Route 5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Route 6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Route 7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Route 8</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Route 9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Route 10</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Route 11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Route 12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1   2  3     4     5    6     7\n",
       "0    Route 1  12   9  6  14.0   8.0  NaN   NaN\n",
       "1    Route 2   0   1  2   5.0  14.0  8.0   NaN\n",
       "2    Route 3   0   1  2   5.0   7.0  9.0  12.0\n",
       "3    Route 4   6  14  5   2.0   1.0  0.0   NaN\n",
       "4    Route 5  12   9  6  14.0   8.0  NaN   NaN\n",
       "5    Route 6  12   9  7   5.0   2.0  1.0   0.0\n",
       "6    Route 7   0   1  2   5.0   7.0  9.0  12.0\n",
       "7    Route 8  12   9  6   NaN   NaN  NaN   NaN\n",
       "8    Route 9   0   1  2   5.0  14.0  8.0   NaN\n",
       "9   Route 10  12   9  7   5.0   2.0  1.0   0.0\n",
       "10  Route 11   0   1  2   5.0   7.0  9.0  12.0\n",
       "11  Route 12  12   9  6  14.0   8.0  NaN   NaN"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "335977f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0., 400., 200.,  60.,  80., 150.,  75.,  75.,  30., 160.,  30.,\n",
       "           25.,  35.,   0.,   0.],\n",
       "         [400.,   0.,  50., 120.,  20., 180.,  90.,  90.,  15., 130.,  20.,\n",
       "           10.,  10.,   5.,   0.],\n",
       "         [200.,  50.,   0.,  40.,  60., 180.,  90.,  90.,  15.,  45.,  20.,\n",
       "           10.,  10.,   5.,   0.],\n",
       "         [ 60., 120.,  40.,   0.,  50., 100.,  50.,  50.,  15., 240.,  40.,\n",
       "           25.,  10.,   5.,   0.],\n",
       "         [ 80.,  20.,  60.,  50.,   0.,  50.,  25.,  25.,  10., 120.,  20.,\n",
       "           15.,   5.,   0.,   0.],\n",
       "         [150., 180., 180., 100.,  50.,   0., 100., 100.,  30., 880.,  60.,\n",
       "           15.,  15.,  10.,   0.],\n",
       "         [ 75.,  90.,  90.,  50.,  25., 100.,   0.,  50.,  15., 440.,  35.,\n",
       "           10.,  10.,   5.,   0.],\n",
       "         [ 75.,  90.,  90.,  50.,  25., 100.,  50.,   0.,  15., 440.,  35.,\n",
       "           10.,  10.,   5.,   0.],\n",
       "         [ 30.,  15.,  15.,  15.,  10.,  30.,  15.,  15.,   0., 140.,  20.,\n",
       "            5.,   0.,   0.,   0.],\n",
       "         [160., 130.,  45., 240., 120., 880., 440., 440., 140.,   0., 600.,\n",
       "          250., 500., 200.,   0.],\n",
       "         [ 30.,  20.,  20.,  40.,  20.,  60.,  35.,  35.,  20., 600.,   0.,\n",
       "           75.,  95.,  15.,   0.],\n",
       "         [ 25.,  10.,  10.,  25.,  15.,  15.,  10.,  10.,   5., 250.,  75.,\n",
       "            0.,  70.,   0.,   0.],\n",
       "         [ 35.,  10.,  10.,  10.,   5.,  15.,  10.,  10.,   0., 500.,  95.,\n",
       "           70.,   0.,  45.,   0.],\n",
       "         [  0.,   5.,   5.,   5.,   0.,  10.,   5.,   5.,   0., 200.,  15.,\n",
       "            0.,  45.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose 'Demand' is your 15×15 DataFrame\n",
    "demand_array = Demand.values  # shape: (15, 15)\n",
    "# Expand dimensions to get (1, 15, 15)\n",
    "demand_3d = np.expand_dims(demand_array, axis=0)  # shape: (1, 15, 15)\n",
    "# Convert to PyTorch tensor (float, on GPU if you wish)\n",
    "demand = torch.tensor(demand_3d, dtype=torch.float)\n",
    "demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072115fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume Travel_Time is a DataFrame with travel times (in minutes) and Routes is the routes DataFrame.\n",
    "N = Travel_Time.shape[0]\n",
    "# We'll build an NxN result matrix (in seconds), defaulting to inf:\n",
    "result_seconds = np.full((N, N), np.inf)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# For each route, consider every ordered pair (i < j) of stops in that route,\n",
    "# and sum up the intermediate legs from i to j.\n",
    "for idx, row in Routes.iterrows():\n",
    "    # row[0] is the route name, so actual node IDs start at column 1\n",
    "    node_sequence = [node for node in row[1:].values if pd.notnull(node)]\n",
    "    # Convert to int in case they are floats\n",
    "    node_sequence = list(map(int, node_sequence))\n",
    "    \n",
    "    # For each pair (i, j) in that route with i < j in route order:\n",
    "    for start_idx in range(len(node_sequence)):\n",
    "        for end_idx in range(start_idx+1, len(node_sequence)):\n",
    "            from_node = node_sequence[start_idx]\n",
    "            to_node   = node_sequence[end_idx]\n",
    "            \n",
    "            # Accumulate segment-by-segment from node_sequence[start_idx] to node_sequence[end_idx]\n",
    "            time_minutes_sum = 0.0\n",
    "            valid_route = True  # Mark False if any segment is inf\n",
    "            for k in range(start_idx, end_idx):\n",
    "                seg_from = node_sequence[k]\n",
    "                seg_to   = node_sequence[k+1]\n",
    "                seg_time = Travel_Time.loc[seg_from, seg_to]  # in minutes\n",
    "                \n",
    "                if seg_time == np.inf:\n",
    "                    valid_route = False\n",
    "                    break\n",
    "                else:\n",
    "                    time_minutes_sum += seg_time\n",
    "            \n",
    "            if valid_route:\n",
    "                # Convert total route time to seconds\n",
    "                time_seconds = time_minutes_sum * 60\n",
    "                # Optionally keep the minimum if there's already a value stored\n",
    "                result_seconds[from_node, to_node] = min(result_seconds[from_node, to_node],\n",
    "                                                         time_seconds)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Set the diagonal (travel from a node to itself) to 0 seconds.\n",
    "np.fill_diagonal(result_seconds, 0)\n",
    "\n",
    "result_seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b757af",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_mat = torch.tensor(result_seconds)\n",
    "route_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = Travel_Time.shape[0]\n",
    "batch_new_routes = torch.full((1, 1, N), -1)\n",
    "batch_new_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f10a8307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   0.,  480.,  600.,  660.,  840.,  780., 1080.,  900., 1440., 1380.,\n",
       "          1680., 1260., 1980., 1860.,  960.],\n",
       "         [ 480.,    0.,  120.,  180.,  360.,  300.,  600.,  420.,  960.,  900.,\n",
       "          1200.,  780., 1500., 1380.,  480.],\n",
       "         [ 600.,  120.,    0.,  300.,  480.,  180.,  480.,  300.,  840.,  780.,\n",
       "          1080.,  900., 1380., 1260.,  360.],\n",
       "         [ 660.,  180.,  300.,    0.,  240.,  240.,  540.,  360.,  900.,  840.,\n",
       "          1140.,  600., 1440., 1320.,  420.],\n",
       "         [ 840.,  360.,  480.,  240.,    0.,  480.,  780.,  600., 1140., 1080.,\n",
       "          1380.,  840., 1680., 1560.,  660.],\n",
       "         [ 780.,  300.,  180.,  240.,  480.,    0.,  300.,  120.,  660.,  600.,\n",
       "           900.,  840., 1200., 1080.,  180.],\n",
       "         [1080.,  600.,  480.,  540.,  780.,  300.,    0.,  240.,  600.,  420.,\n",
       "           720., 1140., 1020.,  900.,  120.],\n",
       "         [ 900.,  420.,  300.,  360.,  600.,  120.,  240.,    0.,  600.,  480.,\n",
       "           780.,  960., 1080.,  960.,  120.],\n",
       "         [1440.,  960.,  840.,  900., 1140.,  660.,  600.,  600.,    0., 1020.,\n",
       "          1320., 1500., 1620., 1500.,  480.],\n",
       "         [1380.,  900.,  780.,  840., 1080.,  600.,  420.,  480., 1020.,    0.,\n",
       "           300.,  900.,  600.,  480.,  540.],\n",
       "         [1680., 1200., 1080., 1140., 1380.,  900.,  720.,  780., 1320.,  300.,\n",
       "             0.,  600.,  300.,  420.,  840.],\n",
       "         [1260.,  780.,  900.,  600.,  840.,  840., 1140.,  960., 1500.,  900.,\n",
       "           600.,    0.,  900., 1020., 1020.],\n",
       "         [1980., 1500., 1380., 1440., 1680., 1200., 1020., 1080., 1620.,  600.,\n",
       "           300.,  900.,    0.,  120., 1140.],\n",
       "         [1860., 1380., 1260., 1320., 1560., 1080.,  900.,  960., 1500.,  480.,\n",
       "           420., 1020.,  120.,    0., 1020.],\n",
       "         [ 960.,  480.,  360.,  420.,  660.,  180.,  120.,  120.,  480.,  540.,\n",
       "           840., 1020., 1140., 1020.,    0.]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# 1. Define the Floyd–Warshall function\n",
    "def floyd_warshall(cost_matrix):\n",
    "    \"\"\"\n",
    "    Runs the Floyd-Warshall algorithm on the given cost matrix.\n",
    "    \n",
    "    :param cost_matrix: A 2D list (NxN) of direct travel times.\n",
    "                        cost_matrix[i][j] = float('inf') if no direct path.\n",
    "    :return: A 2D list (NxN) where the value at [i][j] is the minimum travel time\n",
    "             from node i to node j.\n",
    "    \"\"\"\n",
    "    n = len(cost_matrix)\n",
    "    \n",
    "    # Initialize the distance matrix as a copy of the original cost matrix\n",
    "    dist = [[cost_matrix[i][j]*60 for j in range(n)] for i in range(n)]\n",
    "    \n",
    "    # Run the Floyd–Warshall updates\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if dist[i][k] + dist[k][j] < dist[i][j]:\n",
    "                    dist[i][j] = dist[i][k] + dist[k][j]\n",
    "    \n",
    "    return dist\n",
    "\n",
    "# 2. Read the matrix from a TXT file (assuming whitespace-separated values)\n",
    "filename = 'C://Users//Owner//ICT5012 - Disseration//transit_learning-master//CEC2013Supp//Instances//MandlTravelTimes.txt'\n",
    "raw_matrix = []\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line by whitespace. \n",
    "        # If your file uses commas, use: line.strip().split(',')\n",
    "        tokens = line.strip().split()\n",
    "        raw_matrix.append(tokens)\n",
    "\n",
    "# 3. Convert string \"Inf\" to float('inf') and other strings to floats\n",
    "cost_matrix = []\n",
    "for row in raw_matrix:\n",
    "    new_row = []\n",
    "    for token in row:\n",
    "        if token.strip().lower() == \"inf\":\n",
    "            new_row.append(float('inf'))\n",
    "        else:\n",
    "            new_row.append(float(token))\n",
    "    cost_matrix.append(new_row)\n",
    "\n",
    "cost_matrix = [row for row in cost_matrix if any(row)]  # Removes empty lists\n",
    "\n",
    "# 4. Run the Floyd–Warshall algorithm\n",
    "drive_times_matrix = floyd_warshall(cost_matrix)\n",
    "drive_times = torch.tensor(drive_times_matrix)\n",
    "drive_times =  drive_times.unsqueeze(0)\n",
    "drive_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcd612",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stop_time = torch.tensor(0)\n",
    "mean_stop_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c55c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_routes = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3b57b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/Othercomputers/My laptop/ICT5012 - Disseration/transit_learning-master')\n",
    "import torch_utils_2 as tu\n",
    "new_route_mat = tu.get_route_edge_matrix(batch_new_routes, drive_times, mean_stop_time, symmetric_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_mat = torch.minimum(route_mat, new_route_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf567201",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b20639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def compute_all_pairs_shortest_paths(route_mat: torch.Tensor, transfer_wait_time: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute all-pairs shortest travel times and path info using Floyd–Warshall.\n",
    "    Returns:\n",
    "        next_hop: Tensor of shape (batch, N, N) with next_hop[i,j] = next stop after i on the shortest path to j, or -1 if no path.\n",
    "        travel_time: Tensor of shape (batch, N, N) with the minimum travel time from i to j (including transfer wait penalties if provided).\n",
    "        has_path: Boolean tensor of shape (batch, N, N) indicating reachability (True if a path exists from i to j).\n",
    "        n_transfers: Tensor of shape (batch, N, N) indicating the number of transfers (route changes) on the shortest path from i to j.\n",
    "    \"\"\"\n",
    "    # Ensure route_mat has 3D shape [batch, N, N] for batch processing (batch dim can be 1 if single scenario)\n",
    "    if route_mat.ndim == 2:\n",
    "        route_mat = route_mat.unsqueeze(0)\n",
    "    batch_size, N, _ = route_mat.shape\n",
    "\n",
    "    # Initialize distance and next-hop matrices\n",
    "    # Use clone to avoid modifying the original route_mat\n",
    "    dist = route_mat.clone()\n",
    "    next_hop = -torch.ones((batch_size, N, N), dtype=torch.long, device=route_mat.device)\n",
    "    # Set next_hop for direct edges: if there's a direct edge from u to v, the next step from u to v is v.\n",
    "    # Also, set next_hop[i,i] = i for all i (path from a node to itself).\n",
    "    for b in range(batch_size):\n",
    "        # diagonal next_hop indicates self (0 transfers needed)\n",
    "        for i in range(N):\n",
    "            next_hop[b, i, i] = i\n",
    "        # for each directed edge (i -> j) that exists, set next_hop[i,j] = j\n",
    "        direct_edges = (dist[b] < float('inf'))\n",
    "        for i, j in torch.nonzero(direct_edges, as_tuple=False):\n",
    "            if i != j:\n",
    "                next_hop[b, i, j] = j\n",
    "\n",
    "    # Floyd–Warshall main loop: iterate over each intermediate node k\n",
    "    for k in range(N):\n",
    "        # Using broadcasting to vectorize distance update for all i, j pairs through k\n",
    "        # dist[:, i, j] > dist[:, i, k] + dist[:, k, j] indicates a shorter path found via k\n",
    "        new_dist = dist[:, :, k].unsqueeze(2) + dist[:, k].unsqueeze(1)  # shape (batch, N, 1) + (batch, 1, N) -> (batch, N, N)\n",
    "        improved = new_dist < dist  # elementwise comparison\n",
    "        # Update distances and next_hop where an improvement is found\n",
    "        dist[improved] = new_dist[improved]\n",
    "        # If the path i->k->j is better, set next_hop[i,j] = next_hop[i,k] (first step on path from i to j goes toward k’s direction)\n",
    "        # We gather next_hop for i->k across all batches where improvement happened\n",
    "        if improved.any():\n",
    "            # Get indices where improvement is True\n",
    "            batch_idx, i_idx, j_idx = torch.nonzero(improved, as_tuple=True)\n",
    "            # For each improved triplet (b, i, j), update next_hop[b,i,j]\n",
    "            for b, i, j in zip(batch_idx.tolist(), i_idx.tolist(), j_idx.tolist()):\n",
    "                next_hop[b, i, j] = next_hop[b, i, k]\n",
    "\n",
    "    # At this point, dist contains the shortest travel times (excluding transfer wait penalties) between all stops,\n",
    "    # and next_hop can be used to reconstruct paths.\n",
    "\n",
    "    # Determine reachability: has_path[b,i,j] is True if dist is finite (not inf)\n",
    "    has_path = dist < float('inf')\n",
    "\n",
    "    # Compute number of transfers for each shortest path.\n",
    "    # We will derive this by counting the number of legs (edges) in the path and subtracting 1.\n",
    "    n_transfers = torch.zeros_like(dist, dtype=torch.int)\n",
    "    # Reconstruct path lengths via next_hop: count how many steps from i to j.\n",
    "    for b in range(batch_size):\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if not has_path[b, i, j]:\n",
    "                    # No path from i to j\n",
    "                    n_transfers[b, i, j] = 0\n",
    "                elif i == j:\n",
    "                    # Trivial path (same start and end)\n",
    "                    n_transfers[b, i, j] = 0\n",
    "                else:\n",
    "                    # Follow the next_hop pointers from i to j and count edges\n",
    "                    count_edges = 0\n",
    "                    current = i\n",
    "                    # Traverse until reaching j\n",
    "                    while current != j and current != -1:\n",
    "                        current = next_hop[b, current, j].item()\n",
    "                        count_edges += 1\n",
    "                        # Safety break in case of any unforeseen cycle (should not happen if has_path is True and algorithm is correct)\n",
    "                        if count_edges > N: \n",
    "                            break\n",
    "                    # Number of transfers = number of edges - 1\n",
    "                    transfers = max(count_edges - 1, 0)\n",
    "                    n_transfers[b, i, j] = transfers\n",
    "\n",
    "    # If a transfer wait time is provided, add that penalty to the travel times for each transfer.\n",
    "    if transfer_wait_time is not None:\n",
    "        # Ensure transfer_wait_time is a tensor of shape (batch,) or broadcastable\n",
    "        transfer_wait_time = transfer_wait_time.to(dist.device)\n",
    "        if transfer_wait_time.ndim == 0:\n",
    "            transfer_wait_time = transfer_wait_time.repeat(batch_size)\n",
    "        # Add wait time for each transfer\n",
    "        dist += n_transfers * transfer_wait_time.view(batch_size, 1, 1)\n",
    "\n",
    "    # The `dist` matrix now holds the total travel time including transfer penalties (if any).\n",
    "    return next_hop, dist, has_path, n_transfers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage within RouteGenBatchState (assuming self.route_mat and self.transfer_time_s are defined):\n",
    "nexts, transit_times, has_path, n_transfers = compute_all_pairs_shortest_paths(route_mat, torch.tensor(300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_path = transit_times < float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopath = ~has_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_times = transit_times.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e443fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_times[nopath] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b435043",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_time = demand * trip_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dmd_time = demand_time.sum(dim=(1, 2))\n",
    "total_dmd_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_transfers = demand * n_transfers\n",
    "demand_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56877416",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_transfers = demand_transfers.sum(dim=(1, 2))\n",
    "total_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unserved_demand = (demand * nopath).sum(dim=(1, 2))\n",
    "unserved_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_demand = demand.sum(dim=(1,2))\n",
    "total_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all infs with 0\n",
    "transit_times[torch.isinf(transit_times)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time_Normalizer\n",
    "diameter = drive_times.flatten(1,2).max(1).values\n",
    "diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "served_demand = (has_path*demand).sum(dim=(1,2))\n",
    "served_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = transit_times.clone()\n",
    "total_demand_time = (demand*tt).sum(dim=(1,2))\n",
    "total_demand_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c97b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_demand_time = total_demand_time/(served_demand + 1e-6)\n",
    "mean_demand_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd381f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_demand_time_frac = mean_demand_time / diameter\n",
    "mean_demand_time_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_demand = (demand).sum(dim=(1,2))\n",
    "total_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117fc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopath = ~has_path\n",
    "#nopath\n",
    "unserved_demand = (demand * nopath).sum(dim=(1, 2))\n",
    "unserved_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9512e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_transfers = demand*n_transfers\n",
    "total_transfers = demand_transfers.sum(dim=(1,2))\n",
    "total_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "21715cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1980.])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_normalizer = drive_times.flatten(1,2).max(1).values\n",
    "time_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00819c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_matrix = state.demand\n",
    "trip_times = state.transit_times\n",
    "nopath = ~state.has_path\n",
    "trip_times[nopath] = 0\n",
    "demand_time = demand_matrix * trip_times\n",
    "total_dmd_time = demand_time.sum(dim=(1, 2))\n",
    "demand_transfers = demand_matrix * state.n_transfers\n",
    "total_transfers = demand_transfers.sum(dim=(1, 2))\n",
    "unserved_demand = (demand_matrix * nopath).sum(dim=(1, 2))\n",
    "total_demand = demand_matrix.sum(dim=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aac69027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([663.4530])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_demand_time = total_dmd_time/(served_demand + 1e-6)\n",
    "mean_demand_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e3af5495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demand Cost is tensor([30438900.])\n",
      "Demand Cost Fraction is tensor([1954.9711])\n",
      "Demand Cost Fraction Normalised is tensor([0.9874])\n"
     ]
    }
   ],
   "source": [
    "Demand_Cost = (mean_demand_time*served_demand)+(unserved_demand*2*time_normalizer)\n",
    "print(f\"Demand Cost is {Demand_Cost}\")\n",
    "Demand_Cost_Fraction = Demand_Cost/total_demand\n",
    "print(f\"Demand Cost Fraction is {Demand_Cost_Fraction}\")\n",
    "Demand_Cost_Fraction_Normalised = Demand_Cost_Fraction/(time_normalizer)\n",
    "print(f\"Demand Cost Fraction Normalised is {Demand_Cost_Fraction_Normalised}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f65be577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route 1: Total travel time = 27.0\n",
      "Route 2: Total travel time = 24.0\n",
      "Route 3: Total travel time = 33.0\n",
      "Route 4: Total travel time = 18.0\n",
      "Route 5: Total travel time = 27.0\n",
      "Route 6: Total travel time = 33.0\n",
      "Route 7: Total travel time = 33.0\n",
      "Route 8: Total travel time = 17.0\n",
      "Route 9: Total travel time = 24.0\n",
      "Route 10: Total travel time = 33.0\n",
      "Route 11: Total travel time = 33.0\n",
      "Route 12: Total travel time = 27.0\n",
      "Total travel time for all routes combined = 329.0\n"
     ]
    }
   ],
   "source": [
    "# Convert each row into a list of stops (skip the first column if it's a route name)\n",
    "routes = []\n",
    "for _, row in Routes.iterrows():\n",
    "    stops = [int(x) for x in row[1:] if pd.notna(x)]\n",
    "    routes.append(stops)\n",
    "\n",
    "# For each route, sum the travel time between consecutive stops\n",
    "route_total_times = []\n",
    "for route in routes:\n",
    "    total_time = 0\n",
    "    for i in range(len(route) - 1):\n",
    "        total_time += Travel_Time.at[route[i], route[i+1]]\n",
    "    route_total_times.append(total_time)\n",
    "\n",
    "# Print total travel time for each route\n",
    "for idx, ttime in enumerate(route_total_times, start=1):\n",
    "    print(f\"Route {idx}: Total travel time = {ttime}\")\n",
    "\n",
    "# Combined total travel time of all routes\n",
    "combined_total = sum(route_total_times)\n",
    "print(\"Total travel time for all routes combined =\", combined_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d2873180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route Cost Before Normalization is 19740.0\n",
      "Route_Cost After Normalization tensor([0.8308])\n"
     ]
    }
   ],
   "source": [
    "Total_Routes_Travel_Time = combined_total*60\n",
    "print(f\"Route Cost Before Normalization is {Total_Routes_Travel_Time}\")\n",
    "# Change Number of Routes\n",
    "Route_Cost_Normalised = (Total_Routes_Travel_Time/((time_normalizer*12)+1e-6))\n",
    "print(f\"Route_Cost After Normalization {Route_Cost_Normalised}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "697dff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_path_missing = nopath & (demand>0)\n",
    "n_disconnected_demand_edges = needed_path_missing.sum(dim=(1, 2))\n",
    "n_demand_edges = (demand > 0).sum(dim = (1,2))\n",
    "frac_uncovered = n_disconnected_demand_edges / n_demand_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b4115ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7337])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_violation = frac_uncovered + 0.1\n",
    "constraint_violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3d5ac753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9091])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cost_passenger_and_operator = (0.5*Route_Cost_Normalised)+ (0.5*Demand_Cost_Fraction_Normalised)\n",
    "Cost_passenger_and_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9193d948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5777])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cost = (0.5*Route_Cost_Normalised)+ (0.5*Demand_Cost_Fraction_Normalised) + (5*constraint_violation)\n",
    "Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Condition = df_paths['Demand'] > 0\n",
    "Total_Pairs_WDemand = Condition.sum() \n",
    "print(f\"Total Pairs With Demand {Total_Pairs_WDemand}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22274317",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Satisfied = df_paths.loc[Condition, 'Path Exists'].sum()\n",
    "print(f\"Total Pairs With Demand and Satisfied {Total_Satisfied}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e784b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraction_Unsatisfied = (Total_Pairs_WDemand-Total_Satisfied)/Total_Pairs_WDemand\n",
    "print(f\"Fraction Unsatisfied {Fraction_Unsatisfied}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Constraint_Violation = Fraction_Unsatisfied+0.1\n",
    "print(f\"Constraint Violation {Constraint_Violation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Cost\n",
    "Cost = (0.5*Route_Cost_Normalised)+ (0.5*Demand_Cost_Fraction_Normalised) + (5*Constraint_Violation)\n",
    "Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8dfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be 4.721008777618408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd19039",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [\n",
    "    [   0., 1740.,    0., 1800.,    0.,    0.,  660., 1680.,  780.,    0.,\n",
    "       960.,  840.,  240.,  360., 1140.,  960., 1140.,  240., 1020.,  600.,\n",
    "      1320.,    0.,  120., 1620., 2280., 1260.,    0., 1320.,  840., 1620.],\n",
    "    [2100.,    0.,    0.,   60.,    0.,    0., 3060., 1680., 1260.,    0.,\n",
    "      3360.,  480., 1020., 2760., 1080., 3360., 1920.,  780., 3420., 1560.,\n",
    "      1260.,    0., 2400., 1560., 2280., 1800.,    0., 2400., 1380., 2700.],\n",
    "    [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
    "    [2040., 1620.,    0.,    0.,    0.,    0., 3000., 1620., 1200.,    0.,\n",
    "      3300.,  420.,  960., 2700., 1020., 3300., 1860.,  720., 3360., 1500.,\n",
    "      1200.,    0., 2340., 1500., 2220., 1740.,    0., 2340., 1320., 2640.],\n",
    "    [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
    "    [2460., 2160.,    0., 1860.,    0.,    0., 3420., 1260., 3240.,    0.,\n",
    "      3720., 2460., 2700., 3120., 1860.,  360.,  900., 3000., 3780., 2340.,\n",
    "      2340.,    0., 2160., 2640., 1560., 1860.,    0.,  720., 1500., 1320.],\n",
    "    [ 660., 1500.,    0., 1500.,    0.,    0.,    0.,  600., 1740.,    0.,\n",
    "       300., 1800., 1200.,  300., 1200.,  300.,  360.,  900.,  660., 1260.,\n",
    "      1680.,    0.,  780., 1980., 1200., 1080.,    0.,  840.,  960., 1140.],\n",
    "    [ 900.,  600.,    0.,  600.,    0.,    0., 1860.,    0., 1680.,    0.,\n",
    "      2160.,  900., 1140., 1560.,  300., 2160.,  240., 1440., 2220.,  780.,\n",
    "       780.,    0.,  600., 1080.,  300.,  300.,    0.,  720.,  540., 1020.],\n",
    "    [2100., 1980.,    0., 2040.,    0.,    0., 3060., 2220.,    0.,    0.,\n",
    "      3360., 1080., 1320., 2760., 1380., 3360., 1680.,  780., 3420.,  300.,\n",
    "      1560.,    0., 2400., 1860., 2820., 1800.,    0., 1860., 1380., 2160.],\n",
    "    [1860.,  960.,    0., 1020.,    0.,    0., 2820.,  660., 1740.,    0.,\n",
    "      3120.,  660., 1500., 2520.,  360., 3120.,  900.,  960., 3180., 1740.,\n",
    "       840.,    0., 1560.,  180., 1260., 1260.,    0., 1380., 1200., 1680.],\n",
    "    [1680., 1080.,    0., 1380.,    0.,    0., 2640.,  480., 2460.,    0.,\n",
    "         0., 1380., 1920., 2340.,  780., 2940., 1020., 2220., 3000., 1560.,\n",
    "      1260.,    0., 1380., 1560., 1080., 1080.,    0., 1500., 1320., 1800.],\n",
    "    [1320.,  900.,    0.,  960.,    0.,    0., 2280.,  900.,  780.,    0.,\n",
    "      2580.,    0.,  540., 1980.,  300., 2580., 1140.,  300., 2640., 1080.,\n",
    "       480.,    0., 1620.,  780., 1500., 1020.,    0., 1620.,  600., 1920.],\n",
    "    [2340., 2220.,    0., 2280.,    0.,    0., 3300., 2460.,  240.,    0.,\n",
    "      3600., 1320.,    0., 3000., 1620., 3600., 1920., 1020., 3660.,  540.,\n",
    "      1800.,    0., 2640., 2100., 3060., 2040.,    0., 2100., 1620., 2400.],\n",
    "    [ 360., 1800.,    0., 1800.,    0.,    0.,  300.,  900., 1440.,    0.,\n",
    "       600., 1200.,  900.,    0., 1500.,  600.,  660.,  600.,  360.,  960.,\n",
    "      1980.,    0.,  480., 2280., 1500., 1620.,    0., 1140., 1200., 1440.],\n",
    "    [1500.,  300.,    0.,  360.,    0.,    0., 2460.,  300., 1380.,    0.,\n",
    "      2760.,  300., 1140., 2160.,    0., 2760.,  540.,  600., 2820., 1380.,\n",
    "       180.,    0., 1200.,  480.,  900.,  900.,    0., 1020.,  840., 1320.],\n",
    "    [2100., 1800.,    0., 1500.,    0.,    0., 3060.,  900., 2880.,    0.,\n",
    "      3360., 2100., 2340., 2760., 1500.,    0.,  540., 2640., 3420., 1980.,\n",
    "      1980.,    0., 1800., 2280., 1200., 1500.,    0.,  360., 1140.,  960.],\n",
    "    [ 720.,  840.,    0., 1140.,    0.,    0., 1680.,  240., 1500.,    0.,\n",
    "      1980., 1140.,  960., 1380.,  540., 1980.,    0., 1260., 2040., 1200.,\n",
    "      1020.,    0., 1020., 1320.,  840.,  420.,    0.,  180.,  300.,  480.],\n",
    "    [1020., 1200.,    0., 1260.,    0.,    0., 1980., 1140.,  480.,    0.,\n",
    "      2280.,  300.,  240., 1680.,  600., 2280.,  600.,    0., 2340.,  780.,\n",
    "       780.,    0., 1320., 1080., 1740.,  720.,    0.,  780.,  300., 1080.],\n",
    "    [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
    "    [1500., 1380.,    0., 1440.,    0.,    0., 2460., 1620.,  960.,    0.,\n",
    "      2760.,  480.,  720., 2160.,  780., 2760., 1080.,  180., 2820.,    0.,\n",
    "       960.,    0., 1800., 1260., 2220., 1200.,    0., 1260.,  780., 1560.],\n",
    "    [2280., 1380.,    0., 1440.,    0.,    0., 3240., 1080., 2160.,    0.,\n",
    "      3540., 1080., 1920., 2940.,  780., 3540., 1320., 1380., 3600., 2160.,\n",
    "         0.,    0., 1980.,  300., 1680., 1680.,    0., 1800., 1620., 2100.],\n",
    "    [1260., 2100.,    0., 2100.,    0.,    0.,  300., 1200., 2340.,    0.,\n",
    "       900., 2400., 1800.,  600., 1800.,  900.,  960., 1500.,  960., 1860.,\n",
    "      2280.,    0., 1380., 2580., 1800., 1680.,    0., 1440., 1560., 1740.],\n",
    "    [ 120., 1560.,    0., 1620.,    0.,    0.,  780., 1800., 1200.,    0.,\n",
    "      1380.,  660.,  660.,  480.,  960., 1080., 1260.,  360., 1140.,  180.,\n",
    "      1140.,    0.,    0., 1440., 2400., 1380.,    0., 1440.,  960., 1740.],\n",
    "    [1680.,  780.,    0.,  840.,    0.,    0., 2640.,  480., 1560.,    0.,\n",
    "      2940.,  480., 1320., 2340.,  180., 2940.,  720.,  780., 3000., 1560.,\n",
    "       660.,    0., 1380.,    0., 1080., 1080.,    0., 1200., 1020., 1500.],\n",
    "    [2640., 2220.,    0.,  300.,    0.,    0., 3600., 2220., 1800.,    0.,\n",
    "      3900., 1020., 1560., 3300., 1620., 3900., 2460., 1320., 3960., 2100.,\n",
    "      1800.,    0., 2940., 2100.,    0., 2340.,    0., 2940., 1920., 3240.],\n",
    "    [ 300., 2340.,    0., 2400.,    0.,    0., 1260., 2280., 1080.,    0.,\n",
    "      1560., 1440.,  540.,  960., 1740., 1560., 1740.,  840., 1620.,  480.,\n",
    "      1920.,    0.,  300., 2220., 2880.,    0.,    0., 1920., 1440., 2220.],\n",
    "    [ 300., 2340.,    0., 2400.,    0.,    0.,  960., 2280., 1380.,    0.,\n",
    "      1260., 1440.,  840.,  660., 1740., 1560., 1740.,  840., 1320., 1200.,\n",
    "      1920.,    0.,  720., 2220., 2880., 1860.,    0., 1920., 1440., 2220.],\n",
    "    [1440., 1140.,    0.,  840.,    0.,    0., 2400.,  240., 2220.,    0.,\n",
    "      2700., 1440., 1680., 2100.,  840., 2700.,  180., 1980., 2760., 1320.,\n",
    "      1320.,    0., 1140., 1620.,  540.,  840.,    0.,    0.,  780.,  300.],\n",
    "    [ 420., 1440.,    0., 1740.,    0.,    0., 1380.,  840., 1200.,    0.,\n",
    "      1680., 1560.,  660., 1080., 1140., 1680.,  300.,  960., 1740.,  900.,\n",
    "      1620.,    0.,  720., 1920., 1440.,  120.,    0.,  480.,    0.,  780.],\n",
    "    [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "         0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080325ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55c6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c178dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cost_obj(state)\n",
    "rewards = -result.cost * return_scale * state.is_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ab34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_obj = MyCostModule(low_memory_mode=False, symmetric_routes=False, **cost_cfg.kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCostModule(CostModule):\n",
    "    def __init__(self, mean_stop_time_s=MEAN_STOP_TIME_S, \n",
    "                 avg_transfer_wait_time_s=AVG_TRANSFER_WAIT_TIME_S,\n",
    "                 symmetric_routes=False, low_memory_mode=False,\n",
    "                 demand_time_weight=0.5, route_time_weight=0.5, \n",
    "                 constraint_violation_weight=5, variable_weights=False,\n",
    "                 ignore_stops_oob=False, pp_fraction=0.33, \n",
    "                 op_fraction=0.33):\n",
    "        super().__init__(mean_stop_time_s, avg_transfer_wait_time_s,\n",
    "                         symmetric_routes, low_memory_mode)\n",
    "        self.demand_time_weight = demand_time_weight\n",
    "        self.route_time_weight = route_time_weight\n",
    "        self.constraint_violation_weight = constraint_violation_weight\n",
    "        self.variable_weights = variable_weights\n",
    "        if self.variable_weights:\n",
    "            # the fraction of variable weights sampled that are PP and OP\n",
    "            self.pp_fraction = pp_fraction\n",
    "            self.op_fraction = op_fraction\n",
    "            assert pp_fraction + op_fraction <= 1, \\\n",
    "                \"fractions of extreme samples must sum to <= 1\"\n",
    "        self.ignore_stops_oob = ignore_stops_oob\n",
    "\n",
    "    def sample_variable_weights(self, batch_size, device=None):\n",
    "        if not self.variable_weights:\n",
    "            dtw = torch.full((batch_size,), self.demand_time_weight, \n",
    "                             device=device)\n",
    "            rtw = torch.full((batch_size,), self.route_time_weight, \n",
    "                              device=device)\n",
    "        else:\n",
    "            random_number = torch.rand(batch_size, device=device)\n",
    "            # Initialized to zero, which is the right value for OP\n",
    "            dtw = torch.zeros(batch_size, device=device)\n",
    "            # Set demand time weight to 1 where we're using PP\n",
    "            is_pp = random_number < self.pp_fraction\n",
    "            dtw[is_pp] = 1.0\n",
    "            # Set demand time weight to a random value in [0,1] where it's\n",
    "             # neither OP nor PP\n",
    "            extremes_fraction = self.pp_fraction + self.op_fraction\n",
    "            is_intermediate = random_number >= extremes_fraction\n",
    "            n_intermediate = is_intermediate.sum()\n",
    "            dtw[is_intermediate] = torch.rand(n_intermediate, device=device)\n",
    "\n",
    "            # reward time weight is \n",
    "            rtw = 1 - dtw\n",
    "     \n",
    "        return {\n",
    "            'demand_time_weight': dtw,\n",
    "            'route_time_weight': rtw\n",
    "        }\n",
    "    \n",
    "    def get_weights(self, device=None):\n",
    "        dtm = self.demand_time_weight\n",
    "        if type(dtm) is not Tensor:\n",
    "            dtm = torch.tensor([dtm], device=device)\n",
    "        rtm = self.route_time_weight\n",
    "        if type(rtm) is not Tensor:\n",
    "            rtm = torch.tensor([rtm], device=device)\n",
    "\n",
    "        return {\n",
    "            'demand_time_weight': dtm,\n",
    "            'route_time_weight': rtm\n",
    "        }\n",
    "    \n",
    "    def set_weights(self, demand_time_weight=None, route_time_weight=None, \n",
    "                    constraint_violation_weight=None):\n",
    "        if demand_time_weight is not None:\n",
    "            self.demand_time_weight = demand_time_weight\n",
    "        if route_time_weight is not None:\n",
    "            self.route_time_weight = route_time_weight\n",
    "        if constraint_violation_weight is not None:\n",
    "            self.constraint_violation_weight = constraint_violation_weight\n",
    "\n",
    "    def forward(self, state, constraint_weight=None, no_norm=False, \n",
    "                return_per_route_riders=False):\n",
    "        cho = self._cost_helper(state, return_per_route_riders)\n",
    "        cost_weights = state.cost_weights\n",
    "        if 'demand_time_weight' in cost_weights:\n",
    "            demand_time_weight = cost_weights['demand_time_weight']\n",
    "        else:\n",
    "            demand_time_weight = self.demand_time_weight\n",
    "        if 'route_time_weight' in cost_weights:\n",
    "            route_time_weight = cost_weights['route_time_weight']\n",
    "        else:\n",
    "            route_time_weight = self.route_time_weight\n",
    "            \n",
    "        if constraint_weight is None:\n",
    "            constraint_weight = self.constraint_violation_weight\n",
    "\n",
    "        # if we have more weights than routes, truncate the weights\n",
    "        if type(demand_time_weight) is Tensor and \\\n",
    "           demand_time_weight.shape[0] > state.batch_size:\n",
    "            demand_time_weight = demand_time_weight[:state.batch_size]\n",
    "        if type(route_time_weight) is Tensor and \\\n",
    "           route_time_weight.shape[0] > state.batch_size:\n",
    "            route_time_weight = route_time_weight[:state.batch_size]\n",
    "        if type(constraint_weight) is Tensor and \\\n",
    "           constraint_weight.shape[0] > state.batch_size:\n",
    "            constraint_weight = constraint_weight[:state.batch_size]\n",
    "\n",
    "        # normalize all time values by the maximum drive time in the graph\n",
    "        time_normalizer = state.drive_times.flatten(1,2).max(1).values\n",
    "        #print(f\"What are the drive times buddy: {state.drive_times}\", flush=True)\n",
    "        # AA - Change (Print Time Normalizer, demand_time_weight, route_time_weight, constraint_violation_weight)\n",
    "        #### STARTS HERE ####\n",
    "        #print(f\"time_normalizer: {time_normalizer}\", flush=True)\n",
    "        #print(f\"demand_time_weight: {demand_time_weight}\", flush=True)\n",
    "        #print(f\"route_time_weight: {route_time_weight}\", flush=True)\n",
    "        #print(f\"constraint_violation_weight: {constraint_weight}\", flush=True)\n",
    "        #### ENDS HERE ####\n",
    "\n",
    "        n_routes = state.n_routes_to_plan\n",
    "\n",
    "        # fraction of demand not covered by routes, and fraction of routes\n",
    "        frac_uncovered = cho.n_disconnected_demand_edges / state.n_demand_edges\n",
    "        # AA - Change (Print frac_uncovered)\n",
    "        #### STARTS HERE ####\n",
    "        #print(f\"Uncovered Demand: {frac_uncovered}\", flush=True)\n",
    "        #### ENDS HERE ####\n",
    "        if state.max_route_len is None:\n",
    "            denom = n_routes * state.max_route_len\n",
    "        else:\n",
    "            denom = n_routes * state.min_route_len\n",
    "        # avoid division by 0\n",
    "        denom[denom == 0] = 1\n",
    "        # unserved demand is treated as taking twice the diameter of the graph\n",
    "         # to get where it's going\n",
    "        served_demand = cho.total_demand - cho.unserved_demand\n",
    "        demand_cost = cho.mean_demand_time * served_demand + \\\n",
    "            cho.unserved_demand * time_normalizer * 2\n",
    "        demand_cost /= cho.total_demand\n",
    "        # demand_cost = cho.mean_demand_time\n",
    "        route_cost = cho.total_route_time\n",
    "        # AA - Change (Print served_demand, total_demand, unserved_demand, mean_demand_time, demand_cost, route_cost)\n",
    "        #### STARTS HERE ####\n",
    "        #print(f\"served_demand: {served_demand}\", flush=True)\n",
    "        #print(f\"total_demand: {cho.total_demand}\", flush=True)\n",
    "        #print(f\"unserved_demand: {cho.unserved_demand}\", flush=True)\n",
    "        #print(f\"mean_demand_time: {cho.mean_demand_time}\", flush=True)\n",
    "        #print(f\"demand_cost (Before Normalizer): {demand_cost}\", flush=True)\n",
    "        #print(f\"route_cost (Before Normalizer): {route_cost}\", flush=True)\n",
    "        #### ENDS HERE ####\n",
    "        \n",
    "\n",
    "        # average trip time, total route time, and trips-at-n-transfers\n",
    "        if not no_norm:\n",
    "            # normalize cost components\n",
    "            demand_cost = demand_cost / time_normalizer\n",
    "            route_cost = route_cost / (time_normalizer * n_routes + 1e-6)\n",
    "            # AA - Change (Print demand_cost)\n",
    "            #### STARTS HERE ####\n",
    "            #print(f\"demand_cost (After Normalizer): {demand_cost}\", flush=True)\n",
    "            #print(f\"route_cost (After Normalizer): {route_cost}\", flush=True)\n",
    "            #### ENDS HERE ####\n",
    "            \n",
    "\n",
    "        cost = demand_cost * demand_time_weight + \\\n",
    "            route_cost * route_time_weight\n",
    "        # AA - Change (Print cost of pp and op)\n",
    "        ### STARTS HERE ####\n",
    "        #print(f\"cost passenger and operator : {cost}\", flush=True)\n",
    "        #### ENDS HERE ####       \n",
    "\n",
    "        # compute the weight for the violated-constraint penalty, as an\n",
    "         # upper bound on how bad the demand and route cost components may be\n",
    "        # demand_constraint_weight = 2\n",
    "        # edge_times = state.street_adj.isfinite() * state.drive_times\n",
    "        # max_edge_time = edge_times.flatten(1,2).max(-1)[0]\n",
    "        # route_constraint_weight = 2 * max_edge_time * state.n_nodes\n",
    "        # route_constraint_weight /= time_normalizer\n",
    "        # dynamic_cv_weight = demand_constraint_weight * demand_time_weight + \\\n",
    "        #     route_constraint_weight * route_time_weight\n",
    "        # constraint_weight *= dynamic_cv_weight \n",
    "\n",
    "        const_viol_cost = frac_uncovered + 0.1 * (frac_uncovered > 0)\n",
    "        if not self.ignore_stops_oob:\n",
    "            frac_stops_oob = cho.n_stops_oob / denom\n",
    "            const_viol_cost += frac_stops_oob + 0.1 * (frac_stops_oob > 0)\n",
    "\n",
    "        cost += const_viol_cost * constraint_weight\n",
    "        cho.cost = cost\n",
    "        # AA - Change (Print weight of constraints and constraint violation cost)\n",
    "        ### STARTS HERE ####\n",
    "        #print(f\"Weight of Constraints: {constraint_weight}\", flush=True)\n",
    "        #print(f\"Constraint Violaton Cost: {const_viol_cost}\", flush=True)\n",
    "        #### ENDS HERE ####    \n",
    "\n",
    "        assert cost.isfinite().all(), \"invalid cost was computed!\"\n",
    "        assert (cost >= 0).all(), \"cost is negative!\"\n",
    "\n",
    "        return cho"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
