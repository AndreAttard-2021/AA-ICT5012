batch_size: 64
n_epochs: 5
reward_scale: 1.0
lr: 0.0016134816080499328
decay: 0.0008404361781997002
optimizer: Adam
baseline_mode: neural
discount_rate: 1.0
entropy_weight: 0.0
diff_reward: true

eval:
  min_route_len: 2
  max_route_len: 12
  n_routes: 10

dataset:
  type: pickle
  kwargs:
    path: datasets/20_nodes/mixed
    space_scale: 0.6
    demand_scale: 0.2

defaults:
  - _self_
  - experiment: standard
  - model: bestsofar_feb2023
